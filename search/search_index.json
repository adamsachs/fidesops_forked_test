{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is Fidesops? Fidesops (fee-dez-\u00e4ps, combination of the Latin term \"Fid\u0113s\" + \"operations\") is an open-source, extensible, deployed engine that fulfills any privacy request (e.g. access request, erasure request) by connecting directly to your disparate databases. Key Features Programmable Data Privacy Fidesops connects and orchestrates calls to all of your databases in order to access, update and delete sensitive data per your policy configuration written in Fideslang . Handle Dependencies Between Datastores Fidesops works by integrating all your datasets into a unified graph and automatically traversing them in order. We know that sensitive data is stored all around your dynamic ecosystem, so Fidesops builds these dependencies automatically for each request. Integrate with Compliance Tools Fidesops is open & extensible, meaning it can easily be integrated into your existing privacy compliance management tools like OneTrust to fulfill data subject requests and return results, automatically. Built to Scale Lots of databases? Tons of microservices? Connect as many databases and services as you'd like, and let Fidesops do the heavy lifting. How does Fidesops work with Fidesctl and Fideslang? In a software organization, the team that writes and delivers software is normally the same team responsible for executing a privacy request when it comes in from customer support or legal . When your organization receives a privacy request, Fideops will automatically fulfill it per the execution policies your legal and business owners have created by querying your databases directly. Your policies and database annotations are written in Fideslang : the syntax that describes the attributes of your data and its allowed purposes of use. But after identifying what types of data are in your databases using Fideslang, how will your organization know what data is deemed sensitive? And how will your organization prevent inappropriate uses of that data? That's where Fidesctl comes in. Fidesctl is a CLI tool that continuously verifies Fideslang database annotations against acceptable use privacy policies. Next Steps To start automating requests with Fidesops, visit the Tutorial for a step-by-step walk through!","title":"What is Fidesops?"},{"location":"#what-is-fidesops","text":"Fidesops (fee-dez-\u00e4ps, combination of the Latin term \"Fid\u0113s\" + \"operations\") is an open-source, extensible, deployed engine that fulfills any privacy request (e.g. access request, erasure request) by connecting directly to your disparate databases.","title":"What is Fidesops?"},{"location":"#key-features","text":"","title":"Key Features"},{"location":"#programmable-data-privacy","text":"Fidesops connects and orchestrates calls to all of your databases in order to access, update and delete sensitive data per your policy configuration written in Fideslang .","title":"Programmable Data Privacy"},{"location":"#handle-dependencies-between-datastores","text":"Fidesops works by integrating all your datasets into a unified graph and automatically traversing them in order. We know that sensitive data is stored all around your dynamic ecosystem, so Fidesops builds these dependencies automatically for each request.","title":"Handle Dependencies Between Datastores"},{"location":"#integrate-with-compliance-tools","text":"Fidesops is open & extensible, meaning it can easily be integrated into your existing privacy compliance management tools like OneTrust to fulfill data subject requests and return results, automatically.","title":"Integrate with Compliance Tools"},{"location":"#built-to-scale","text":"Lots of databases? Tons of microservices? Connect as many databases and services as you'd like, and let Fidesops do the heavy lifting.","title":"Built to Scale"},{"location":"#how-does-fidesops-work-with-fidesctl-and-fideslang","text":"In a software organization, the team that writes and delivers software is normally the same team responsible for executing a privacy request when it comes in from customer support or legal . When your organization receives a privacy request, Fideops will automatically fulfill it per the execution policies your legal and business owners have created by querying your databases directly. Your policies and database annotations are written in Fideslang : the syntax that describes the attributes of your data and its allowed purposes of use. But after identifying what types of data are in your databases using Fideslang, how will your organization know what data is deemed sensitive? And how will your organization prevent inappropriate uses of that data? That's where Fidesctl comes in. Fidesctl is a CLI tool that continuously verifies Fideslang database annotations against acceptable use privacy policies.","title":"How does Fidesops work with Fidesctl and Fideslang?"},{"location":"#next-steps","text":"To start automating requests with Fidesops, visit the Tutorial for a step-by-step walk through!","title":"Next Steps"},{"location":"deployment/","text":"Deployment Guide To quickly experiment with fidesops , it's easiest to clone the source repo and use the built-in docker compose configuration to get a fully working demo environment up and running. However, when you want to use fidesops in production, you'll want to deploy it in parts, leveraging whatever cloud infrastructure your organization is most familiar with. Fully deployed, fidesops has three individual systems you'll need to run: Hosted Database : PostgreSQL database server used for permanent storage of configuration data for the web server Hosted Cache : Redis database server used as a temporary cache during execution and scheduling of tasks fidesops Web Server : Main application with API endpoints to configure, execute, and report on privacy requests Let's review each individually. Step 1: Setup Hosted Database Like most web applications, fidesops uses an application database for persistent storage. Any hosted PostgreSQL database solution will work (PostgreSQL version 12+), as long as it's accessible. Good options include: Managed PostgreSQL database services (e.g. AWS RDS, GCP Cloud SQL, Azure Database) Self-hosted PostgreSQL Docker container with a persistent volume mount (e.g. on a Kubernetes cluster) Self-hosted PostgreSQL server (e.g. on an EC2 server) NOTE: there is no reason to expose this database to the public Internet as long as it is will be accessible by your fidesops web server! Setting up a production-grade PostgreSQL database is likely something your team is already familiar with, so we won't revisit that here. Once it's up and running, make sure you create a unique user and database to use for fidesops (we recommended calling these both fidesops ) and assign a secure password, then keep track of all those credentials. You'll need those values later to populate these configuration variables for fidesops : Config Variable Example Description FIDESOPS__DATABASE__SERVER postgres.internal hostname for your database server FIDESOPS__DATABASE__USER fidesops username fidesops should use to access the database FIDESOPS__DATABASE__PASSWORD fidesopssecret password fidesops should use to access the database FIDESOPS__DATABASE__DB fidesops database name Fidesops PostgreSQL app database diagram Step 2: Setup Hosted Cache During privacy request execution, fidesops collects result data in a temporary Redis cache that automatically expires to ensure personal data is never retained erroneously. Any hosted Redis database will work for this purpose (Redis version 6.2.0+), from a simple Docker redis container to a managed service (e.g. AWS ElastiCache, GCP Memorystore, Azure Cache, Redis Cloud). NOTE: Similar to PostgreSQL, there is no reason to expose this cache to the public Internet as long as it is will be accessible by your fidesops web server! As with the PostgreSQL deployment, setting up a production-grade Redis cache is outside the scope of these docs. Once your Redis cache is available, ensure you enable a password (via Redis AUTH ) to provide additional security, and then keep track of all the connection credentials as you'll need these to configure fidesops in the next step with the following variables: Config Variable Example Description FIDESOPS__REDIS__HOST redis.internal hostname for your Redis server FIDESOPS__REDIS__PORT 6379 port for your Redis server FIDESOPS__REDIS__PASSWORD fidesopssecret password fidesops should use to access Redis Step 3: Setup fidesops Web Server The fidesops web server is a FastAPI application with a Uvicorn server to handle requests. The host requirements for the fidesops web server are pretty minimal: A general purpose web server (e.g. for AWS EC2, a t2.small should be plenty) No persistent storage requirements (this is handled by the hosted database) Docker version 20.10.8 or newer (if installing via Docker) OR Python 3.8 or newer (if installing via Python) Depending on your preferences, you can install fidesops in one of two ways: Docker or Python . Install fidesops via Docker If you typically run your applications via Docker, you'll probably be familiar with pulling images and configuring them with environment variables. Setting up a fidesops container should contain no surprises. First, ensure that Docker is running on your host, with a minimum version of 20.10.8 . You can docker pull ethyca/fidesops to get the latest image from Ethyca's Docker Hub here: ethyca/fidesops . 1 docker pull ethyca/fidesops Once pulled, you can run docker run ethyca/fidesops to start the server. To configure fidesops for your environment, however, you'll need to provide a number of required environment variables through docker run . You can accomplish this either by creating a .env file and passing it in via the --env-file {file} option or by providing individual variables with the --env {VAR} option. At a minimum, you'll need to provide the following as env variables: Config Variable Example Description FIDESOPS__SECURITY__APP_ENCRYPTION_KEY averyveryverysecretencryptionkey AES256 encryption key used for DB & JWE encryption, must be exactly 32 characters (256bits) FIDESOPS__SECURITY__OAUTH_ROOT_CLIENT_ID fidesopsadmin client ID used for the \"root\" OAuth client FIDESOPS__SECURITY__OAUTH_ROOT_CLIENT_SECRET fidesopsadminsecret client secret used for the \"root\" OAuth client FIDESOPS__DATABASE__SERVER postgres.internal hostname for your database server FIDESOPS__DATABASE__PORT 5432 port for your database server FIDESOPS__DATABASE__USER fidesops username fidesops should use to access the database FIDESOPS__DATABASE__PASSWORD fidesopssecret password fidesops should use to access the database FIDESOPS__DATABASE__DB fidesops database name FIDESOPS__REDIS__HOST redis.internal hostname for your Redis server FIDESOPS__REDIS__PORT 6379 port for your Redis server FIDESOPS__REDIS__PASSWORD fidesopssecret password fidesops should use to access Redis Lastly, you'll also want to ensure you use the -p 8080:8080 option to docker run to bind port 8080 (the web server) to port 8080 on the host, so you can connect from the outside. Putting this together: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 docker run \\ -p 8080:8080 \\ --env FIDESOPS__SECURITY__APP_ENCRYPTION_KEY=\"averyveryverysecretencryptionkey\" \\ --env FIDESOPS__SECURITY__OAUTH_ROOT_CLIENT_ID=\"fidesopsadmin\" \\ --env FIDESOPS__SECURITY__OAUTH_ROOT_CLIENT_SECRET=\"fidesopsadminsecret\" \\ --env FIDESOPS__DATABASE__SERVER=\"postgres.internal\" \\ --env FIDESOPS__DATABASE__PORT=\"5432\" \\ --env FIDESOPS__DATABASE__USER=\"fidesops\" \\ --env FIDESOPS__DATABASE__PASSWORD=\"fidesopssecret\" \\ --env FIDESOPS__DATABASE__DB=\"fidesops\" \\ --env FIDESOPS__REDIS__HOST=\"redis.internal\" \\ --env FIDESOPS__REDIS__PORT=6379 \\ --env FIDESOPS__REDIS__PASSWORD=\"fidesopssecret\" \\ ethyca/fidesops INFO:fidesops.main:****************fidesops**************** INFO:fidesops.main:Running any pending DB migrations... INFO:alembic.runtime.migration:Context impl PostgresqlImpl. INFO:alembic.runtime.migration:Will assume transactional DDL. INFO:fidesops.main:Starting scheduled request intake... INFO:apscheduler.scheduler:Scheduler started INFO:fidesops.main:Starting web server... INFO:uvicorn.error:Started server process [1] INFO:uvicorn.error:Waiting for application startup. INFO:uvicorn.error:Application startup complete. INFO:uvicorn.error:Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit) Or if you prefer to create your .env file and pass an --env-file variable, you can use the following: 1 2 3 4 docker run \\ -p 8080:8080 \\ --env-file=<ENV FILE NAME>.env \\ ethyca/fidesops Now, for most Docker hosts, you won't be calling docker run directly, and instead will be providing configuration variables to Kubernetes/Swarm/ECS/etc. As you can see in the docker run example above, this config is quite minimal and should just involve specifying (1) the image, (2) the port mapping, (3) all the various environment variables for configuration. Note that there's no need for a persistent volume mount for the web server, it's fully ephemeral and relies on the database for all it's permanent state. Test the Web Server To test that your server is running, visit http://{server_url}/health in your browser (e.g. http://0.0.0.0:8080/health) and you should see { \"healthy\": true } . You now have a functional fidesops server running! Now you can use the API to set up your OAuth clients, connect to databases, configure policies, execute privacy requests, etc. To learn more, head to the How-To Guides for details.","title":"Deployment Guide"},{"location":"deployment/#deployment-guide","text":"To quickly experiment with fidesops , it's easiest to clone the source repo and use the built-in docker compose configuration to get a fully working demo environment up and running. However, when you want to use fidesops in production, you'll want to deploy it in parts, leveraging whatever cloud infrastructure your organization is most familiar with. Fully deployed, fidesops has three individual systems you'll need to run: Hosted Database : PostgreSQL database server used for permanent storage of configuration data for the web server Hosted Cache : Redis database server used as a temporary cache during execution and scheduling of tasks fidesops Web Server : Main application with API endpoints to configure, execute, and report on privacy requests Let's review each individually.","title":"Deployment Guide"},{"location":"deployment/#step-1-setup-hosted-database","text":"Like most web applications, fidesops uses an application database for persistent storage. Any hosted PostgreSQL database solution will work (PostgreSQL version 12+), as long as it's accessible. Good options include: Managed PostgreSQL database services (e.g. AWS RDS, GCP Cloud SQL, Azure Database) Self-hosted PostgreSQL Docker container with a persistent volume mount (e.g. on a Kubernetes cluster) Self-hosted PostgreSQL server (e.g. on an EC2 server) NOTE: there is no reason to expose this database to the public Internet as long as it is will be accessible by your fidesops web server! Setting up a production-grade PostgreSQL database is likely something your team is already familiar with, so we won't revisit that here. Once it's up and running, make sure you create a unique user and database to use for fidesops (we recommended calling these both fidesops ) and assign a secure password, then keep track of all those credentials. You'll need those values later to populate these configuration variables for fidesops : Config Variable Example Description FIDESOPS__DATABASE__SERVER postgres.internal hostname for your database server FIDESOPS__DATABASE__USER fidesops username fidesops should use to access the database FIDESOPS__DATABASE__PASSWORD fidesopssecret password fidesops should use to access the database FIDESOPS__DATABASE__DB fidesops database name","title":"Step 1: Setup Hosted Database"},{"location":"deployment/#fidesops-postgresql-app-database-diagram","text":"","title":"Fidesops PostgreSQL app database diagram"},{"location":"deployment/#step-2-setup-hosted-cache","text":"During privacy request execution, fidesops collects result data in a temporary Redis cache that automatically expires to ensure personal data is never retained erroneously. Any hosted Redis database will work for this purpose (Redis version 6.2.0+), from a simple Docker redis container to a managed service (e.g. AWS ElastiCache, GCP Memorystore, Azure Cache, Redis Cloud). NOTE: Similar to PostgreSQL, there is no reason to expose this cache to the public Internet as long as it is will be accessible by your fidesops web server! As with the PostgreSQL deployment, setting up a production-grade Redis cache is outside the scope of these docs. Once your Redis cache is available, ensure you enable a password (via Redis AUTH ) to provide additional security, and then keep track of all the connection credentials as you'll need these to configure fidesops in the next step with the following variables: Config Variable Example Description FIDESOPS__REDIS__HOST redis.internal hostname for your Redis server FIDESOPS__REDIS__PORT 6379 port for your Redis server FIDESOPS__REDIS__PASSWORD fidesopssecret password fidesops should use to access Redis","title":"Step 2: Setup Hosted Cache"},{"location":"deployment/#step-3-setup-fidesops-web-server","text":"The fidesops web server is a FastAPI application with a Uvicorn server to handle requests. The host requirements for the fidesops web server are pretty minimal: A general purpose web server (e.g. for AWS EC2, a t2.small should be plenty) No persistent storage requirements (this is handled by the hosted database) Docker version 20.10.8 or newer (if installing via Docker) OR Python 3.8 or newer (if installing via Python) Depending on your preferences, you can install fidesops in one of two ways: Docker or Python .","title":"Step 3: Setup fidesops Web Server"},{"location":"deployment/#install-fidesops-via-docker","text":"If you typically run your applications via Docker, you'll probably be familiar with pulling images and configuring them with environment variables. Setting up a fidesops container should contain no surprises. First, ensure that Docker is running on your host, with a minimum version of 20.10.8 . You can docker pull ethyca/fidesops to get the latest image from Ethyca's Docker Hub here: ethyca/fidesops . 1 docker pull ethyca/fidesops Once pulled, you can run docker run ethyca/fidesops to start the server. To configure fidesops for your environment, however, you'll need to provide a number of required environment variables through docker run . You can accomplish this either by creating a .env file and passing it in via the --env-file {file} option or by providing individual variables with the --env {VAR} option. At a minimum, you'll need to provide the following as env variables: Config Variable Example Description FIDESOPS__SECURITY__APP_ENCRYPTION_KEY averyveryverysecretencryptionkey AES256 encryption key used for DB & JWE encryption, must be exactly 32 characters (256bits) FIDESOPS__SECURITY__OAUTH_ROOT_CLIENT_ID fidesopsadmin client ID used for the \"root\" OAuth client FIDESOPS__SECURITY__OAUTH_ROOT_CLIENT_SECRET fidesopsadminsecret client secret used for the \"root\" OAuth client FIDESOPS__DATABASE__SERVER postgres.internal hostname for your database server FIDESOPS__DATABASE__PORT 5432 port for your database server FIDESOPS__DATABASE__USER fidesops username fidesops should use to access the database FIDESOPS__DATABASE__PASSWORD fidesopssecret password fidesops should use to access the database FIDESOPS__DATABASE__DB fidesops database name FIDESOPS__REDIS__HOST redis.internal hostname for your Redis server FIDESOPS__REDIS__PORT 6379 port for your Redis server FIDESOPS__REDIS__PASSWORD fidesopssecret password fidesops should use to access Redis Lastly, you'll also want to ensure you use the -p 8080:8080 option to docker run to bind port 8080 (the web server) to port 8080 on the host, so you can connect from the outside. Putting this together: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 docker run \\ -p 8080:8080 \\ --env FIDESOPS__SECURITY__APP_ENCRYPTION_KEY=\"averyveryverysecretencryptionkey\" \\ --env FIDESOPS__SECURITY__OAUTH_ROOT_CLIENT_ID=\"fidesopsadmin\" \\ --env FIDESOPS__SECURITY__OAUTH_ROOT_CLIENT_SECRET=\"fidesopsadminsecret\" \\ --env FIDESOPS__DATABASE__SERVER=\"postgres.internal\" \\ --env FIDESOPS__DATABASE__PORT=\"5432\" \\ --env FIDESOPS__DATABASE__USER=\"fidesops\" \\ --env FIDESOPS__DATABASE__PASSWORD=\"fidesopssecret\" \\ --env FIDESOPS__DATABASE__DB=\"fidesops\" \\ --env FIDESOPS__REDIS__HOST=\"redis.internal\" \\ --env FIDESOPS__REDIS__PORT=6379 \\ --env FIDESOPS__REDIS__PASSWORD=\"fidesopssecret\" \\ ethyca/fidesops INFO:fidesops.main:****************fidesops**************** INFO:fidesops.main:Running any pending DB migrations... INFO:alembic.runtime.migration:Context impl PostgresqlImpl. INFO:alembic.runtime.migration:Will assume transactional DDL. INFO:fidesops.main:Starting scheduled request intake... INFO:apscheduler.scheduler:Scheduler started INFO:fidesops.main:Starting web server... INFO:uvicorn.error:Started server process [1] INFO:uvicorn.error:Waiting for application startup. INFO:uvicorn.error:Application startup complete. INFO:uvicorn.error:Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit) Or if you prefer to create your .env file and pass an --env-file variable, you can use the following: 1 2 3 4 docker run \\ -p 8080:8080 \\ --env-file=<ENV FILE NAME>.env \\ ethyca/fidesops Now, for most Docker hosts, you won't be calling docker run directly, and instead will be providing configuration variables to Kubernetes/Swarm/ECS/etc. As you can see in the docker run example above, this config is quite minimal and should just involve specifying (1) the image, (2) the port mapping, (3) all the various environment variables for configuration. Note that there's no need for a persistent volume mount for the web server, it's fully ephemeral and relies on the database for all it's permanent state.","title":"Install fidesops via Docker"},{"location":"deployment/#test-the-web-server","text":"To test that your server is running, visit http://{server_url}/health in your browser (e.g. http://0.0.0.0:8080/health) and you should see { \"healthy\": true } . You now have a functional fidesops server running! Now you can use the API to set up your OAuth clients, connect to databases, configure policies, execute privacy requests, etc. To learn more, head to the How-To Guides for details.","title":"Test the Web Server"},{"location":"ethyca/","text":"About Ethyca The mission of Ethyca is to make Internet-scale technology respectful and ethical. We're a venture-backed privacy technology team headquartered in New York, but working as a distributed team across the US to solve what we believe is the most important problem in technology today: the human right to privacy in vastly complex data-driven systems. What is Fides? Fides is a universally understandable, open-source language that can be used to describe privacy within tech infrastructure. Our existing tools ( Fidesctl and Fidesops ) use this language to power a low friction set of developer tools that integrate with your existing CI pipelines, making privacy a feature of your tech stack. With Fides, we hope everyone can build better tools for privacy in the next decade and beyond. What we Believe Data privacy is a human right that should be a native feature of any respectful technology. Today building great privacy as a feature in software is friction-filled and complicated. We're building open-source privacy tools for the developer community because we believe the only way to achieve a respectful internet is to make privacy an easy-to-implement layer of any tech stack. The Future We've been working on this problem since 2018 and have a clear view of our next five years. We're excited about the roadmap of features we'll add to Fides in order to make it the comprehensive tool for addressing the major challenges of privacy in both the code management and runtime environments. This means building solutions for automated privacy analysis, context rich data classification, automated data orchestration for privacy rights, semantic access control models, and more. We'd love you to contribute to Fides and you can do this directly as part of the open-source community. If you're interested in solving some of the toughest and most important problems facing internet scale data-driven software, join us now and get paid to work on this problem too! Your Participation Fides' success is predicated on your participation -- Privacy as Code can only become a reality if we ensure it's easy to understand, implement and an interoperable standard for wide adoption. Your feedback, contributions and improvements are encouraged as we work towards building a community with the sole objective of building more respectful software for everyone on the internet.","title":"About Ethyca"},{"location":"ethyca/#about-ethyca","text":"The mission of Ethyca is to make Internet-scale technology respectful and ethical. We're a venture-backed privacy technology team headquartered in New York, but working as a distributed team across the US to solve what we believe is the most important problem in technology today: the human right to privacy in vastly complex data-driven systems.","title":"About Ethyca"},{"location":"ethyca/#what-is-fides","text":"Fides is a universally understandable, open-source language that can be used to describe privacy within tech infrastructure. Our existing tools ( Fidesctl and Fidesops ) use this language to power a low friction set of developer tools that integrate with your existing CI pipelines, making privacy a feature of your tech stack. With Fides, we hope everyone can build better tools for privacy in the next decade and beyond.","title":"What is Fides?"},{"location":"ethyca/#what-we-believe","text":"Data privacy is a human right that should be a native feature of any respectful technology. Today building great privacy as a feature in software is friction-filled and complicated. We're building open-source privacy tools for the developer community because we believe the only way to achieve a respectful internet is to make privacy an easy-to-implement layer of any tech stack.","title":"What we Believe"},{"location":"ethyca/#the-future","text":"We've been working on this problem since 2018 and have a clear view of our next five years. We're excited about the roadmap of features we'll add to Fides in order to make it the comprehensive tool for addressing the major challenges of privacy in both the code management and runtime environments. This means building solutions for automated privacy analysis, context rich data classification, automated data orchestration for privacy rights, semantic access control models, and more. We'd love you to contribute to Fides and you can do this directly as part of the open-source community. If you're interested in solving some of the toughest and most important problems facing internet scale data-driven software, join us now and get paid to work on this problem too!","title":"The Future"},{"location":"ethyca/#your-participation","text":"Fides' success is predicated on your participation -- Privacy as Code can only become a reality if we ensure it's easy to understand, implement and an interoperable standard for wide adoption. Your feedback, contributions and improvements are encouraged as we work towards building a community with the sole objective of building more respectful software for everyone on the internet.","title":"Your Participation"},{"location":"glossary/","text":"Glossary of Key Terms Fidesops terms Privacy Request : A Privacy Request is a Fidesops representation of what is more widely known as a Data Subject Request, or Data Subject Access Request. access request: The customer wants to see the data an organization has collected about them. erasure request: The customer wants an organization to delete the data they have collected about them. Policy : Different from a Fidesctl Policy, this is a configuration that describes how to handle a Privacy Request. For example, you might define a simple policy that when given an email, it locates all the related data the customer has provided to you, and upload that to a specific S3 bucket. ConnectionConfig : A configuration for how to connect a database to Fidesops, so it can retrieve or remove customer data. DatasetConfig : A resource that contains a Fidesctl Dataset (the annotation of a database schema) and its related ConnectionConfig StorageConfig : A configuration for where the customer's data is going to be sent after an access request. MaskingStrategy : A configuration for how to erase customer data - for example, you might replace a customer's email with a random string. Identity : A piece of information used to uniquely identify an individual, like an email or a phone number. Identity Graph : A mapping that knows where personal data lives and how to look it up. For example, you might have photos stored in a MySQL database and customer information stored in a PostgreSQL database. The identity graph might say to get the customer id from the PostgreSQL database, and use that to look up the customer's photo in the MySQL database. Traversal : Created from an identity and an identity graph. In short, it says here's the first table I'm going to visit, I'm going to get this Field, cache it, and then use that to get this information from the next Collection, and so on. PolicyPreWebhook : Webhooks configured on a Policy to be triggered before a PrivacyRequest is executed. PolicyPostWebhook : Webhooks configured on a Policy to be triggered after a PrivacyRequest is executed. Database terms: Datasets - Resources at the database level. Datasets can have many Collections. Collections - A table, or a Collection of related data. Collections can have many Fields. Fields - Attributes on Collections. Fidesctl terms See the Fidesctl repo for more information, but here's some Fidesctl terms that might be helpful in Fidesops. Manifest : YAML files that describe different types of objects within Fides, with a high-level \"privacy as code\" language. Policy : Different from a Fidesops Policy, this controls what kinds of data you are permitted to commit to source code. For example, you might create a fidesctl policy that says, I am not going to allow any System that takes in provided contact information and uses it for marketing purposes. Dataset : An annotation of a database schema, which describes the Collections in a database, the Fields, the Data Categories of those fields, and the relationships between relevant Collections. System : Systems represent the applications, services, integrations, and any software that processes data for a specific use case. Privacy Data Types: Data Category - What kind of data is it? For example, the Data Category user.provided.identifiable includes things like contact email and street address. Data Use - Why is it being used? For example, for advertising or to improve the system. Data Subject - Whose data is it? For example, a customer . Data Qualifier - How is the data being protected? For example, it might be aggregated .","title":"Glossary"},{"location":"glossary/#glossary-of-key-terms","text":"","title":"Glossary of Key Terms"},{"location":"glossary/#fidesops-terms","text":"Privacy Request : A Privacy Request is a Fidesops representation of what is more widely known as a Data Subject Request, or Data Subject Access Request. access request: The customer wants to see the data an organization has collected about them. erasure request: The customer wants an organization to delete the data they have collected about them. Policy : Different from a Fidesctl Policy, this is a configuration that describes how to handle a Privacy Request. For example, you might define a simple policy that when given an email, it locates all the related data the customer has provided to you, and upload that to a specific S3 bucket. ConnectionConfig : A configuration for how to connect a database to Fidesops, so it can retrieve or remove customer data. DatasetConfig : A resource that contains a Fidesctl Dataset (the annotation of a database schema) and its related ConnectionConfig StorageConfig : A configuration for where the customer's data is going to be sent after an access request. MaskingStrategy : A configuration for how to erase customer data - for example, you might replace a customer's email with a random string. Identity : A piece of information used to uniquely identify an individual, like an email or a phone number. Identity Graph : A mapping that knows where personal data lives and how to look it up. For example, you might have photos stored in a MySQL database and customer information stored in a PostgreSQL database. The identity graph might say to get the customer id from the PostgreSQL database, and use that to look up the customer's photo in the MySQL database. Traversal : Created from an identity and an identity graph. In short, it says here's the first table I'm going to visit, I'm going to get this Field, cache it, and then use that to get this information from the next Collection, and so on. PolicyPreWebhook : Webhooks configured on a Policy to be triggered before a PrivacyRequest is executed. PolicyPostWebhook : Webhooks configured on a Policy to be triggered after a PrivacyRequest is executed. Database terms: Datasets - Resources at the database level. Datasets can have many Collections. Collections - A table, or a Collection of related data. Collections can have many Fields. Fields - Attributes on Collections.","title":"Fidesops terms"},{"location":"glossary/#fidesctl-terms","text":"See the Fidesctl repo for more information, but here's some Fidesctl terms that might be helpful in Fidesops. Manifest : YAML files that describe different types of objects within Fides, with a high-level \"privacy as code\" language. Policy : Different from a Fidesops Policy, this controls what kinds of data you are permitted to commit to source code. For example, you might create a fidesctl policy that says, I am not going to allow any System that takes in provided contact information and uses it for marketing purposes. Dataset : An annotation of a database schema, which describes the Collections in a database, the Fields, the Data Categories of those fields, and the relationships between relevant Collections. System : Systems represent the applications, services, integrations, and any software that processes data for a specific use case. Privacy Data Types: Data Category - What kind of data is it? For example, the Data Category user.provided.identifiable includes things like contact email and street address. Data Use - Why is it being used? For example, for advertising or to improve the system. Data Subject - Whose data is it? For example, a customer . Data Qualifier - How is the data being protected? For example, it might be aggregated .","title":"Fidesctl terms"},{"location":"license/","text":"1 2 3 Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. 1 2 3 4 5 6 7 8 To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright [yyyy] [name of copyright owner] Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at 1 http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"use_cases/","text":"Use Cases The world of privacy is changing quickly and so is your organization's technology stack. Fidesops can help you become compliant with data privacy regulation, as well as help to manage ongoing privacy operations for your company. Privacy Request Management Under various data privacy laws, like the General Data Protection Regulations (GDPR), California Consumer Protection Act (CCPA), or Brazil's LGPD, consumers have the right to request for you to delete or return their personal data to them within a desginated timeframe. Your organization is likely already receiving \"Privacy Requests\", which are also known as: Data Subject Requests (DSR) Data Subject Access Request (DSAR) Right to be forgotten (RTBF) Request to Delete Right to Access Request to Know Request to Opt-In or Opt-Out It's possible you may not know what these are until you're expected to fulfill a request like this. However, your customer support team and your legal and privacy team are probably very familiar with these requests because they generally come in through support channels via email. Generally, the team responsible for fulfilling these requests is a combination of product engineering, marketing, legal, and sales because your organization has customer data stored in so many locations. Fidesops helps to automate the execution of these privacy requests by 1) accepting and responding to privacy requests from an application of your choosing, 2) connecting directly to your datasets and 3) retrieving and/or updating data in those datasets. Data Inventory Because Fidesops connects directly to your datasets, it is easy to maintain a record of where you're storing personally identifiable data and other potentially sensitive data types. Keeping this updated data inventory helps reduce risk for your organization by making it simple to provide a full auditable report of your data ecosystem. Targeted or Bulk Data Anonymization As machine learning models require more and more data, your organization may decide to remove certain sensitive data from a dataset to be used for analytics purposes. Fidesops allows you to create a custom policy to anonymize data for any use. For example, you can pseudonymize just the email address field with a consistent hash both within a database or between different databases using deterministic pseudonymization ; this way, the email address will have the same hashed value across datasets, which will maintain referential integrity for your analytics reports and dashboards.","title":"Use Cases"},{"location":"use_cases/#use-cases","text":"The world of privacy is changing quickly and so is your organization's technology stack. Fidesops can help you become compliant with data privacy regulation, as well as help to manage ongoing privacy operations for your company.","title":"Use Cases"},{"location":"use_cases/#privacy-request-management","text":"Under various data privacy laws, like the General Data Protection Regulations (GDPR), California Consumer Protection Act (CCPA), or Brazil's LGPD, consumers have the right to request for you to delete or return their personal data to them within a desginated timeframe. Your organization is likely already receiving \"Privacy Requests\", which are also known as: Data Subject Requests (DSR) Data Subject Access Request (DSAR) Right to be forgotten (RTBF) Request to Delete Right to Access Request to Know Request to Opt-In or Opt-Out It's possible you may not know what these are until you're expected to fulfill a request like this. However, your customer support team and your legal and privacy team are probably very familiar with these requests because they generally come in through support channels via email. Generally, the team responsible for fulfilling these requests is a combination of product engineering, marketing, legal, and sales because your organization has customer data stored in so many locations. Fidesops helps to automate the execution of these privacy requests by 1) accepting and responding to privacy requests from an application of your choosing, 2) connecting directly to your datasets and 3) retrieving and/or updating data in those datasets.","title":"Privacy Request Management"},{"location":"use_cases/#data-inventory","text":"Because Fidesops connects directly to your datasets, it is easy to maintain a record of where you're storing personally identifiable data and other potentially sensitive data types. Keeping this updated data inventory helps reduce risk for your organization by making it simple to provide a full auditable report of your data ecosystem.","title":"Data Inventory"},{"location":"use_cases/#targeted-or-bulk-data-anonymization","text":"As machine learning models require more and more data, your organization may decide to remove certain sensitive data from a dataset to be used for analytics purposes. Fidesops allows you to create a custom policy to anonymize data for any use. For example, you can pseudonymize just the email address field with a consistent hash both within a database or between different databases using deterministic pseudonymization ; this way, the email address will have the same hashed value across datasets, which will maintain referential integrity for your analytics reports and dashboards.","title":"Targeted or Bulk Data Anonymization"},{"location":"api/","text":"API Reference You can view the live, interactive Swagger API docs for Fidesops by visiting /docs on a running instance. This is a great way to experiment with the APIs using Swagger's built-in \"Try it out\" functionality. Additionally, you can download our Fidesops Postman Collection and follow instructions to set up on your machine . Below, we've embedded the latest release's API documentation as a living reference. These work largely the same, but since this documentation site isn't connected to a live instance, the \"Try it out\" and \"Authorize\" buttons won't work, sorry! Swagger API Docs const ui = SwaggerUIBundle({ url: 'openapi.json', dom_id: '#swagger-ui', }) /* If there is an anchor tag, reload it after the page loads to scroll to * that section, since the Swagger UI takes some time to render. */ if (location.hash) { setTimeout(function() { location.href = location.href }, 200); }","title":"API"},{"location":"api/#api-reference","text":"You can view the live, interactive Swagger API docs for Fidesops by visiting /docs on a running instance. This is a great way to experiment with the APIs using Swagger's built-in \"Try it out\" functionality. Additionally, you can download our Fidesops Postman Collection and follow instructions to set up on your machine . Below, we've embedded the latest release's API documentation as a living reference. These work largely the same, but since this documentation site isn't connected to a live instance, the \"Try it out\" and \"Authorize\" buttons won't work, sorry!","title":"API Reference"},{"location":"api/#swagger-api-docs","text":"const ui = SwaggerUIBundle({ url: 'openapi.json', dom_id: '#swagger-ui', }) /* If there is an anchor tag, reload it after the page loads to scroll to * that section, since the Swagger UI takes some time to render. */ if (location.hash) { setTimeout(function() { location.href = location.href }, 200); }","title":"Swagger API Docs"},{"location":"community/code_of_conduct/","text":"Fides Code of Conduct Our Pledge In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct that could reasonably be considered inappropriate in a professional setting Our Responsibilities Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope This Code of Conduct applies within all project spaces, and it also applies when an individual is representing the project or its community in public spaces. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the Fides core team at fides@ethyca.com . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Code of Conduct"},{"location":"community/code_of_conduct/#fides-code-of-conduct","text":"","title":"Fides Code of Conduct"},{"location":"community/code_of_conduct/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"community/code_of_conduct/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct that could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"community/code_of_conduct/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"community/code_of_conduct/#scope","text":"This Code of Conduct applies within all project spaces, and it also applies when an individual is representing the project or its community in public spaces. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"community/code_of_conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the Fides core team at fides@ethyca.com . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"community/code_of_conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Attribution"},{"location":"community/github/","text":"Community The Fides project welcomes issues, contributions and discussion from all users, regardless of background or experience level. In order to create a positive and welcoming environment, all interactions are governed by the Fides Code of Conduct . GitHub We have a public GitHub Repo for development and collaboration. GitHub Guidelines Whether it's giving us feedback, raising a question, or showing your Fides-related work, we are looking forward to hearing from you. The Fides community is vibrant because of the quality of its members and the discussions they bring. To keep the workspace inviting and helpful for everyone, there are a few guidelines that we ask all members to follow. Rule 1: Assume Positive Intent Being nice is the most important pillar of the Fides community. We are considerate to each other's effort and time. It's also easy to misinterpret people through Slack, so we make an extra effort to chat in a positive tone. We assume that you are here to learn and exchange ideas, and we ask that you contribute to making a welcoming community. If someone is helping you, be mindful of the effort they are putting in. While we are always happy to help users, we can not help users with step-by-step debugging. Use your professional judgment in discerning whether requests are unreasonable. The Fides team always tries to listen to the community. Please be understanding if your issue or feature request is not deemed an immediate priority. Rule 2: Use threads for larger messages Because of the size of our community and frequency of posts, it's easy for large messages to drown out smaller messages. Using threads helps people see more messages on their screen. Larger code blocks should be posted in threads. Rule 3: Avoid posting sensitive information Community members sometimes need to post code snippets as they ask for help. Be sure to remove sensitive information from posts to the public channels. If your Fides account information is needed to help you, we will ask you to direct message such information. Be cautious of anyone asking for information through direct messages. Rule 4: Write high quality questions The Fides community is here to support you. That said, it is significantly easier to answer well-researched and clearly-written questions. Even adding potentially relevant links to a post helps tremendously. Informative Slack threads are archived by our resident bot Marvin. Having well-written threads helps future users encountering the same problem. Oftentimes your question may have been answered somewhere else; some good resources to start looking before asking a question: Fides Documentation GitHub Issues StackOverflow Rule 5: Don't abuse tagging users Requests for help will be seen by the Fides team, and will be directed to the appropriate person. Tagging individual users is highly discouraged unless it is in the context of a conversation thread. Rule 6: Avoid using DMs to ask for help Fides employees should not be sent questions in DMs unless we specifically ask you to send us private information. There are times when it makes sense to directly message another community member experiencing a similar issue, or working with similar technologies. Just be aware that some people may not want to be messaged. It also helps other people if you post your question publicly. Similar to above, informative Slack threads are archived. Having conversations in public channels drives better quality discussions that can be referenced in the future. Rule 7: Don't advertise material unrelated to Fides Our community is in the channel to learn more about Fides. Showing us Fides-related stuff that you're working on is highly encouraged. Advertising products and events unrelated to Fides will be removed.","title":"GitHub"},{"location":"community/github/#community","text":"The Fides project welcomes issues, contributions and discussion from all users, regardless of background or experience level. In order to create a positive and welcoming environment, all interactions are governed by the Fides Code of Conduct .","title":"Community"},{"location":"community/github/#github","text":"We have a public GitHub Repo for development and collaboration.","title":"GitHub"},{"location":"community/github/#github-guidelines","text":"Whether it's giving us feedback, raising a question, or showing your Fides-related work, we are looking forward to hearing from you. The Fides community is vibrant because of the quality of its members and the discussions they bring. To keep the workspace inviting and helpful for everyone, there are a few guidelines that we ask all members to follow.","title":"GitHub Guidelines"},{"location":"community/github/#rule-1-assume-positive-intent","text":"Being nice is the most important pillar of the Fides community. We are considerate to each other's effort and time. It's also easy to misinterpret people through Slack, so we make an extra effort to chat in a positive tone. We assume that you are here to learn and exchange ideas, and we ask that you contribute to making a welcoming community. If someone is helping you, be mindful of the effort they are putting in. While we are always happy to help users, we can not help users with step-by-step debugging. Use your professional judgment in discerning whether requests are unreasonable. The Fides team always tries to listen to the community. Please be understanding if your issue or feature request is not deemed an immediate priority.","title":"Rule 1: Assume Positive Intent"},{"location":"community/github/#rule-2-use-threads-for-larger-messages","text":"Because of the size of our community and frequency of posts, it's easy for large messages to drown out smaller messages. Using threads helps people see more messages on their screen. Larger code blocks should be posted in threads.","title":"Rule 2: Use threads for larger messages"},{"location":"community/github/#rule-3-avoid-posting-sensitive-information","text":"Community members sometimes need to post code snippets as they ask for help. Be sure to remove sensitive information from posts to the public channels. If your Fides account information is needed to help you, we will ask you to direct message such information. Be cautious of anyone asking for information through direct messages.","title":"Rule 3: Avoid posting sensitive information"},{"location":"community/github/#rule-4-write-high-quality-questions","text":"The Fides community is here to support you. That said, it is significantly easier to answer well-researched and clearly-written questions. Even adding potentially relevant links to a post helps tremendously. Informative Slack threads are archived by our resident bot Marvin. Having well-written threads helps future users encountering the same problem. Oftentimes your question may have been answered somewhere else; some good resources to start looking before asking a question: Fides Documentation GitHub Issues StackOverflow","title":"Rule 4: Write high quality questions"},{"location":"community/github/#rule-5-dont-abuse-tagging-users","text":"Requests for help will be seen by the Fides team, and will be directed to the appropriate person. Tagging individual users is highly discouraged unless it is in the context of a conversation thread.","title":"Rule 5: Don't abuse tagging users"},{"location":"community/github/#rule-6-avoid-using-dms-to-ask-for-help","text":"Fides employees should not be sent questions in DMs unless we specifically ask you to send us private information. There are times when it makes sense to directly message another community member experiencing a similar issue, or working with similar technologies. Just be aware that some people may not want to be messaged. It also helps other people if you post your question publicly. Similar to above, informative Slack threads are archived. Having conversations in public channels drives better quality discussions that can be referenced in the future.","title":"Rule 6: Avoid using DMs to ask for help"},{"location":"community/github/#rule-7-dont-advertise-material-unrelated-to-fides","text":"Our community is in the channel to learn more about Fides. Showing us Fides-related stuff that you're working on is highly encouraged. Advertising products and events unrelated to Fides will be removed.","title":"Rule 7: Don't advertise material unrelated to Fides"},{"location":"development/code_style/","text":"Code Style Black formatting Fides's code is formatted using the black style. This style is checked in a CI step, and merges to master are prevented if code does not conform. To apply black to your code, run black from the root Fidesops directory: 1 2 cd fidesops black . A number of extensions are available for popular editors that will automatically apply black to your code. Pylint Fides's code is linted using pylint . Linter checks run as part of a CI step and merges to master are prevented if code does not conform. To apply pylint to your code, run pylint from the root Fidesops directory: 1 2 cd fidesops pylint src Mypy typing Fides's code is statically-typed using mypy . Type checking is validated as a CI step, and merges to master are prevented if code does not pass type checks. As a general rule, mypy typing requires all function arguments and return values to be annotated. 1 2 cd fidesops mypy src","title":"Code Style"},{"location":"development/code_style/#code-style","text":"","title":"Code Style"},{"location":"development/code_style/#black-formatting","text":"Fides's code is formatted using the black style. This style is checked in a CI step, and merges to master are prevented if code does not conform. To apply black to your code, run black from the root Fidesops directory: 1 2 cd fidesops black . A number of extensions are available for popular editors that will automatically apply black to your code.","title":"Black formatting"},{"location":"development/code_style/#pylint","text":"Fides's code is linted using pylint . Linter checks run as part of a CI step and merges to master are prevented if code does not conform. To apply pylint to your code, run pylint from the root Fidesops directory: 1 2 cd fidesops pylint src","title":"Pylint"},{"location":"development/code_style/#mypy-typing","text":"Fides's code is statically-typed using mypy . Type checking is validated as a CI step, and merges to master are prevented if code does not pass type checks. As a general rule, mypy typing requires all function arguments and return values to be annotated. 1 2 cd fidesops mypy src","title":"Mypy typing"},{"location":"development/documentation/","text":"Documentation Documentation is incredibly important to Fides, both for explaining its concepts to general audiences and describing its usage to developers. Concepts Fides includes a great deal of \"concept\" documentation, which covers features, tutorials, guides, and examples separately from the auto-generated API reference. This page is part of the concept documentation for development! To write concept docs, add Markdown files to the docs/fidesops/docs/ directory (or one of its subdirectories). To ensure that your page is displayed in the navigation, edit mkdocs.yml to include a reference to it. Semantics Capitalization Concepts that refer to proper nouns or are trademarked should always be capitalized, including \"Fides\" and \"Fidesops\". Other Fides terms, like \"Data Category\" or \"System\", should also be capitalized to be clear about the fact that a Fides resource is being referenced. When a System is applied, it is either created or updated through the FidesAPI. The System model requires a field called fides_key . Previewing docs locally Documentation (including both concepts and API references) is built and deployed with every merge to Fides's master branch. If you're using VS Code Dev Containers, the docs will automatically be available at localhost:8000 , otherwise you'll need to run the following command: 1 make docs-serve You'll see a status update as the docs build, and then an announcement that they are available on http://127.0.0.1:8000 .","title":"Documentation"},{"location":"development/documentation/#documentation","text":"Documentation is incredibly important to Fides, both for explaining its concepts to general audiences and describing its usage to developers.","title":"Documentation"},{"location":"development/documentation/#concepts","text":"Fides includes a great deal of \"concept\" documentation, which covers features, tutorials, guides, and examples separately from the auto-generated API reference. This page is part of the concept documentation for development! To write concept docs, add Markdown files to the docs/fidesops/docs/ directory (or one of its subdirectories). To ensure that your page is displayed in the navigation, edit mkdocs.yml to include a reference to it.","title":"Concepts"},{"location":"development/documentation/#semantics","text":"","title":"Semantics"},{"location":"development/documentation/#capitalization","text":"Concepts that refer to proper nouns or are trademarked should always be capitalized, including \"Fides\" and \"Fidesops\". Other Fides terms, like \"Data Category\" or \"System\", should also be capitalized to be clear about the fact that a Fides resource is being referenced. When a System is applied, it is either created or updated through the FidesAPI. The System model requires a field called fides_key .","title":"Capitalization"},{"location":"development/documentation/#previewing-docs-locally","text":"Documentation (including both concepts and API references) is built and deployed with every merge to Fides's master branch. If you're using VS Code Dev Containers, the docs will automatically be available at localhost:8000 , otherwise you'll need to run the following command: 1 make docs-serve You'll see a status update as the docs build, and then an announcement that they are available on http://127.0.0.1:8000 .","title":"Previewing docs locally"},{"location":"development/overview/","text":"Development Overview Thanks for contributing to Fidesops! This section of the docs is designed to help you become familiar with how we work, the standards we apply, and how to ensure your contribution is successful. If you're stuck, don't be shy about asking for help on GitHub . Getting Started with Fidesops in Docker The recommended way to run Fidesops is to launch it with Docker and Docker Compose. Make commands wrap docker-compose commands to give you different functionality. System Requirements Install Docker: https://docs.docker.com/desktop/#download-and-install Install make locally (see Make on Homebrew (Mac), Make for Windows, or your preferred installation) brew install make Create a fork of fidesops Clone your fork git clone https://github.com/<your-fork-location>/fidesops.git cd fidesops Available make commands make server - this spins up the Fastapi server and supporting resources (a Postgres database and a Redis cache), which you can visit at http://0.0.0.0:8080 . Check out the docs at http://0.0.0.0:8000/fidesops/ make integration-env - spins up everything in make server, plus additional postgres, mongo, and mysql databases for you to execute privacy requests against. Try this out locally with our Fidesops Postman Collection make integration-shell - spins up everything in make server, plus all Docker Compose specified datastores (Postgres, MySQL, MSSQL, Mongodb) and opens a server shell. This is most useful for running pytest -k ... commands within the integration shell to test connected datastores. make black , make mypy , and make pylint - auto-formats code make check-all - runs the CI checks locally and verifies that your code meets project standards make server-shell - opens a shell on the Docker container, from here you can run useful commands like: ipython - open a Python shell make pytest - runs all unit tests except those that talk to integration databases make pytest-integration - runs access integration tests. make pytest-integration datastores=\"postgres snowflake mssql\" - runs access integration tests for the Postgres, Snowflake and MSSQL environments. make pytest-integration-erasure - runs erasure integration tests. make reset-db - tears down the Fideops postgres db, then recreates and re-runs migrations. make quickstart - runs a quick, five second quickstart that talks to the Fidesops API to execute privacy requests make check-migrations - verifies there are no un-run migrations make docs-serve - spins up just the docs See Makefile for more options. Issues MSSQL: Known issues around connecting to MSSQL exist today for Apple M1 users. M1 users that wish to install pyodbc locally, please reference the workaround here . Package not found: When running make server , if you get a importlib.metadata.PackageNotFoundError: fidesops , do make server-shell , and then run pip install -e . . Verify Fidesops is installed with pip list . Write your code We have no doubt you can write amazing code! However, we want to help you ensure your code plays nicely with the rest of the Fidesops ecosystem. Many projects describe code style and documentation as a suggestion; in Fidesops it's a CI-checked requirement. To learn how to style your code, see the style guide . To learn how to document your code, see the docs guide . To learn how to test your code, see the tests guide . To learn what format your PR should follow, make sure to follow the pull request guidelines . Submit your code In order to submit code to Fidesops, please: Fork the Fidesops repository Add the original as a remote (I'm naming it upstream ), to keep your fork in sync 1 git remote add upstream https://github.com/ethyca/fidesops.git Create a new branch on your fork bash git checkout main git fetch upstream git merge upstream/main git push origin main git checkout -b my-new-branch git push origin my-new-branch Open a Pull Request once your work is ready for review Submit the pull request from your repo Once automated tests have passed, a maintainer will review your PR and provide feedback on any changes it requires to be approved. Once approved, your PR will be merged into Fidesops. Congratulations You're a Fidesops contributor - welcome to the team! \ud83c\udf89","title":"Overview"},{"location":"development/overview/#development-overview","text":"Thanks for contributing to Fidesops! This section of the docs is designed to help you become familiar with how we work, the standards we apply, and how to ensure your contribution is successful. If you're stuck, don't be shy about asking for help on GitHub .","title":"Development Overview"},{"location":"development/overview/#getting-started-with-fidesops-in-docker","text":"The recommended way to run Fidesops is to launch it with Docker and Docker Compose. Make commands wrap docker-compose commands to give you different functionality.","title":"Getting Started with Fidesops in Docker"},{"location":"development/overview/#system-requirements","text":"Install Docker: https://docs.docker.com/desktop/#download-and-install Install make locally (see Make on Homebrew (Mac), Make for Windows, or your preferred installation) brew install make Create a fork of fidesops Clone your fork git clone https://github.com/<your-fork-location>/fidesops.git cd fidesops","title":"System Requirements"},{"location":"development/overview/#available-make-commands","text":"make server - this spins up the Fastapi server and supporting resources (a Postgres database and a Redis cache), which you can visit at http://0.0.0.0:8080 . Check out the docs at http://0.0.0.0:8000/fidesops/ make integration-env - spins up everything in make server, plus additional postgres, mongo, and mysql databases for you to execute privacy requests against. Try this out locally with our Fidesops Postman Collection make integration-shell - spins up everything in make server, plus all Docker Compose specified datastores (Postgres, MySQL, MSSQL, Mongodb) and opens a server shell. This is most useful for running pytest -k ... commands within the integration shell to test connected datastores. make black , make mypy , and make pylint - auto-formats code make check-all - runs the CI checks locally and verifies that your code meets project standards make server-shell - opens a shell on the Docker container, from here you can run useful commands like: ipython - open a Python shell make pytest - runs all unit tests except those that talk to integration databases make pytest-integration - runs access integration tests. make pytest-integration datastores=\"postgres snowflake mssql\" - runs access integration tests for the Postgres, Snowflake and MSSQL environments. make pytest-integration-erasure - runs erasure integration tests. make reset-db - tears down the Fideops postgres db, then recreates and re-runs migrations. make quickstart - runs a quick, five second quickstart that talks to the Fidesops API to execute privacy requests make check-migrations - verifies there are no un-run migrations make docs-serve - spins up just the docs See Makefile for more options.","title":"Available make commands"},{"location":"development/overview/#issues","text":"MSSQL: Known issues around connecting to MSSQL exist today for Apple M1 users. M1 users that wish to install pyodbc locally, please reference the workaround here . Package not found: When running make server , if you get a importlib.metadata.PackageNotFoundError: fidesops , do make server-shell , and then run pip install -e . . Verify Fidesops is installed with pip list .","title":"Issues"},{"location":"development/overview/#write-your-code","text":"We have no doubt you can write amazing code! However, we want to help you ensure your code plays nicely with the rest of the Fidesops ecosystem. Many projects describe code style and documentation as a suggestion; in Fidesops it's a CI-checked requirement. To learn how to style your code, see the style guide . To learn how to document your code, see the docs guide . To learn how to test your code, see the tests guide . To learn what format your PR should follow, make sure to follow the pull request guidelines .","title":"Write your code"},{"location":"development/overview/#submit-your-code","text":"In order to submit code to Fidesops, please: Fork the Fidesops repository Add the original as a remote (I'm naming it upstream ), to keep your fork in sync 1 git remote add upstream https://github.com/ethyca/fidesops.git Create a new branch on your fork bash git checkout main git fetch upstream git merge upstream/main git push origin main git checkout -b my-new-branch git push origin my-new-branch Open a Pull Request once your work is ready for review Submit the pull request from your repo Once automated tests have passed, a maintainer will review your PR and provide feedback on any changes it requires to be approved. Once approved, your PR will be merged into Fidesops.","title":"Submit your code"},{"location":"development/overview/#congratulations","text":"You're a Fidesops contributor - welcome to the team! \ud83c\udf89","title":"Congratulations"},{"location":"development/pull_requests/","text":"Pull Requests Pull Requests are the primary unit of work within the Fides project. All code changes are expected to be submitted via a PR, and as such here are a few requirements for submitting PRs: Completely fill out the provided pull request template If you're unsure about a potential feature implementation or there is anything else that needs discussing, feel free to ask for an early review/feedback in the comments of the PR. Make sure that all checks are passing and all boxes have been checked before passing it off to a reviewer for a final approval. PR reviews require other people to spend their time, so please be courteous and double-check your work before passing it to a reviewer. If there is a bug in a PR, fix it within that PR, do not create another PR to fix a bug in a separate PR.","title":"Pull Requests"},{"location":"development/pull_requests/#pull-requests","text":"Pull Requests are the primary unit of work within the Fides project. All code changes are expected to be submitted via a PR, and as such here are a few requirements for submitting PRs: Completely fill out the provided pull request template If you're unsure about a potential feature implementation or there is anything else that needs discussing, feel free to ask for an early review/feedback in the comments of the PR. Make sure that all checks are passing and all boxes have been checked before passing it off to a reviewer for a final approval. PR reviews require other people to spend their time, so please be courteous and double-check your work before passing it to a reviewer. If there is a bug in a PR, fix it within that PR, do not create another PR to fix a bug in a separate PR.","title":"Pull Requests"},{"location":"development/release_checklist/","text":"Release Checklist Documentation [ ] Quickstart verified working and up-to-date [ ] Tutorial verified working and up-to-date [ ] Fidesdemo verified working and up-to-date [ ] New/updated API endpoints described in the Guides [ ] New/updated API endpoints included in the Postman collections [ ] New tables/columns added to database diagram","title":"Release Checklist"},{"location":"development/release_checklist/#release-checklist","text":"","title":"Release Checklist"},{"location":"development/release_checklist/#documentation","text":"[ ] Quickstart verified working and up-to-date [ ] Tutorial verified working and up-to-date [ ] Fidesdemo verified working and up-to-date [ ] New/updated API endpoints described in the Guides [ ] New/updated API endpoints included in the Postman collections [ ] New tables/columns added to database diagram","title":"Documentation"},{"location":"development/releases/","text":"Releases Fides uses semantic versioning. Each release version has a corresponding GitHub Project assigned to it. Issues are then assigned to them as a way to determine what new features/bug fixes will be included in each release. When a release project is complete, a new version is cut using GitHub's release page here . This will trigger a GitHub Action that pushes the new version to PyPi. Hotfixes are an exception to this and can be added and pushed mid-release as needed.","title":"Releases"},{"location":"development/releases/#releases","text":"Fides uses semantic versioning. Each release version has a corresponding GitHub Project assigned to it. Issues are then assigned to them as a way to determine what new features/bug fixes will be included in each release. When a release project is complete, a new version is cut using GitHub's release page here . This will trigger a GitHub Action that pushes the new version to PyPi. Hotfixes are an exception to this and can be added and pushed mid-release as needed.","title":"Releases"},{"location":"development/testing/","text":"Testing Fides loves tests! There are a few important reasons to write tests: Make sure your code works when it's supposed to Tests ensure that your code does the thing you intend it to do. If you have a function that adds two numbers, you'll want to test that it does, in fact, return their sum. If behavior depends on a configuration setting, ensure that changing that setting changes the behavior. In short, if you wrote a line of code, you should test that line works as expected. Make sure your code doesn't work when it's not supposed to It may seem silly, but another important reason to write tests is to ensure that your code behaves as expected even when it's broken . This is especially important for a project like Fides, which is focused on helping engineers when something unexpected happens to their code. For example, you could write tests about what you expect to happen if your function is called with incorrect (or no) arguments, or to ensure that any errors are properly trapped and handled. Tests are documentation Ultimately, your tests are the best documentation for your code. Another developer should be able to look at your tests and understand what your code does, how to invoke it, and what edge cases it contains. Therefore, try to write short, self-explanatory tests with descriptive titles. Help future developers As Fides grows, your code will be reused in more and more places, by developers who may not be familiar with the details of your implementation. Therefore, your tests are an opportunity to ensure that your code is used correctly in the future. For example, if your code needs to be used in a certain way, or expects a certain configuration, or is always expected to return a certain output, or has any other details that might impact its ability to be used in the framework, write a test for it! At minimum, you'll help a future developer understand that you consciously chose to design your code a certain way. Writing tests Fides's tests are stored in the tests directory. Tests should have descriptive names that make it clear what you're testing. If necessary, add a docstring or comment to explain why you're testing this specific thing. 1 2 3 4 5 6 def test_dry_evaluate_system_fail ( server_url , resources_dict ): ... # bad test name def test_dry_evaluate (): ... Fidesops has a few pytest fixtures available for testing; see conftest.py for details. Running tests Fidesops uses pytest for unit testing. To run tests, invoke pytest from the root Fidesops directory: 1 2 cd fidesops pytest Running specific tests To run a subset of tests, provide a filename or directory; to match a specific test name, use the -k flag: 1 2 # run all tests in the tests/integration directory that contain the word \"api\" in their title pytest tests/integration/ -k api Debugging For debugging, we recommend installing the pdbpp package and running pytest with the --pdb flag (which will open the debugger on any error) or setting breakpoint() appropriately. Stepwise execution The --sw flag will exit pytest the first time it encounters an error; subsequent runs with the same flag will skip any tests that succeeded and run the failed test first. CI Workflows CI will run automatically against any PR you open. Please run your tests locally first to avoid \"debugging in CI\", as this takes up resources that could be used by other contributors.","title":"Testing"},{"location":"development/testing/#testing","text":"Fides loves tests! There are a few important reasons to write tests: Make sure your code works when it's supposed to Tests ensure that your code does the thing you intend it to do. If you have a function that adds two numbers, you'll want to test that it does, in fact, return their sum. If behavior depends on a configuration setting, ensure that changing that setting changes the behavior. In short, if you wrote a line of code, you should test that line works as expected. Make sure your code doesn't work when it's not supposed to It may seem silly, but another important reason to write tests is to ensure that your code behaves as expected even when it's broken . This is especially important for a project like Fides, which is focused on helping engineers when something unexpected happens to their code. For example, you could write tests about what you expect to happen if your function is called with incorrect (or no) arguments, or to ensure that any errors are properly trapped and handled. Tests are documentation Ultimately, your tests are the best documentation for your code. Another developer should be able to look at your tests and understand what your code does, how to invoke it, and what edge cases it contains. Therefore, try to write short, self-explanatory tests with descriptive titles. Help future developers As Fides grows, your code will be reused in more and more places, by developers who may not be familiar with the details of your implementation. Therefore, your tests are an opportunity to ensure that your code is used correctly in the future. For example, if your code needs to be used in a certain way, or expects a certain configuration, or is always expected to return a certain output, or has any other details that might impact its ability to be used in the framework, write a test for it! At minimum, you'll help a future developer understand that you consciously chose to design your code a certain way.","title":"Testing"},{"location":"development/testing/#writing-tests","text":"Fides's tests are stored in the tests directory. Tests should have descriptive names that make it clear what you're testing. If necessary, add a docstring or comment to explain why you're testing this specific thing. 1 2 3 4 5 6 def test_dry_evaluate_system_fail ( server_url , resources_dict ): ... # bad test name def test_dry_evaluate (): ... Fidesops has a few pytest fixtures available for testing; see conftest.py for details.","title":"Writing tests"},{"location":"development/testing/#running-tests","text":"Fidesops uses pytest for unit testing. To run tests, invoke pytest from the root Fidesops directory: 1 2 cd fidesops pytest","title":"Running tests"},{"location":"development/testing/#running-specific-tests","text":"To run a subset of tests, provide a filename or directory; to match a specific test name, use the -k flag: 1 2 # run all tests in the tests/integration directory that contain the word \"api\" in their title pytest tests/integration/ -k api","title":"Running specific tests"},{"location":"development/testing/#debugging","text":"For debugging, we recommend installing the pdbpp package and running pytest with the --pdb flag (which will open the debugger on any error) or setting breakpoint() appropriately.","title":"Debugging"},{"location":"development/testing/#stepwise-execution","text":"The --sw flag will exit pytest the first time it encounters an error; subsequent runs with the same flag will skip any tests that succeeded and run the failed test first.","title":"Stepwise execution"},{"location":"development/testing/#ci-workflows","text":"CI will run automatically against any PR you open. Please run your tests locally first to avoid \"debugging in CI\", as this takes up resources that could be used by other contributors.","title":"CI Workflows"},{"location":"development/update_erd_diagram/","text":"Updating database diagram If you make updates to the Fidesops application database, you should update our DB Architecture diagram in the documentation. Connect DBeaver to our app DB container DBeaver > Database > New Database Connection > PostgreSQL Add configuration details Right-click on postgres connection > Create > Other Select ER Diagram, Click Next Drill down to Postgres > app > Schemas > public and click the checkbox. Click Finish Drag and drop tables so they are less messy. File > Save As (img/app_database.png) Replace img/app_database.png with the new file","title":"Updating database diagram"},{"location":"development/update_erd_diagram/#updating-database-diagram","text":"If you make updates to the Fidesops application database, you should update our DB Architecture diagram in the documentation. Connect DBeaver to our app DB container DBeaver > Database > New Database Connection > PostgreSQL Add configuration details Right-click on postgres connection > Create > Other Select ER Diagram, Click Next Drill down to Postgres > app > Schemas > public and click the checkbox. Click Finish Drag and drop tables so they are less messy. File > Save As (img/app_database.png) Replace img/app_database.png with the new file","title":"Updating database diagram"},{"location":"guides/configuration_reference/","text":"Fidesops: Application Configuration Reference In this section we'll cover: How to configure the Fidesops application Configuration variable reference An example fidesops.toml configuration file Reporting a running application's configuration Take me directly to api docs . How to configure the Fidesops application The Fidesops application configuration variables are provided in the fidesops.toml file in .toml format. Fidesops will take the first config file it finds from the following locations: The location according to the FIDESOPS_CONFIG_PATH environment variable The current working directory ( ./fidesops.toml ) The parent of the current working directory ( ../fidesops.toml ) The user's home directory ( ~/fidesops.toml ) Fidesops is also able to be run exclusively from environment variables. For more information and examples, see Deployment . Configuration variable reference The fidesops.toml file should specify the following variables: TOML Variable ENV Variable Type Example Default Description SERVER FIDESOPS__DATABASE__SERVER string postgres.internal N/A The networking address for the Fideops Postgres database server USER FIDESOPS__DATABASE_USER string postgres N/A The database user with which to login to the Fidesops application database PASSWORD FIDESOPS__DATABASE_PASSWORD string apassword N/A The password with which to login to the Fidesops application database PORT FIDESOPS__DATABASE__PORT int 5432 5432 The port at which the Fidesops application database will be accessible DB FIDESOPS__DATABASE_DB string db N/A The name of the database to use in the Fidesops application database --- --- --- --- --- --- HOST FIDESOPS__REDIS__HOST string redis.internal N/A The networking address for the Fidesops application Redis cache PORT FIDESOPS__REDIS__PORT int 6379 6379 The port at which the Fidesops application cache will be accessible PASSWORD FIDESOPS__REDIS__PASSWORD string anotherpassword N/A The password with which to login to the Fidesops application cache DB_INDEX FIDESOPS__REDIS__DB_INDEX int 0 0 The Fidesops application will use this index in the Redis cache to cache data DEFAULT_TTL_SECONDS FIDESOPS__REDIS__DEFAULT_TTL_SECONDS int 3600 3600 The number of seconds for which data will live in Redis before automatically expiring --- --- --- --- --- --- APP_ENCRYPTION_KEY FIDESOPS__SECURITY__APP_ENCRYPTION_KEY string OLMkv91j8DHiDAULnK5Lxx3kSCov30b3 N/A The key used to sign Fidesops API access tokens CORS_ORIGINS FIDESOPS__SECURITY__CORS_ORIGINS List[AnyHttpUrl] [\"https://a-client.com/\", \"https://another-client.com\"/] N/A A list of pre-approved addresses of clients allowed to communicate with the Fidesops application server OAUTH_ROOT_CLIENT_ID FIDESOPS__SECURITY__OAUTH_ROOT_CLIENT_ID string fidesopsadmin N/A The value used to identify the Fidesops application root API client OAUTH_ROOT_CLIENT_SECRET FIDESOPS__SECURITY__OAUTH_ROOT_CLIENT_SECRET string fidesopsadminsecret N/A The secret value used to authenticate the Fidesops application root API client OAUTH_ACCESS_TOKEN_EXPIRE_MINUTES FIDESOPS__SECURITY__OAUTH_ACCESS_TOKEN_EXPIRE_MINUTES int 1 11520 The time period Fidesops API tokens will be valid --- --- --- --- --- --- TASK_RETRY_COUNT FIDESOPS__EXECUTION__TASK_RETRY_COUNT int 5 2 The number of times a failed request will be retried TASK_RETRY_DELAY FIDESOPS__EXECUTION__TASK_RETRY_DELAY int 20 5 The delays between retries in seconds TASK_RETRY_BACKOFF FIDESOPS__EXECUTION__TASK_RETRY_BACKOFF int 2 2 The backoff factor for retries, to space out repeated retries. An example fidesops.toml configuration file 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 [database] SERVER=\"db\" USER=\"postgres\" PASSWORD=\"a-password\" DB=\"app\" TEST_DB=\"test\" [redis] HOST=\"redis\" PASSWORD=\"testpassword\" PORT=6379 CHARSET=\"utf8\" DEFAULT_TTL_SECONDS=3600 DB_INDEX=0 [security] APP_ENCRYPTION_KEY=\"OLMkv91j8DHiDAULnK5Lxx3kSCov30b3\" CORS_ORIGINS=[\"http://localhost\", \"http://localhost:8080\"] ENCODING=\"UTF-8\" OAUTH_ROOT_CLIENT_ID=\"fidesopsadmin\" OAUTH_ROOT_CLIENT_SECRET=\"fidesopsadminsecret\" [execution] TASK_RETRY_COUNT=3 TASK_RETRY_DELAY=20 TASK_RETRY_BACKOFF=2 Please note: The configuration is case-sensitive, so the variables must be specified in UPPERCASE. Additional environment variables ENV Variable Default Description LOG_PII False If this is set to \"True\", pii values will display unmasked in log output. This variable should always be set to \"False\" in production systems. DEV_MODE False If \"True\", the fidesops server will run with hot-reloading of files. This variable should always be set to \"False\" in production systems. FIDESOPS_CONFIG_PATH None If this variable is set to a path, that path will be used to load .toml files first. That is, any .toml files on this path will override any installed .toml files. - Reporting a running application's configuration You can view the currently running configuration of a Fidesops application with the following request: GET /api/v1/config Please note: Fidesops will filter out any sensitive configuration variables. The full list of variables deemed safe to return is: Postgres database SERVER USER PORT DB TEST_DB Redis cache HOST PORT CHARSET DECODE_RESPONSES DEFAULT_TTL_SECONDS DB_INDEX Security settings CORS_ORIGINS ENCODING OAUTH_ACCESS_TOKEN_EXPIRE_MINUTES Execution settings TASK_RETRY_COUNT TASK_RETRY_DELAY TASK_RETRY_BACKOFF For more information please see the api docs .","title":"Configuration Reference"},{"location":"guides/configuration_reference/#fidesops-application-configuration-reference","text":"In this section we'll cover: How to configure the Fidesops application Configuration variable reference An example fidesops.toml configuration file Reporting a running application's configuration Take me directly to api docs .","title":"Fidesops: Application Configuration Reference"},{"location":"guides/configuration_reference/#how-to-configure-the-fidesops-application","text":"The Fidesops application configuration variables are provided in the fidesops.toml file in .toml format. Fidesops will take the first config file it finds from the following locations: The location according to the FIDESOPS_CONFIG_PATH environment variable The current working directory ( ./fidesops.toml ) The parent of the current working directory ( ../fidesops.toml ) The user's home directory ( ~/fidesops.toml ) Fidesops is also able to be run exclusively from environment variables. For more information and examples, see Deployment .","title":"How to configure the Fidesops application"},{"location":"guides/configuration_reference/#configuration-variable-reference","text":"The fidesops.toml file should specify the following variables: TOML Variable ENV Variable Type Example Default Description SERVER FIDESOPS__DATABASE__SERVER string postgres.internal N/A The networking address for the Fideops Postgres database server USER FIDESOPS__DATABASE_USER string postgres N/A The database user with which to login to the Fidesops application database PASSWORD FIDESOPS__DATABASE_PASSWORD string apassword N/A The password with which to login to the Fidesops application database PORT FIDESOPS__DATABASE__PORT int 5432 5432 The port at which the Fidesops application database will be accessible DB FIDESOPS__DATABASE_DB string db N/A The name of the database to use in the Fidesops application database --- --- --- --- --- --- HOST FIDESOPS__REDIS__HOST string redis.internal N/A The networking address for the Fidesops application Redis cache PORT FIDESOPS__REDIS__PORT int 6379 6379 The port at which the Fidesops application cache will be accessible PASSWORD FIDESOPS__REDIS__PASSWORD string anotherpassword N/A The password with which to login to the Fidesops application cache DB_INDEX FIDESOPS__REDIS__DB_INDEX int 0 0 The Fidesops application will use this index in the Redis cache to cache data DEFAULT_TTL_SECONDS FIDESOPS__REDIS__DEFAULT_TTL_SECONDS int 3600 3600 The number of seconds for which data will live in Redis before automatically expiring --- --- --- --- --- --- APP_ENCRYPTION_KEY FIDESOPS__SECURITY__APP_ENCRYPTION_KEY string OLMkv91j8DHiDAULnK5Lxx3kSCov30b3 N/A The key used to sign Fidesops API access tokens CORS_ORIGINS FIDESOPS__SECURITY__CORS_ORIGINS List[AnyHttpUrl] [\"https://a-client.com/\", \"https://another-client.com\"/] N/A A list of pre-approved addresses of clients allowed to communicate with the Fidesops application server OAUTH_ROOT_CLIENT_ID FIDESOPS__SECURITY__OAUTH_ROOT_CLIENT_ID string fidesopsadmin N/A The value used to identify the Fidesops application root API client OAUTH_ROOT_CLIENT_SECRET FIDESOPS__SECURITY__OAUTH_ROOT_CLIENT_SECRET string fidesopsadminsecret N/A The secret value used to authenticate the Fidesops application root API client OAUTH_ACCESS_TOKEN_EXPIRE_MINUTES FIDESOPS__SECURITY__OAUTH_ACCESS_TOKEN_EXPIRE_MINUTES int 1 11520 The time period Fidesops API tokens will be valid --- --- --- --- --- --- TASK_RETRY_COUNT FIDESOPS__EXECUTION__TASK_RETRY_COUNT int 5 2 The number of times a failed request will be retried TASK_RETRY_DELAY FIDESOPS__EXECUTION__TASK_RETRY_DELAY int 20 5 The delays between retries in seconds TASK_RETRY_BACKOFF FIDESOPS__EXECUTION__TASK_RETRY_BACKOFF int 2 2 The backoff factor for retries, to space out repeated retries.","title":"Configuration variable reference"},{"location":"guides/configuration_reference/#an-example-fidesopstoml-configuration-file","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 [database] SERVER=\"db\" USER=\"postgres\" PASSWORD=\"a-password\" DB=\"app\" TEST_DB=\"test\" [redis] HOST=\"redis\" PASSWORD=\"testpassword\" PORT=6379 CHARSET=\"utf8\" DEFAULT_TTL_SECONDS=3600 DB_INDEX=0 [security] APP_ENCRYPTION_KEY=\"OLMkv91j8DHiDAULnK5Lxx3kSCov30b3\" CORS_ORIGINS=[\"http://localhost\", \"http://localhost:8080\"] ENCODING=\"UTF-8\" OAUTH_ROOT_CLIENT_ID=\"fidesopsadmin\" OAUTH_ROOT_CLIENT_SECRET=\"fidesopsadminsecret\" [execution] TASK_RETRY_COUNT=3 TASK_RETRY_DELAY=20 TASK_RETRY_BACKOFF=2 Please note: The configuration is case-sensitive, so the variables must be specified in UPPERCASE.","title":"An example fidesops.toml configuration file"},{"location":"guides/configuration_reference/#additional-environment-variables","text":"ENV Variable Default Description LOG_PII False If this is set to \"True\", pii values will display unmasked in log output. This variable should always be set to \"False\" in production systems. DEV_MODE False If \"True\", the fidesops server will run with hot-reloading of files. This variable should always be set to \"False\" in production systems. FIDESOPS_CONFIG_PATH None If this variable is set to a path, that path will be used to load .toml files first. That is, any .toml files on this path will override any installed .toml files.","title":"Additional environment variables"},{"location":"guides/configuration_reference/#-reporting-a-running-applications-configuration","text":"You can view the currently running configuration of a Fidesops application with the following request: GET /api/v1/config Please note: Fidesops will filter out any sensitive configuration variables. The full list of variables deemed safe to return is:","title":"- Reporting a running application's configuration"},{"location":"guides/configuration_reference/#postgres-database","text":"SERVER USER PORT DB TEST_DB","title":"Postgres database"},{"location":"guides/configuration_reference/#redis-cache","text":"HOST PORT CHARSET DECODE_RESPONSES DEFAULT_TTL_SECONDS DB_INDEX","title":"Redis cache"},{"location":"guides/configuration_reference/#security-settings","text":"CORS_ORIGINS ENCODING OAUTH_ACCESS_TOKEN_EXPIRE_MINUTES","title":"Security settings"},{"location":"guides/configuration_reference/#execution-settings","text":"TASK_RETRY_COUNT TASK_RETRY_DELAY TASK_RETRY_BACKOFF For more information please see the api docs .","title":"Execution settings"},{"location":"guides/database_connectors/","text":"How-To: Connect to SQL and NoSQL Databases In this section we'll cover: What's a \"connection\"? Which databases does Fidesops support? How do you create a ConnectionConfig object? How do you identify the database that a ConnectionConfig connects to? How do you test and update a ConnectionConfig's Secrets? How does a ConnectionConfig differ from a Dataset? Take me directly to the ConnectionConfig API documentation . What is a connection? A connection links your databases to Fidesops, so you can gather and update selected PII categories. Supported databases Fidesops supports connections to the following databases: PostgreSQL MongoDB MySQL Microsoft SQLServer Amazon Redshift Snowflake Other platforms will be added in future releases. Creating a ConnectionConfig object The connection between Fidesops and your database is represented by a ConnectionConfig object. To create a ConnectionConfig, you issue a request to the Create a ConnectionConfig operation, passing a payload that contains the properties listed below. name is a human-readable name for your database. key is a string token that uniquely identifies your ConnectionConfig object. If you don't supply a key , the name value, converted to snake-case, is used. For example, if the name is Application PostgreSQL DB , the converted key is application_postgresql_db . connection-type specifies the type of database. Valid values are postgres , mongodb , mysql , redshift , and snowflake . access sets the connection's permissions, one of \"read\" (Fidesops may only read from your database) or \"write\" (Fidesops can read from and write to your database). While the ConnectionConfig object contains meta information about the database, you'll notice that it doesn't actually identify the database itself. We'll get to that when we set the ConnectionConfig's \"secrets\". Example 1: PostgreSQL ConnectionConfig 1 2 3 4 5 6 7 8 9 10 PATCH api/v1/connection [ { \"name\": \"Application PostgreSQL DB\", \"key\": \"application_postgresql_db\", \"connection_type\": \"postgres\", \"access\": \"read\" } ] Example 2: MongoDB ConnectionConfig 1 2 3 4 5 6 7 8 9 10 PATCH api/v1/connection [ { \"name\": \"My Mongo DB\", \"key\": \"my_mongo_db\", \"connection_type\": \"mongodb\", \"access\": \"write\" } ] Example 3: MySQL ConnectionConfig 1 2 3 4 5 6 7 8 9 PATCH api/v1/connection [ { \"name\": \"My MySQL DB\", \"key\": \"my_mysql_db\", \"connection_type\": \"mysql\", \"access\": \"write\" } ] Example 4: MsSQL ConnectionConfig 1 2 3 4 5 6 7 8 9 PATCH api/v1/connection [ { \"name\": \"My MsSQL DB\", \"key\": \"my_mssql_db\", \"connection_type\": \"mssql\", \"access\": \"write\" } ] Set the ConnectionConfig's Secrets After you create a ConnectionConfig, you explain how to connect to it by setting its \"secrets\": host, port, user, and password (note that the secrets used are specific to the DB connector). You do this by creating a ConnectionConfig Secrets object by calling the Set a ConnectionConfig's Secrets operation. You can set the object's attributes separately, or supply a single url string that encodes them all. If you set the verify query parameter to true , the operation will test the connection by issuing a trivial request to the database. The test_status response property announces the success of the connection attempt as succeeded or failed . If the attempt has failed, the failure_reason property gives further details about the failure. To skip the connection test, set verify to false . Note: Fidesops encrypts all ConnectionConfig Secrets values before they're stored. Example 1: Set the secrets separately This example sets the database secrets through separate properties and then tests the connection. 1 2 3 4 5 6 7 8 9 PUT /api/v1/connection/application-postgresql-db/secret?verify=true` { \"host\": \"host.docker.internal\", \"port\": 5432, \"dbname\": \"postgres_example\", \"username\": \"postgres\", \"password\": \"postgres\" } Example 2: Set the secrets as a URL This example sets the database secrets as a single url property, and skips the connection test. 1 2 3 4 5 PUT api/v1/connection/my_mongo_db/secret?verify=false` { \"url\": \"mongodb://mongo_user:mongo_pass@mongodb_example/mongo_test\" } Example 3: Amazon Redshift: Set URL and Schema This Amazon Redshift example sets the database secrets as a url property and a db_schema property. Redshift databases have one or more schemas, with the default being named public . If you need to set a different schema, specify db_schema for Redshift, and it will be set as the search_path when querying. 1 2 3 4 5 6 PUT api/v1/connection/my_redshift_db/secret` { \"url\": \"redshift+psycopg2://username@host.amazonaws.com:5439/database\", \"db_schema\": \"my_test_schema\" } Testing your connection You can verify that a ConnectionConfig's secrets are valid at any time by calling the Test a ConnectionConfig's Secrets operation: 1 GET /api/v1/connection/application-postgresql-db/test Once again, the test_status and failure_reason properties describe the success or failure of the test. If the test failed, you should adjust the ConnectionConfig Secrets properties through additional calls to Set a ConnectionConfig's Secrets Example 1: Connection Succeeded 1 2 3 4 5 { \"msg\" : \"Test completed for ConnectionConfig with key: app_postgres_db.\" , \"test_status\" : \"succeeded\" , \"failure_reason\" : null } Example 2: Connection Failed 1 2 3 4 5 { \"msg\" : \"Secrets updated for ConnectionConfig with key: app_mongo_db.\" , \"test_status\" : \"failed\" , \"failure_reason\" : \"Operation Failure connecting to MongoDB.\" } How do ConnectionConfigs differ from Datasets? A Dataset is an annotation of your database schema; it describes the PII category (or Data Categories) for each field that the database contains. A ConnectionConfig holds the secrets to connect to the database. Each Dataset has a foreign key to a ConnectionConfig. After Fidesops connects to your database, it generates valid queries by consulting the annotations in the Dataset. Here is an example of how a \"person\" table in your PostgreSQL database might map to a Fidesops Dataset: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Person: id: str name: str email: str dataset: - fides_key: my_app name: App Dataset description: ... collections: - name: person fields: - name: name data_categories: [user.provided.identifiable.contact.name] - name: email data_categories: [user.provided.identifiable.contact.email] - name: id data_categories: [system.operations] See How-To: Configure Datasets for more information.","title":"Connect SQL and NoSQL Databases"},{"location":"guides/database_connectors/#how-to-connect-to-sql-and-nosql-databases","text":"In this section we'll cover: What's a \"connection\"? Which databases does Fidesops support? How do you create a ConnectionConfig object? How do you identify the database that a ConnectionConfig connects to? How do you test and update a ConnectionConfig's Secrets? How does a ConnectionConfig differ from a Dataset? Take me directly to the ConnectionConfig API documentation .","title":"How-To: Connect to SQL and NoSQL Databases"},{"location":"guides/database_connectors/#what-is-a-connection","text":"A connection links your databases to Fidesops, so you can gather and update selected PII categories.","title":"What is a connection?"},{"location":"guides/database_connectors/#supported-databases","text":"Fidesops supports connections to the following databases: PostgreSQL MongoDB MySQL Microsoft SQLServer Amazon Redshift Snowflake Other platforms will be added in future releases.","title":"Supported databases"},{"location":"guides/database_connectors/#creating-a-connectionconfig-object","text":"The connection between Fidesops and your database is represented by a ConnectionConfig object. To create a ConnectionConfig, you issue a request to the Create a ConnectionConfig operation, passing a payload that contains the properties listed below. name is a human-readable name for your database. key is a string token that uniquely identifies your ConnectionConfig object. If you don't supply a key , the name value, converted to snake-case, is used. For example, if the name is Application PostgreSQL DB , the converted key is application_postgresql_db . connection-type specifies the type of database. Valid values are postgres , mongodb , mysql , redshift , and snowflake . access sets the connection's permissions, one of \"read\" (Fidesops may only read from your database) or \"write\" (Fidesops can read from and write to your database). While the ConnectionConfig object contains meta information about the database, you'll notice that it doesn't actually identify the database itself. We'll get to that when we set the ConnectionConfig's \"secrets\".","title":"Creating a ConnectionConfig object"},{"location":"guides/database_connectors/#example-1-postgresql-connectionconfig","text":"1 2 3 4 5 6 7 8 9 10 PATCH api/v1/connection [ { \"name\": \"Application PostgreSQL DB\", \"key\": \"application_postgresql_db\", \"connection_type\": \"postgres\", \"access\": \"read\" } ]","title":"Example 1: PostgreSQL ConnectionConfig"},{"location":"guides/database_connectors/#example-2-mongodb-connectionconfig","text":"1 2 3 4 5 6 7 8 9 10 PATCH api/v1/connection [ { \"name\": \"My Mongo DB\", \"key\": \"my_mongo_db\", \"connection_type\": \"mongodb\", \"access\": \"write\" } ]","title":"Example 2: MongoDB ConnectionConfig"},{"location":"guides/database_connectors/#example-3-mysql-connectionconfig","text":"1 2 3 4 5 6 7 8 9 PATCH api/v1/connection [ { \"name\": \"My MySQL DB\", \"key\": \"my_mysql_db\", \"connection_type\": \"mysql\", \"access\": \"write\" } ]","title":"Example 3: MySQL ConnectionConfig"},{"location":"guides/database_connectors/#example-4-mssql-connectionconfig","text":"1 2 3 4 5 6 7 8 9 PATCH api/v1/connection [ { \"name\": \"My MsSQL DB\", \"key\": \"my_mssql_db\", \"connection_type\": \"mssql\", \"access\": \"write\" } ]","title":"Example 4: MsSQL ConnectionConfig"},{"location":"guides/database_connectors/#set-the-connectionconfigs-secrets","text":"After you create a ConnectionConfig, you explain how to connect to it by setting its \"secrets\": host, port, user, and password (note that the secrets used are specific to the DB connector). You do this by creating a ConnectionConfig Secrets object by calling the Set a ConnectionConfig's Secrets operation. You can set the object's attributes separately, or supply a single url string that encodes them all. If you set the verify query parameter to true , the operation will test the connection by issuing a trivial request to the database. The test_status response property announces the success of the connection attempt as succeeded or failed . If the attempt has failed, the failure_reason property gives further details about the failure. To skip the connection test, set verify to false . Note: Fidesops encrypts all ConnectionConfig Secrets values before they're stored.","title":"Set the ConnectionConfig's Secrets"},{"location":"guides/database_connectors/#example-1-set-the-secrets-separately","text":"This example sets the database secrets through separate properties and then tests the connection. 1 2 3 4 5 6 7 8 9 PUT /api/v1/connection/application-postgresql-db/secret?verify=true` { \"host\": \"host.docker.internal\", \"port\": 5432, \"dbname\": \"postgres_example\", \"username\": \"postgres\", \"password\": \"postgres\" }","title":"Example 1: Set the secrets separately"},{"location":"guides/database_connectors/#example-2-set-the-secrets-as-a-url","text":"This example sets the database secrets as a single url property, and skips the connection test. 1 2 3 4 5 PUT api/v1/connection/my_mongo_db/secret?verify=false` { \"url\": \"mongodb://mongo_user:mongo_pass@mongodb_example/mongo_test\" }","title":"Example 2: Set the secrets as a URL"},{"location":"guides/database_connectors/#example-3-amazon-redshift-set-url-and-schema","text":"This Amazon Redshift example sets the database secrets as a url property and a db_schema property. Redshift databases have one or more schemas, with the default being named public . If you need to set a different schema, specify db_schema for Redshift, and it will be set as the search_path when querying. 1 2 3 4 5 6 PUT api/v1/connection/my_redshift_db/secret` { \"url\": \"redshift+psycopg2://username@host.amazonaws.com:5439/database\", \"db_schema\": \"my_test_schema\" }","title":"Example 3: Amazon Redshift: Set URL and Schema"},{"location":"guides/database_connectors/#testing-your-connection","text":"You can verify that a ConnectionConfig's secrets are valid at any time by calling the Test a ConnectionConfig's Secrets operation: 1 GET /api/v1/connection/application-postgresql-db/test Once again, the test_status and failure_reason properties describe the success or failure of the test. If the test failed, you should adjust the ConnectionConfig Secrets properties through additional calls to Set a ConnectionConfig's Secrets","title":"Testing your connection"},{"location":"guides/database_connectors/#example-1-connection-succeeded","text":"1 2 3 4 5 { \"msg\" : \"Test completed for ConnectionConfig with key: app_postgres_db.\" , \"test_status\" : \"succeeded\" , \"failure_reason\" : null }","title":"Example 1: Connection Succeeded"},{"location":"guides/database_connectors/#example-2-connection-failed","text":"1 2 3 4 5 { \"msg\" : \"Secrets updated for ConnectionConfig with key: app_mongo_db.\" , \"test_status\" : \"failed\" , \"failure_reason\" : \"Operation Failure connecting to MongoDB.\" }","title":"Example 2: Connection Failed"},{"location":"guides/database_connectors/#how-do-connectionconfigs-differ-from-datasets","text":"A Dataset is an annotation of your database schema; it describes the PII category (or Data Categories) for each field that the database contains. A ConnectionConfig holds the secrets to connect to the database. Each Dataset has a foreign key to a ConnectionConfig. After Fidesops connects to your database, it generates valid queries by consulting the annotations in the Dataset. Here is an example of how a \"person\" table in your PostgreSQL database might map to a Fidesops Dataset: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Person: id: str name: str email: str dataset: - fides_key: my_app name: App Dataset description: ... collections: - name: person fields: - name: name data_categories: [user.provided.identifiable.contact.name] - name: email data_categories: [user.provided.identifiable.contact.email] - name: id data_categories: [system.operations] See How-To: Configure Datasets for more information.","title":"How do ConnectionConfigs differ from Datasets?"},{"location":"guides/datasets/","text":"What is a Dataset? A Fidesops Dataset is the configuration you provide for a database or other queryable datastore. We use the term Dataset and not Database to emphasize that this will ultimately be applicable to a wide variety of datastores beyond traditional databases. With Datasets, a Collection is the term used for a SQL table, mongo database collection, or any other single coherent set values. Configuring a Dataset Beyond collection and field names, Fidesops needs some additional information to fully configure a Dataset. Let's look at a simple example database, and how it would be translated into a configuration in Fidesops. An example database Here we have a database of customers and addresses (the example is a bit simplified from an actual SQL schema). We have a customer table that has a foreign key of address_id to an address table: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 CREATE TABLE CUSTOMER ( id INT PRIMARY KEY , name VARCHAR , email VARCHAR , address_id int REFERENCES ADDRESS ( id ) ); CREATE TABLE ADDRESS ( id INT PRIMARY KEY , street VARCHAR , city VARCHAR , state VARCHAR , zip VARCHAR ); A Fidesops Dataset consists of a declaration of fields, with metadata describing how those fields are related. We use the information about their relationship to navigate between different collections. The dataset declaration for the above schema looks like: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 dataset : - fides_key : mydatabase name : internal database description : our internal database of customer data collections : - name : address fields : - name : id data_categories : [ system.operations ] fidesops_meta : primary_key : True - name : street data_categories : [ user.provided.identifiable.contact.street ] fidesops_meta : data_type : string - name : city data_categories : [ user.provided.identifiable.contact.city ] fidesops_meta : data_type : string - name : state data_categories : [ user.provided.identifiable.contact.state ] fidesops_meta : data_type : string - name : zip data_categories : [ user.provided.identifiable.contact.postal_code ] fidesops_meta : data_type : string - name : customer after : mydatabase.address fields : - name : address_id data_categories : [ system.operations ] fidesops_meta : references : - dataset : mydatabase field : address.id direction : to - name : created data_categories : [ system.operations ] - name : email data_categories : [ user.provided.identifiable.contact.email ] fidesops_meta : identity : email data_type : string - name : id data_categories : [ user.derived.identifiable.unique_id ] fidesops_meta : primary_key : True - name : name data_categories : [ user.provided.identifiable.name ] fidesops_meta : data_type : string Dataset members fides_key : A unique identifier name for the dataset collections : A list of addressable collections. after : An optional list of datasets that must be fully traversed before this dataset is queried. Collection members name : The name of the collection in your configuration must correspond to the name used for it in your datastore, since it will be used to generate query and update statements. fields : A list of addressable fields in the collection. Specifying the fields in the collection tells fidesOps what data to address in the collection. after : An optional list of collections (in the form [dataset name].[collection name] ) that must be fully traversed before this collection is queried. Field members name : The name of the field will be used to generate query and update statements. Please note that Fidesops does not do automated schema discovery. It is only aware of the fields you declare. This means that the only fields that will be addressed and retrieved by Fidesops queries are the fields you declare. data_categories : Annotating data_categories connects fields to policy rules, and determines which actions apply to each field. For more information see Policies fidesops_meta : The fidesops_meta section specifies some additional fields that control how Fidesops manages your data: references : A declaration of relationships between collections. Where the configuration declares a reference to mydatabase:address:id it means Fidesops will use the values from mydatabase.address.id to search for related values in customer . Unlike the SQL declaration, this is not an enforceable relationship, but simply a statement of which values are connected. In the example above, the references from the customer field to mydatabase.address.id is analogous to a SQL statement customer id REFERENCES address.id , with the exception that any dataset and collection can be referenced. The relationship requires you to specify the dataset as well as the collection for relationships, because you may declare a configuration with multiple datasets, where values in one collection in the first dataset are searched using values found in the second dataset. field : The specified linked field, using the syntax [dataset name].[collection name ].[field name] . identity : Signifies that this field is an identity value that can be used as the root for a traversal See graph traversal direction ( Optional ): Accepted values are from or to . This determines how Fidesops uses the relationships to discover data. If the direction is to , Fidesops will only use data in the source collection to discover data in the referenced collection. If the direction is from , Fidesops will only use data in the referenced collection to discover data in the source collection. If the direction is omitted, Fidesops will traverse the relation in whatever direction works to discover all related data. primary_key ( Optional ): A boolean value that means that Fidesops will treat this field as a unique row identifier for generating update statements. If multiple fields are marked as primary keys the combination of their values will be treated as a combined key. In SQL terms, we'd issue a query that looked like SELECT ... FROM TABLE WHERE primary_key_name_1 = value1 AND primary_key_name_2 = value2 . If no primary key is specified for any field on a collection, no updates will be generated against that collection. data_type ( Optional - Required only when processing erasure requests for masking strategies other than Null rewrite ): An indication of type of data held by this field. Data types are used to convert values to the appropriate type when those values are used in queries. Data types are also used to generate the appropriate masked value when running erasures, since Fidesops needs to know the type of data expected by the field in order to generate an appropriate masked value. Available datatypes are string , integer , float , boolean , object_id . object types are also supported for MongoDB. length ( Optional ): An indicator of field length. Object fields To declare an object field, you should define nested fields underneath that field. You can optionally add the data_type: object annotation, but the object type will be inferred by the presence of the nested fields. In the example below, workplace_info is an object field with two nested fields: employer and position . Data categories cannot be specified at the object level due to potential conflicts with nested fields. Instead, annotate the scalar fields within the object field. Here, the workplace_info.position field has data_category user.provided.identifiable.job_title . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 dataset : - fides_key : mongo_nested_object_example name : Mongo Example with Nested Objects description : Example of a Mongo dataset that contains 'details' about customers defined in the 'postgres_example_test_dataset' collections : - name : customer_details fields : - name : _id data_categories : [ system.operations ] fidesops_meta : primary_key : True - name : customer_id data_categories : [ user.derived.identifiable.unique_id ] fidesops_meta : references : - dataset : postgres_example_test_dataset field : customer.id direction : from - name : workplace_info fidesops_meta : data_type : object fields : - name : employer fidesops_meta : data_type : string - name : position data_categories : [ user.provided.identifiable.job_title ] fidesops_meta : data_type : string - name : id Referencing a nested field To define a relationship between a field on one collection and a nested field on another collection, use dot notation in the fidesops_meta references for as many levels are necessary. In the example below, we might add another column to our customer collection that references the nested field workplace_info.id field in the customer_details collection. Under references, this field is denoted by <collection_name>.<field_name>.<sub_field> name, or customer_details.workplace_info.id . If we preferred, we could instead define this relationship on the customer_details.workplace_info.id field itself, with a direction of from , with field mydatabase.customer.workplace_id , and dataset mydatabase . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 dataset: - fides_key: mydatabase name: internal database description: our internal database of customer data collections: - name: customer fields: - name: workplace_id data_categories: [system.operations] fidesops_meta: references: - dataset: mongo_nested_object_example field: customer_details.workplace_info.id direction: to ... Note that we currently support access requests on object fields in MongoDB only. Support for nested erasures, as well as support for array fields is underway.","title":"Configure Datasets"},{"location":"guides/datasets/#what-is-a-dataset","text":"A Fidesops Dataset is the configuration you provide for a database or other queryable datastore. We use the term Dataset and not Database to emphasize that this will ultimately be applicable to a wide variety of datastores beyond traditional databases. With Datasets, a Collection is the term used for a SQL table, mongo database collection, or any other single coherent set values.","title":"What is a Dataset?"},{"location":"guides/datasets/#configuring-a-dataset","text":"Beyond collection and field names, Fidesops needs some additional information to fully configure a Dataset. Let's look at a simple example database, and how it would be translated into a configuration in Fidesops.","title":"Configuring a Dataset"},{"location":"guides/datasets/#an-example-database","text":"Here we have a database of customers and addresses (the example is a bit simplified from an actual SQL schema). We have a customer table that has a foreign key of address_id to an address table: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 CREATE TABLE CUSTOMER ( id INT PRIMARY KEY , name VARCHAR , email VARCHAR , address_id int REFERENCES ADDRESS ( id ) ); CREATE TABLE ADDRESS ( id INT PRIMARY KEY , street VARCHAR , city VARCHAR , state VARCHAR , zip VARCHAR ); A Fidesops Dataset consists of a declaration of fields, with metadata describing how those fields are related. We use the information about their relationship to navigate between different collections. The dataset declaration for the above schema looks like: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 dataset : - fides_key : mydatabase name : internal database description : our internal database of customer data collections : - name : address fields : - name : id data_categories : [ system.operations ] fidesops_meta : primary_key : True - name : street data_categories : [ user.provided.identifiable.contact.street ] fidesops_meta : data_type : string - name : city data_categories : [ user.provided.identifiable.contact.city ] fidesops_meta : data_type : string - name : state data_categories : [ user.provided.identifiable.contact.state ] fidesops_meta : data_type : string - name : zip data_categories : [ user.provided.identifiable.contact.postal_code ] fidesops_meta : data_type : string - name : customer after : mydatabase.address fields : - name : address_id data_categories : [ system.operations ] fidesops_meta : references : - dataset : mydatabase field : address.id direction : to - name : created data_categories : [ system.operations ] - name : email data_categories : [ user.provided.identifiable.contact.email ] fidesops_meta : identity : email data_type : string - name : id data_categories : [ user.derived.identifiable.unique_id ] fidesops_meta : primary_key : True - name : name data_categories : [ user.provided.identifiable.name ] fidesops_meta : data_type : string","title":"An example database"},{"location":"guides/datasets/#dataset-members","text":"fides_key : A unique identifier name for the dataset collections : A list of addressable collections. after : An optional list of datasets that must be fully traversed before this dataset is queried.","title":"Dataset members"},{"location":"guides/datasets/#collection-members","text":"name : The name of the collection in your configuration must correspond to the name used for it in your datastore, since it will be used to generate query and update statements. fields : A list of addressable fields in the collection. Specifying the fields in the collection tells fidesOps what data to address in the collection. after : An optional list of collections (in the form [dataset name].[collection name] ) that must be fully traversed before this collection is queried.","title":"Collection members"},{"location":"guides/datasets/#field-members","text":"name : The name of the field will be used to generate query and update statements. Please note that Fidesops does not do automated schema discovery. It is only aware of the fields you declare. This means that the only fields that will be addressed and retrieved by Fidesops queries are the fields you declare. data_categories : Annotating data_categories connects fields to policy rules, and determines which actions apply to each field. For more information see Policies fidesops_meta : The fidesops_meta section specifies some additional fields that control how Fidesops manages your data: references : A declaration of relationships between collections. Where the configuration declares a reference to mydatabase:address:id it means Fidesops will use the values from mydatabase.address.id to search for related values in customer . Unlike the SQL declaration, this is not an enforceable relationship, but simply a statement of which values are connected. In the example above, the references from the customer field to mydatabase.address.id is analogous to a SQL statement customer id REFERENCES address.id , with the exception that any dataset and collection can be referenced. The relationship requires you to specify the dataset as well as the collection for relationships, because you may declare a configuration with multiple datasets, where values in one collection in the first dataset are searched using values found in the second dataset. field : The specified linked field, using the syntax [dataset name].[collection name ].[field name] . identity : Signifies that this field is an identity value that can be used as the root for a traversal See graph traversal direction ( Optional ): Accepted values are from or to . This determines how Fidesops uses the relationships to discover data. If the direction is to , Fidesops will only use data in the source collection to discover data in the referenced collection. If the direction is from , Fidesops will only use data in the referenced collection to discover data in the source collection. If the direction is omitted, Fidesops will traverse the relation in whatever direction works to discover all related data. primary_key ( Optional ): A boolean value that means that Fidesops will treat this field as a unique row identifier for generating update statements. If multiple fields are marked as primary keys the combination of their values will be treated as a combined key. In SQL terms, we'd issue a query that looked like SELECT ... FROM TABLE WHERE primary_key_name_1 = value1 AND primary_key_name_2 = value2 . If no primary key is specified for any field on a collection, no updates will be generated against that collection. data_type ( Optional - Required only when processing erasure requests for masking strategies other than Null rewrite ): An indication of type of data held by this field. Data types are used to convert values to the appropriate type when those values are used in queries. Data types are also used to generate the appropriate masked value when running erasures, since Fidesops needs to know the type of data expected by the field in order to generate an appropriate masked value. Available datatypes are string , integer , float , boolean , object_id . object types are also supported for MongoDB. length ( Optional ): An indicator of field length.","title":"Field members"},{"location":"guides/datasets/#object-fields","text":"To declare an object field, you should define nested fields underneath that field. You can optionally add the data_type: object annotation, but the object type will be inferred by the presence of the nested fields. In the example below, workplace_info is an object field with two nested fields: employer and position . Data categories cannot be specified at the object level due to potential conflicts with nested fields. Instead, annotate the scalar fields within the object field. Here, the workplace_info.position field has data_category user.provided.identifiable.job_title . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 dataset : - fides_key : mongo_nested_object_example name : Mongo Example with Nested Objects description : Example of a Mongo dataset that contains 'details' about customers defined in the 'postgres_example_test_dataset' collections : - name : customer_details fields : - name : _id data_categories : [ system.operations ] fidesops_meta : primary_key : True - name : customer_id data_categories : [ user.derived.identifiable.unique_id ] fidesops_meta : references : - dataset : postgres_example_test_dataset field : customer.id direction : from - name : workplace_info fidesops_meta : data_type : object fields : - name : employer fidesops_meta : data_type : string - name : position data_categories : [ user.provided.identifiable.job_title ] fidesops_meta : data_type : string - name : id","title":"Object fields"},{"location":"guides/datasets/#referencing-a-nested-field","text":"To define a relationship between a field on one collection and a nested field on another collection, use dot notation in the fidesops_meta references for as many levels are necessary. In the example below, we might add another column to our customer collection that references the nested field workplace_info.id field in the customer_details collection. Under references, this field is denoted by <collection_name>.<field_name>.<sub_field> name, or customer_details.workplace_info.id . If we preferred, we could instead define this relationship on the customer_details.workplace_info.id field itself, with a direction of from , with field mydatabase.customer.workplace_id , and dataset mydatabase . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 dataset: - fides_key: mydatabase name: internal database description: our internal database of customer data collections: - name: customer fields: - name: workplace_id data_categories: [system.operations] fidesops_meta: references: - dataset: mongo_nested_object_example field: customer_details.workplace_info.id direction: to ... Note that we currently support access requests on object fields in MongoDB only. Support for nested erasures, as well as support for array fields is underway.","title":"Referencing a nested field"},{"location":"guides/masking_strategies/","text":"How-To: Configure Data Masking Strategies In this section we'll cover: What is data masking? Why might you want to mask personally identifiable information rather than delete? How do you use fidesops as a masking service only? What are the currently-supported masking strategies in fidesops? How do you configure masking strategies for your fidesops policies? How do you create your own masking strategies? Data masking basics Data masking is the process of obfuscating data in client systems, so it is no longer recognizable as PII (personally identifiable information.) For example, if a customer requests that your remove all information associated with their email, test@example.com , you might choose to \"mask\" that email with a random string, xgoi4301nkyi79fjfdopvyjc5lnbr9 , and their associated address with another random string 2ab6jghdg37uhkaz3hpyavpss1dvg2 . It's important to remember that masking != anonymization. Since records are not deleted, a masked dataset is (at best) pseudonymized in most cases, and (at worst) may still be identifiable if the masking is reversible or easy to predict, which is a common mistake! In fidesops, your options to pseudonymize data are captured in \"masking strategies\". Fidesops supports a wide variety of masking strategies for different purposes when used directly as an API including HMAC, hashing, encryption, and randomization. However, note that fidesops only supports the \"null\" strategy when processing privacy requests right now, but we'll be adding support for all masking strategies in an upcoming release! Why mask instead of delete? Deleting customer data may involve entirely deleting a whole record (all attributes of the entity) or permanent and irreversible anonymization of the record by updating specific fields within a record with masked values. Using a masking strategy instead of straight deletion to obscure PII helps ensure referential integrity in your database. For example, you might have an orders table with a foreign key to user without cascade delete. Say you first deleted a user with email test@example.com without addressing their orders, you could potentially have lingering orphans in the orders table. Using masking as a \"soft delete\" might be a safer strategy depending on how your tables are defined. In order to ensure referential integrity is retained, any values that represent foreign keys must be consistently updated with the same masked values across all sources. Other reasons to mask instead of delete include legal requirements that have you retain certain data for a certain length of time. Using fidesops as a masking service If you just want to use fidesops as a masking service, you can send a PUT request to the masking endpoint with the value you'd like pseudonymized. This endpoint is also useful for getting a feel of how the different masking strategies work. Example: PUT /masking/mask?value=test@example.com 1 2 3 4 5 6 7 8 9 10 { \"strategy\" : \"random_string_rewrite\" , \"configuration\" : { \"length\" : 20 , \"format_preservation\" : { \"suffix\" : \"@masked.com\" } } } Response 200 OK 1 2 3 4 { \"plain\" : \"test@example.com\" , \"masked_value\" : \"idkeaotbrub346ycbmpo@masked.com\" } The email has been replaced with a random string of 20 characters, while still preserving that the value is an email. See Masking values API docs on how to use fidesops to as a masking service . Supported Masking Strategies Supported by fidesops policies NullMaskingStrategy : Masks the input value with a null value. ... More strategies coming soon Supported by masking service only StringRewriteMaskingStrategy : Masks the input value with a default string value HashMaskingStrategy : Masks the input value by returning a hashed version of the input value RandomStringRewriteMaskingStrategy : Masks the input value with a random string of a specified length AesEncryptionMaskingStrategy : Masks by encrypting the value using AES HmacMaskingStrategy : Masks the input value by using the HMAC algorithm along with a hashed version of the data and a secret key Configuration Only null value masking is currently supported by fidesops policies, but support for other strategies is coming. Currently, erasure requests will replace customer data with null values. In the future, to configure a specific masking strategy to be used for a Policy, you will create an erasure rule that captures that strategy for the Policy. Issue a PATCH request to /policy/policy_key/rule : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [{ \"name\" : \"Global erasure rule\" , \"action_type\" : \"erasure\" , \"key\" : \"string_rewrite_rule\" , \"masking_strategy\" : { \"strategy\" : \"random_string_rewrite\" , \"configuration\" : { \"length\" : 20 , \"format_preservation\" : { \"suffix\" : \"@masked.com\" } } } }] See the Policy guide for more detailed instructions on creating Policies and Rules. Getting masking options Issue a GET request to /api/v1/masking/strategy to preview the different masking strategies available, along with their configuration options. Extensibility In fidesops, masking strategies are all built on top of an abstract base class - MaskingStrategy . MaskingStrategy has three methods - mask , get_configuration_model and get_description . For more detail on these methods, visit the class in the fidesops repository. For now, we will focus on the implementation of RandomStringRewriteMaskingStrategy below: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 import string from typing import Optional from secrets import choice from fidesops.schemas.masking.masking_configuration import RandomStringMaskingConfiguration , MaskingConfiguration from fidesops.schemas.masking.masking_strategy_description import MaskingStrategyDescription from fidesops.service.masking.strategy.format_preservation import FormatPreservation from fidesops.service.masking.strategy.masking_strategy import MaskingStrategy class RandomStringRewriteMaskingStrategy ( MaskingStrategy ): \"\"\"Masks a value with a random string of the length specified in the configuration.\"\"\" def __init__ ( self , configuration : RandomStringMaskingConfiguration , ): self . length = configuration . length self . format_preservation = configuration . format_preservation def mask ( self , value : Optional [ str ]) -> Optional [ str ]: \"\"\"Replaces the value with a random lowercase string of the configured length\"\"\" if value is None : return None masked : str = \"\" . join ( [ choice ( string . ascii_lowercase + string . digits ) for _ in range ( self . length )] ) if self . format_preservation is not None : formatter = FormatPreservation ( self . format_preservation ) return formatter . format ( masked ) return masked @staticmethod def get_configuration_model () -> MaskingConfiguration : \"\"\"Not covered in this example\"\"\" @staticmethod def get_description () -> MaskingStrategyDescription : \"\"\"Not covered in this example\"\"\" The mask method will be called with the value to be masked and the masked value will be the output. In this case, if a value is supplied, we want to replace it with a random mixture of ascii lowercase letters and digits of the specified length. If format preservation is specified, for example, we still want to know that an email was an email, we might tack on an email-like suffix. Note the arguments to the init method - there is a field configuration of type RandomStringMaskingConfiguration . This is the configuration for the masking strategy. It is used to house the options specified by the client as well as any defaults that should be applied in their absence. All configuration classes extend from the MaskingConfiguration class. Integrating with the Masking Strategy Factory Now that we know how a masking strategy is built in the system and how a masking strategy is configured, we will cover how to enable the linkage between the two. In other words, how do we run the masking strategy that we have configured? The answer to that is the Masking Strategy Factory. The masking strategy factory is defined in the masking_strategy_factory.py file. The pertinent sections have been pasted below: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 from enum import Enum from typing import Dict , Union from pydantic import ValidationError from fidesops.service.masking.strategy.masking_strategy_hmac import HmacMaskingStrategy from fidesops.service.masking.strategy.masking_strategy_random_string_rewrite import ( RandomStringRewriteMaskingStrategy , ) from fidesops.service.masking.strategy.masking_strategy import MaskingStrategy from fidesops.service.masking.strategy.masking_strategy_aes_encrypt import ( AesEncryptionMaskingStrategy , ) from fidesops.service.masking.strategy.masking_strategy_hash import HashMaskingStrategy from fidesops.service.masking.strategy.masking_strategy_string_rewrite import ( StringRewriteMaskingStrategy , ) from fidesops.common_exceptions import ValidationError as FidesopsValidationError from fidesops.schemas.masking.masking_configuration import FormatPreservationConfig class SupportedMaskingStrategies ( Enum ): string_rewrite = StringRewriteMaskingStrategy hash = HashMaskingStrategy random_string_rewrite = RandomStringRewriteMaskingStrategy aes_encrypt = AesEncryptionMaskingStrategy hmac = HmacMaskingStrategy def get_strategy ( strategy_name : str , configuration : Dict [ str , Union [ str , FormatPreservationConfig ], ], ) -> MaskingStrategy : \"\"\" Returns the strategy given the name and configuration. Raises NoSuchStrategyException if the strategy does not exist \"\"\" if strategy_name not in SupportedMaskingStrategies . __members__ : valid_strategies = \", \" . join ([ s . name for s in SupportedMaskingStrategies ]) raise NoSuchStrategyException ( f \"Strategy ' { strategy_name } ' does not exist. Valid strategies are [ { valid_strategies } ]\" ) strategy = SupportedMaskingStrategies [ strategy_name ] . value try : strategy_config = strategy . get_configuration_model ()( ** configuration ) return strategy ( configuration = strategy_config ) except ValidationError as e : raise FidesopsValidationError ( message = str ( e )) The SupportedMaskingStrategy enum maps the strategy name to the masking strategy implementation class. After creating a new masking strategy and configuration, just register it in this enum, and it will be ready for use by the system.","title":"Configure Data Masking Strategies"},{"location":"guides/masking_strategies/#how-to-configure-data-masking-strategies","text":"In this section we'll cover: What is data masking? Why might you want to mask personally identifiable information rather than delete? How do you use fidesops as a masking service only? What are the currently-supported masking strategies in fidesops? How do you configure masking strategies for your fidesops policies? How do you create your own masking strategies?","title":"How-To: Configure Data Masking Strategies"},{"location":"guides/masking_strategies/#data-masking-basics","text":"Data masking is the process of obfuscating data in client systems, so it is no longer recognizable as PII (personally identifiable information.) For example, if a customer requests that your remove all information associated with their email, test@example.com , you might choose to \"mask\" that email with a random string, xgoi4301nkyi79fjfdopvyjc5lnbr9 , and their associated address with another random string 2ab6jghdg37uhkaz3hpyavpss1dvg2 . It's important to remember that masking != anonymization. Since records are not deleted, a masked dataset is (at best) pseudonymized in most cases, and (at worst) may still be identifiable if the masking is reversible or easy to predict, which is a common mistake! In fidesops, your options to pseudonymize data are captured in \"masking strategies\". Fidesops supports a wide variety of masking strategies for different purposes when used directly as an API including HMAC, hashing, encryption, and randomization. However, note that fidesops only supports the \"null\" strategy when processing privacy requests right now, but we'll be adding support for all masking strategies in an upcoming release!","title":"Data masking basics"},{"location":"guides/masking_strategies/#why-mask-instead-of-delete","text":"Deleting customer data may involve entirely deleting a whole record (all attributes of the entity) or permanent and irreversible anonymization of the record by updating specific fields within a record with masked values. Using a masking strategy instead of straight deletion to obscure PII helps ensure referential integrity in your database. For example, you might have an orders table with a foreign key to user without cascade delete. Say you first deleted a user with email test@example.com without addressing their orders, you could potentially have lingering orphans in the orders table. Using masking as a \"soft delete\" might be a safer strategy depending on how your tables are defined. In order to ensure referential integrity is retained, any values that represent foreign keys must be consistently updated with the same masked values across all sources. Other reasons to mask instead of delete include legal requirements that have you retain certain data for a certain length of time.","title":"Why mask instead of delete?"},{"location":"guides/masking_strategies/#using-fidesops-as-a-masking-service","text":"If you just want to use fidesops as a masking service, you can send a PUT request to the masking endpoint with the value you'd like pseudonymized. This endpoint is also useful for getting a feel of how the different masking strategies work. Example: PUT /masking/mask?value=test@example.com 1 2 3 4 5 6 7 8 9 10 { \"strategy\" : \"random_string_rewrite\" , \"configuration\" : { \"length\" : 20 , \"format_preservation\" : { \"suffix\" : \"@masked.com\" } } } Response 200 OK 1 2 3 4 { \"plain\" : \"test@example.com\" , \"masked_value\" : \"idkeaotbrub346ycbmpo@masked.com\" } The email has been replaced with a random string of 20 characters, while still preserving that the value is an email. See Masking values API docs on how to use fidesops to as a masking service .","title":"Using fidesops as a masking service"},{"location":"guides/masking_strategies/#supported-masking-strategies","text":"","title":"Supported Masking Strategies"},{"location":"guides/masking_strategies/#supported-by-fidesops-policies","text":"NullMaskingStrategy : Masks the input value with a null value. ... More strategies coming soon","title":"Supported by fidesops policies"},{"location":"guides/masking_strategies/#supported-by-masking-service-only","text":"StringRewriteMaskingStrategy : Masks the input value with a default string value HashMaskingStrategy : Masks the input value by returning a hashed version of the input value RandomStringRewriteMaskingStrategy : Masks the input value with a random string of a specified length AesEncryptionMaskingStrategy : Masks by encrypting the value using AES HmacMaskingStrategy : Masks the input value by using the HMAC algorithm along with a hashed version of the data and a secret key","title":"Supported by masking service only"},{"location":"guides/masking_strategies/#configuration","text":"Only null value masking is currently supported by fidesops policies, but support for other strategies is coming. Currently, erasure requests will replace customer data with null values. In the future, to configure a specific masking strategy to be used for a Policy, you will create an erasure rule that captures that strategy for the Policy. Issue a PATCH request to /policy/policy_key/rule : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [{ \"name\" : \"Global erasure rule\" , \"action_type\" : \"erasure\" , \"key\" : \"string_rewrite_rule\" , \"masking_strategy\" : { \"strategy\" : \"random_string_rewrite\" , \"configuration\" : { \"length\" : 20 , \"format_preservation\" : { \"suffix\" : \"@masked.com\" } } } }] See the Policy guide for more detailed instructions on creating Policies and Rules.","title":"Configuration"},{"location":"guides/masking_strategies/#getting-masking-options","text":"Issue a GET request to /api/v1/masking/strategy to preview the different masking strategies available, along with their configuration options.","title":"Getting masking options"},{"location":"guides/masking_strategies/#extensibility","text":"In fidesops, masking strategies are all built on top of an abstract base class - MaskingStrategy . MaskingStrategy has three methods - mask , get_configuration_model and get_description . For more detail on these methods, visit the class in the fidesops repository. For now, we will focus on the implementation of RandomStringRewriteMaskingStrategy below: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 import string from typing import Optional from secrets import choice from fidesops.schemas.masking.masking_configuration import RandomStringMaskingConfiguration , MaskingConfiguration from fidesops.schemas.masking.masking_strategy_description import MaskingStrategyDescription from fidesops.service.masking.strategy.format_preservation import FormatPreservation from fidesops.service.masking.strategy.masking_strategy import MaskingStrategy class RandomStringRewriteMaskingStrategy ( MaskingStrategy ): \"\"\"Masks a value with a random string of the length specified in the configuration.\"\"\" def __init__ ( self , configuration : RandomStringMaskingConfiguration , ): self . length = configuration . length self . format_preservation = configuration . format_preservation def mask ( self , value : Optional [ str ]) -> Optional [ str ]: \"\"\"Replaces the value with a random lowercase string of the configured length\"\"\" if value is None : return None masked : str = \"\" . join ( [ choice ( string . ascii_lowercase + string . digits ) for _ in range ( self . length )] ) if self . format_preservation is not None : formatter = FormatPreservation ( self . format_preservation ) return formatter . format ( masked ) return masked @staticmethod def get_configuration_model () -> MaskingConfiguration : \"\"\"Not covered in this example\"\"\" @staticmethod def get_description () -> MaskingStrategyDescription : \"\"\"Not covered in this example\"\"\" The mask method will be called with the value to be masked and the masked value will be the output. In this case, if a value is supplied, we want to replace it with a random mixture of ascii lowercase letters and digits of the specified length. If format preservation is specified, for example, we still want to know that an email was an email, we might tack on an email-like suffix. Note the arguments to the init method - there is a field configuration of type RandomStringMaskingConfiguration . This is the configuration for the masking strategy. It is used to house the options specified by the client as well as any defaults that should be applied in their absence. All configuration classes extend from the MaskingConfiguration class.","title":"Extensibility"},{"location":"guides/masking_strategies/#integrating-with-the-masking-strategy-factory","text":"Now that we know how a masking strategy is built in the system and how a masking strategy is configured, we will cover how to enable the linkage between the two. In other words, how do we run the masking strategy that we have configured? The answer to that is the Masking Strategy Factory. The masking strategy factory is defined in the masking_strategy_factory.py file. The pertinent sections have been pasted below: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 from enum import Enum from typing import Dict , Union from pydantic import ValidationError from fidesops.service.masking.strategy.masking_strategy_hmac import HmacMaskingStrategy from fidesops.service.masking.strategy.masking_strategy_random_string_rewrite import ( RandomStringRewriteMaskingStrategy , ) from fidesops.service.masking.strategy.masking_strategy import MaskingStrategy from fidesops.service.masking.strategy.masking_strategy_aes_encrypt import ( AesEncryptionMaskingStrategy , ) from fidesops.service.masking.strategy.masking_strategy_hash import HashMaskingStrategy from fidesops.service.masking.strategy.masking_strategy_string_rewrite import ( StringRewriteMaskingStrategy , ) from fidesops.common_exceptions import ValidationError as FidesopsValidationError from fidesops.schemas.masking.masking_configuration import FormatPreservationConfig class SupportedMaskingStrategies ( Enum ): string_rewrite = StringRewriteMaskingStrategy hash = HashMaskingStrategy random_string_rewrite = RandomStringRewriteMaskingStrategy aes_encrypt = AesEncryptionMaskingStrategy hmac = HmacMaskingStrategy def get_strategy ( strategy_name : str , configuration : Dict [ str , Union [ str , FormatPreservationConfig ], ], ) -> MaskingStrategy : \"\"\" Returns the strategy given the name and configuration. Raises NoSuchStrategyException if the strategy does not exist \"\"\" if strategy_name not in SupportedMaskingStrategies . __members__ : valid_strategies = \", \" . join ([ s . name for s in SupportedMaskingStrategies ]) raise NoSuchStrategyException ( f \"Strategy ' { strategy_name } ' does not exist. Valid strategies are [ { valid_strategies } ]\" ) strategy = SupportedMaskingStrategies [ strategy_name ] . value try : strategy_config = strategy . get_configuration_model ()( ** configuration ) return strategy ( configuration = strategy_config ) except ValidationError as e : raise FidesopsValidationError ( message = str ( e )) The SupportedMaskingStrategy enum maps the strategy name to the masking strategy implementation class. After creating a new masking strategy and configuration, just register it in this enum, and it will be ready for use by the system.","title":"Integrating with the Masking Strategy Factory"},{"location":"guides/oauth/","text":"How-To: Authenticate with OAuth In this section we'll cover: How to use the root client Creating additional OAuth clients using the root client Authorizing your client with scopes Creating OAuth tokens When you invoke a Fidesops API, you must pass an access token as the value of the Authorization header. Furthermore, the token must include a scope that gives you permission to take an action on the API. For example, let's say you want to create a new Policy by calling PATCH /api/v1/policy . The token that you pass to the Authorization header must include the policy:create_or_update scope. This document explains how to craft a properly-scoped access token. Getting Started First, create an access token for the \"root\" client, included in the deployment by default. The root client's token is all-powerful: It contains all scopes, so it can call any of the Fidesops APIs. To create the root token, you pass the OAUTH_ROOT_CLIENT_ID and OAUTH_ROOT_CLIENT_SECRET environment variables (which are automatically defined in your system) to the POST /api/v1/oauth/token endpoint. You also set the grant_type parameter to client_credentials : 1 2 3 4 5 curl \\ -X POST 'http://<HOST>:8080/api/v1/oauth/token' \\ -d client_id=$OAUTH_ROOT_CLIENT_ID \\ -d client_secret=$OAUTH_ROOT_CLIENT_SECRET \\ -d grant_type=client_credentials You'll notice that there's no Authorization header. This is the only Fidesops API that doesn't require an access token. If the token call is successful, the response will return the root client's access token in the access_token property: 1 2 3 4 5 6 7 HTTP/1.1 200 OK Content-Type: application/json { \"access_token\" : \"MTI4Q0JDJSrgyplbmMiOiJBjU2I..._X0hTMyXAyPx\", /* ignore any other properties */ } Creating Additional Clients Because the root client's token is all-powerful, it can create new clients and new client ID/client secret pairs which can be used to create additional access tokens. Pro Tip For general best practices, we recommend creating a client with scope CLIENT_CREATE to create any new clients. This will help to reduce the utilization of the all-scopes root client. To create the client ID/secret pair, call POST /api/v1/oauth/client : 1 2 3 4 5 curl \\ -X POST 'http://<HOST>:8080/api/v1/oauth/client' \\ -H 'Authorization: Bearer <root_access_token>' -H 'Content-Type: application/json' -d '{ \"scopes\": [\"policy:read\", \"rule:read\"]}' For this call, we have to populate the Authorization header. Notice that the header's value is formed as Bearer <token> . We also have to declare the request's Content-Type to be application/json . Authorize your Client with Scopes To add scopes to the client, the body of your request must contain an array of scope tokens. You can retrieve the available scopes by calling GET /api/v1/oauth/scopes , or you can look in the scope registry file . If the call is successful, Fidesapi responds with a new client ID/client secret pair: 1 2 3 4 5 6 7 HTTP/1.1 200 OK Content-Type: application/json { \"client_id\" : \"<new_client_id>\" \"client_secret\" : \"<new_client_secret>\", } Create Access Token You then create a new access token by calling POST /api/v1/oauth/token with the new credentials. In the above example, your new access token only lets the client read policies and rules -- the client nor create other clients, nor write policies, nor perform other operations using Fidesops APIs. Access Token Expiration By default, access tokens expire after 11520 minutes (8 days). To specify a different expiration time (in minutes) set the OAUTH_ACCESS_TOKEN_EXPIRE_MINUTES environment variable. If you call a Fidesops API with an expired token, the call returns 401 . Other OAuth Calls Fidesops defines OAuth operations that let you delete a client, and read and write a client's scopes. See the OAuth section of the API documentation for details.","title":"Authenticate with OAuth"},{"location":"guides/oauth/#how-to-authenticate-with-oauth","text":"In this section we'll cover: How to use the root client Creating additional OAuth clients using the root client Authorizing your client with scopes Creating OAuth tokens When you invoke a Fidesops API, you must pass an access token as the value of the Authorization header. Furthermore, the token must include a scope that gives you permission to take an action on the API. For example, let's say you want to create a new Policy by calling PATCH /api/v1/policy . The token that you pass to the Authorization header must include the policy:create_or_update scope. This document explains how to craft a properly-scoped access token.","title":"How-To: Authenticate with OAuth"},{"location":"guides/oauth/#getting-started","text":"First, create an access token for the \"root\" client, included in the deployment by default. The root client's token is all-powerful: It contains all scopes, so it can call any of the Fidesops APIs. To create the root token, you pass the OAUTH_ROOT_CLIENT_ID and OAUTH_ROOT_CLIENT_SECRET environment variables (which are automatically defined in your system) to the POST /api/v1/oauth/token endpoint. You also set the grant_type parameter to client_credentials : 1 2 3 4 5 curl \\ -X POST 'http://<HOST>:8080/api/v1/oauth/token' \\ -d client_id=$OAUTH_ROOT_CLIENT_ID \\ -d client_secret=$OAUTH_ROOT_CLIENT_SECRET \\ -d grant_type=client_credentials You'll notice that there's no Authorization header. This is the only Fidesops API that doesn't require an access token. If the token call is successful, the response will return the root client's access token in the access_token property: 1 2 3 4 5 6 7 HTTP/1.1 200 OK Content-Type: application/json { \"access_token\" : \"MTI4Q0JDJSrgyplbmMiOiJBjU2I..._X0hTMyXAyPx\", /* ignore any other properties */ }","title":"Getting Started"},{"location":"guides/oauth/#creating-additional-clients","text":"Because the root client's token is all-powerful, it can create new clients and new client ID/client secret pairs which can be used to create additional access tokens. Pro Tip For general best practices, we recommend creating a client with scope CLIENT_CREATE to create any new clients. This will help to reduce the utilization of the all-scopes root client. To create the client ID/secret pair, call POST /api/v1/oauth/client : 1 2 3 4 5 curl \\ -X POST 'http://<HOST>:8080/api/v1/oauth/client' \\ -H 'Authorization: Bearer <root_access_token>' -H 'Content-Type: application/json' -d '{ \"scopes\": [\"policy:read\", \"rule:read\"]}' For this call, we have to populate the Authorization header. Notice that the header's value is formed as Bearer <token> . We also have to declare the request's Content-Type to be application/json .","title":"Creating Additional Clients"},{"location":"guides/oauth/#authorize-your-client-with-scopes","text":"To add scopes to the client, the body of your request must contain an array of scope tokens. You can retrieve the available scopes by calling GET /api/v1/oauth/scopes , or you can look in the scope registry file . If the call is successful, Fidesapi responds with a new client ID/client secret pair: 1 2 3 4 5 6 7 HTTP/1.1 200 OK Content-Type: application/json { \"client_id\" : \"<new_client_id>\" \"client_secret\" : \"<new_client_secret>\", }","title":"Authorize your Client with Scopes"},{"location":"guides/oauth/#create-access-token","text":"You then create a new access token by calling POST /api/v1/oauth/token with the new credentials. In the above example, your new access token only lets the client read policies and rules -- the client nor create other clients, nor write policies, nor perform other operations using Fidesops APIs.","title":"Create Access Token"},{"location":"guides/oauth/#access-token-expiration","text":"By default, access tokens expire after 11520 minutes (8 days). To specify a different expiration time (in minutes) set the OAUTH_ACCESS_TOKEN_EXPIRE_MINUTES environment variable. If you call a Fidesops API with an expired token, the call returns 401 .","title":"Access Token Expiration"},{"location":"guides/oauth/#other-oauth-calls","text":"Fidesops defines OAuth operations that let you delete a client, and read and write a client's scopes. See the OAuth section of the API documentation for details.","title":"Other OAuth Calls"},{"location":"guides/onetrust/","text":"How-To: Configure OneTrust Integration In this section we'll cover: An overview of the OneTrust Integration How the OneTrust Integration works through Fidesops How to configure OneTrust request intake and storage How to test the OneTrust integration API docs for OneTrust are part of the storage module. Overview OneTrust is a DSAR automation provider that provides an interface to manage privacy requests. Fidesops handles the integration to OneTrust to fulfill Data Subject Requests and returns the data package back to OneTrust. How it works Here's how our OneTrust integration works: You set up a new storage destination of type onetrust A new scheduled task kicks off that pings OneTrust for subtasks labeled for Fidesops Fidesops processes those DSARs normally Upon completion of DSAR processing, we do 2 things: Ping OneTrust to set the subtask status appropriately If applicable, upload a data package back to OneTrust Configuration Fidesops OneTrust request intake is configured as part of the StorageConfig in the storage module. To configure Fidesops to connect to OneTrust: Add Destination: Add a StorageConfig that includes a onetrust destination type. Authenticate: Use appropriate credentials to authenticate with OneTrust. Determine polling interval: Decide what day of the week and hour of the day you wish to retrieve requests from OneTrust. Read more about how to do this here OneTrust When the Fidesops scheduled task runs, it looks for subtasks with an exact string name of \"fides task\". So, you'll need to be sure tasks you wish to pass through the Fides ecosystem are correctly labeled in the OneTrust interface. Testing To test the OneTrust integration works correctly, you'll need to do the following: Ensure that you have subtasks with a name of \"fides task\" in OneTrust Set your OneTrust destination config in Fides such that day of week and hour of request intake is appropriate for testing Confirm that the subtask status has been updated at that time, and any DSAR data packages have been uploaded at the request level in OneTrust","title":"Configure OneTrust Integration"},{"location":"guides/onetrust/#how-to-configure-onetrust-integration","text":"In this section we'll cover: An overview of the OneTrust Integration How the OneTrust Integration works through Fidesops How to configure OneTrust request intake and storage How to test the OneTrust integration API docs for OneTrust are part of the storage module.","title":"How-To: Configure OneTrust Integration"},{"location":"guides/onetrust/#overview","text":"OneTrust is a DSAR automation provider that provides an interface to manage privacy requests. Fidesops handles the integration to OneTrust to fulfill Data Subject Requests and returns the data package back to OneTrust.","title":"Overview"},{"location":"guides/onetrust/#how-it-works","text":"Here's how our OneTrust integration works: You set up a new storage destination of type onetrust A new scheduled task kicks off that pings OneTrust for subtasks labeled for Fidesops Fidesops processes those DSARs normally Upon completion of DSAR processing, we do 2 things: Ping OneTrust to set the subtask status appropriately If applicable, upload a data package back to OneTrust","title":"How it works"},{"location":"guides/onetrust/#configuration","text":"","title":"Configuration"},{"location":"guides/onetrust/#fidesops","text":"OneTrust request intake is configured as part of the StorageConfig in the storage module. To configure Fidesops to connect to OneTrust: Add Destination: Add a StorageConfig that includes a onetrust destination type. Authenticate: Use appropriate credentials to authenticate with OneTrust. Determine polling interval: Decide what day of the week and hour of the day you wish to retrieve requests from OneTrust. Read more about how to do this here","title":"Fidesops"},{"location":"guides/onetrust/#onetrust","text":"When the Fidesops scheduled task runs, it looks for subtasks with an exact string name of \"fides task\". So, you'll need to be sure tasks you wish to pass through the Fides ecosystem are correctly labeled in the OneTrust interface.","title":"OneTrust"},{"location":"guides/onetrust/#testing","text":"To test the OneTrust integration works correctly, you'll need to do the following: Ensure that you have subtasks with a name of \"fides task\" in OneTrust Set your OneTrust destination config in Fides such that day of week and hour of request intake is appropriate for testing Confirm that the subtask status has been updated at that time, and any DSAR data packages have been uploaded at the request level in OneTrust","title":"Testing"},{"location":"guides/policies/","text":"How-To: Configure Policies A Policy is a set of instructions (or \"Rules\") that are executed when a user submits a request to retrieve or delete their data (the user makes a \"Privacy Request\"). Each Rule contains an \"execution strategy\": action_type : The action this Rule performs, either access (retrieve data) or erasure (delete data). storage_destination : If the action_type is access , this is the key of a StorageConfig object that defines where the data is uploaded. Currently, Amazon S3 buckets and local filesystem storage are supported. See How-To: Configure Storage for more information. masking_strategy : If the action_type is erasure , this is the key of a Masking object that defines how the erasure is implemented. See How-To: Configure Masking Strategies for a list of masking strategies. In addition to specifying an execution strategy, a Rule contains one or more Data Categories, or \"Targets\", to which the rule applies. Putting it all together, we have: 1 2 3 Policy |-> Rules |-> Targets This is reflected in the API paths that create these elements: PATCH /policy PATCH /policy/{policy_key}/rule PATCH /policy/{policy_key}/rule/{rule_key}/target Each operation takes an array of objects, so you can create more than one at a time. A note about PATCH endpoints The PATCH requests perform the equivalent of a create_or_update operation. This means that any existing objects sent to this endpoint will: be updated, any non-existing objects will be created, AND any objects existing that are not specified in the request will not be deleted Create a Policy Let's say you want to make a Policy that contains rules about a user's email address. You would start by first creating a Policy object: 1 2 3 4 5 6 7 8 PATCH /api/v1/policy [ { \"name\": \"User Email Address\", \"key\": \"user_email_address_polcy\" } ] This policy is subtly different from the concept of a Policy in Fidesctl . A Fidesctl policy dictates which data categories can be stored where. A Fidesops policy, on the other hand, dictates how to access, mask or erase data that matches specific data categories for privacy requests. Add an Access Rule to your Policy The policy creation operation returns a Policy key, which we'll use to add a Rule: 1 2 3 4 5 6 7 8 9 10 PATCH /api/v1/policy/{policy_key}/rule [ { \"name\": \"Access User Email Address\", \"key\": \"access_user_email_address_rule\", \"action_type\": \"access\", \"storage_destination_key\": \"storage_key\" } ] Note that storage_key must identify an existing StorageConfig object. Finally, we use the Rule key to add a Target: 1 2 3 4 5 6 7 8 9 PATCH /api/v1/policy/{policy_key}/rule/{rule_key}/target [ { \"name\": \"Access User Email Address Target\", \"key\": \"access_user_email_address_target\", \"data_category\": \"user.provided.identifiable.contact.email\", } ] Rule Attributes Rule.action_type : Which action is this Rule handling? access : A data subject access request. A user would like to access their own data from within the Fidesops identity graph. Fidesops must look these fields up and return it to them. Fidesops will return these to a storage_destination . erasure : A data subject erasure request (also known in some legislation as the Right to be Forgotten). A user would like to erase their own data currently stored in the Fidesops identity graph. Fidesops must look these fields up and either erase them entirely, or apply a masking_strategy . Rule.storage_destination : Where Fidesops will upload the returned data for an access action. Currently, Amazon S3 buckets and local filesystem storage are supported. Rule.masking_strategy : How to erase data in the Identity Graph that applies to this Rule . See How-To: Configure Masking Strategies for a full list of supported strategies and their respective configurations. Add an Erasure Rule to your Policy The simple access policy we've created above, will simply pull all data of category user.provided.identifiable.contact.email , but in the event of an erasure request, we might also want to mask this information. PATCH /api/v1/policy/{policy_key}/rule 1 2 3 4 5 6 7 8 9 10 11 12 13 [ { \"name\" : \"Mask Provided Emails\" , \"key\" : \"mask_provided_emails\" , \"action_type\" : \"erasure\" , \"masking_strategy\" : { \"strategy\" : \"hash\" , \"configuration\" : { \"algorithm\" : \"SHA-512\" }, }, }, ] This will create a rule to hash a not-yet-specified value with a SHA-512 hash. We need to specify a target to hash, so we need to create a target for this rule: PATCH api/v1/policy/{policy_key}/rule/{rule_key} 1 2 3 4 5 [ { \"data_category\" : \"user.provided.identifiable.contact.email\" , }, ] This policy, user_email_address_polcy , will now do the following: - Return all data inside the Identity Graph with a data category that matches (or is nested under) user.provided.identifiable.contact . - Mask all data inside the Identity Graph with a data category that matches user.provided.identifiable.contact.email with a the SHA-512 hashing function. A Note About Erasing Data When a Policy Rule erases data, it erases the entire branch given by the Target. For example, if we created an erasure rule with a Target of user.provided.identifiable.contact , all of the information within the contact node -- including user.provided.identifiable.contact.email -- would be erased. It's illegal to erase the same data twice within a Policy, so you should take care when you add Targets to a Rule. For example, you can't add user.provided.identifiable.contact and user.provided.identifiable.contact.email \"data_category\". And lastly, access rules will always run before erasure rules.","title":"Create Request Policies"},{"location":"guides/policies/#how-to-configure-policies","text":"A Policy is a set of instructions (or \"Rules\") that are executed when a user submits a request to retrieve or delete their data (the user makes a \"Privacy Request\"). Each Rule contains an \"execution strategy\": action_type : The action this Rule performs, either access (retrieve data) or erasure (delete data). storage_destination : If the action_type is access , this is the key of a StorageConfig object that defines where the data is uploaded. Currently, Amazon S3 buckets and local filesystem storage are supported. See How-To: Configure Storage for more information. masking_strategy : If the action_type is erasure , this is the key of a Masking object that defines how the erasure is implemented. See How-To: Configure Masking Strategies for a list of masking strategies. In addition to specifying an execution strategy, a Rule contains one or more Data Categories, or \"Targets\", to which the rule applies. Putting it all together, we have: 1 2 3 Policy |-> Rules |-> Targets This is reflected in the API paths that create these elements: PATCH /policy PATCH /policy/{policy_key}/rule PATCH /policy/{policy_key}/rule/{rule_key}/target Each operation takes an array of objects, so you can create more than one at a time. A note about PATCH endpoints The PATCH requests perform the equivalent of a create_or_update operation. This means that any existing objects sent to this endpoint will: be updated, any non-existing objects will be created, AND any objects existing that are not specified in the request will not be deleted","title":"How-To: Configure Policies"},{"location":"guides/policies/#create-a-policy","text":"Let's say you want to make a Policy that contains rules about a user's email address. You would start by first creating a Policy object: 1 2 3 4 5 6 7 8 PATCH /api/v1/policy [ { \"name\": \"User Email Address\", \"key\": \"user_email_address_polcy\" } ] This policy is subtly different from the concept of a Policy in Fidesctl . A Fidesctl policy dictates which data categories can be stored where. A Fidesops policy, on the other hand, dictates how to access, mask or erase data that matches specific data categories for privacy requests.","title":"Create a Policy"},{"location":"guides/policies/#add-an-access-rule-to-your-policy","text":"The policy creation operation returns a Policy key, which we'll use to add a Rule: 1 2 3 4 5 6 7 8 9 10 PATCH /api/v1/policy/{policy_key}/rule [ { \"name\": \"Access User Email Address\", \"key\": \"access_user_email_address_rule\", \"action_type\": \"access\", \"storage_destination_key\": \"storage_key\" } ] Note that storage_key must identify an existing StorageConfig object. Finally, we use the Rule key to add a Target: 1 2 3 4 5 6 7 8 9 PATCH /api/v1/policy/{policy_key}/rule/{rule_key}/target [ { \"name\": \"Access User Email Address Target\", \"key\": \"access_user_email_address_target\", \"data_category\": \"user.provided.identifiable.contact.email\", } ]","title":"Add an Access Rule to your Policy"},{"location":"guides/policies/#rule-attributes","text":"Rule.action_type : Which action is this Rule handling? access : A data subject access request. A user would like to access their own data from within the Fidesops identity graph. Fidesops must look these fields up and return it to them. Fidesops will return these to a storage_destination . erasure : A data subject erasure request (also known in some legislation as the Right to be Forgotten). A user would like to erase their own data currently stored in the Fidesops identity graph. Fidesops must look these fields up and either erase them entirely, or apply a masking_strategy . Rule.storage_destination : Where Fidesops will upload the returned data for an access action. Currently, Amazon S3 buckets and local filesystem storage are supported. Rule.masking_strategy : How to erase data in the Identity Graph that applies to this Rule . See How-To: Configure Masking Strategies for a full list of supported strategies and their respective configurations.","title":"Rule Attributes"},{"location":"guides/policies/#add-an-erasure-rule-to-your-policy","text":"The simple access policy we've created above, will simply pull all data of category user.provided.identifiable.contact.email , but in the event of an erasure request, we might also want to mask this information. PATCH /api/v1/policy/{policy_key}/rule 1 2 3 4 5 6 7 8 9 10 11 12 13 [ { \"name\" : \"Mask Provided Emails\" , \"key\" : \"mask_provided_emails\" , \"action_type\" : \"erasure\" , \"masking_strategy\" : { \"strategy\" : \"hash\" , \"configuration\" : { \"algorithm\" : \"SHA-512\" }, }, }, ] This will create a rule to hash a not-yet-specified value with a SHA-512 hash. We need to specify a target to hash, so we need to create a target for this rule: PATCH api/v1/policy/{policy_key}/rule/{rule_key} 1 2 3 4 5 [ { \"data_category\" : \"user.provided.identifiable.contact.email\" , }, ] This policy, user_email_address_polcy , will now do the following: - Return all data inside the Identity Graph with a data category that matches (or is nested under) user.provided.identifiable.contact . - Mask all data inside the Identity Graph with a data category that matches user.provided.identifiable.contact.email with a the SHA-512 hashing function.","title":"Add an Erasure Rule to your Policy"},{"location":"guides/policies/#a-note-about-erasing-data","text":"When a Policy Rule erases data, it erases the entire branch given by the Target. For example, if we created an erasure rule with a Target of user.provided.identifiable.contact , all of the information within the contact node -- including user.provided.identifiable.contact.email -- would be erased. It's illegal to erase the same data twice within a Policy, so you should take care when you add Targets to a Rule. For example, you can't add user.provided.identifiable.contact and user.provided.identifiable.contact.email \"data_category\". And lastly, access rules will always run before erasure rules.","title":"A Note About Erasing Data"},{"location":"guides/policy_webhooks/","text":"How-To: Configure Policy Webhooks In this section we'll cover: What's a Policy Webhook? How do I configure Policy Webhooks? Create a ConnectionConfig Add ConnectionConfig secrets Define PolicyPreWebhooks or PolicyPostWebhooks Expected webhook request and response formats Resuming Privacy Request Execution Take me directly to the Policy Webhooks API documentation . Policy Webhook Defined A Policy Webhook is an HTTPS Callback that you've defined on a Policy to call an external REST API endpoint before or after a PrivacyRequest executes. You can define as many webhooks as you'd like. Webhooks can be one_way , where we will just ping your API and move on, or two_way , where we will wait for a response. Any derived_identities returned from a two_way webhook will be saved and can be used to locate other user information. For example, a webhook might take a known email identity and use that to find a phone_number derived)identity . Another use case for a Policy Webhook might be to log a user out of your mobile app after you've cleared their data from your system. In this case, you'd create a Policy and a ConnectionConfig to describe the URL to hit to clear the cache. You'd then create a one-way PolicyPostWebhook to run after your PrivacyRequest executes. Configuration Big picture, you will define an https ConnectionConfig that contains the details to make a request to your API endpoint. You will then define a PolicyPreWebhook or a PolicyPostWebhook for a specific Policy using that ConnectionConfig . Creating an HTTPS ConnectionConfig The information that describes how to connect to your API endpoint lives on a ConnectionConfig . We also use ConnectionConfigs to connect to databases like PostgreSQL and MongoDB . This same construct can help us store how to connect to an external API endpoint. For more information on ConnectionConfigs, see how to Create a ConnectionConfig. To start, send a PATCH request to /v1/connection to add an https ConnectionConfig: 1 2 3 4 5 6 7 8 [ { \"name\" : \"My Webhook Connection Configuration\" , \"key\" : \"test_webhook_connection_config\" , \"connection_type\" : \"https\" , \"access\" : \"read\" } ] Adding ConnectionConfig Secrets The secret details needed to talk to your API endpoint are defined by making a PUT to the ConnectionConfig Secrets endpoint: These credentials are stored encrypted in the fidesops app database. See API docs on how to Set a ConnectionConfig's Secrets . PUT /v1/connection/test_webhook_connection_config 1 2 3 4 { \"url\" : \"https://www.example.com\" , \"authorization\" : \"test_authorization\" } Defining Pre-Execution or Post-Execution Policy Webhooks After you've defined a ConnectionConfig , you can create lists of webhooks to run before ( PolicyPreWebhooks ) or after ( PolicyPostWebhooks ) a PrivacyRequest is executed. If you are defining PolicyPreWebhooks, all desired PolicyPreWebhooks should be included in the request body in the desired order. Any PolicyPreWebhooks on the Policy not included in the request, will be removed from the Policy. The same applies for PolicyPostWebhooks. To update your list of PolicyPreWebhooks: PUT /policy/<policy_key>/webhook/pre_execution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [ { \"connection_config_key\" : \"test_webhook_connection_config\" , \"direction\" : \"one_way\" , \"key\" : \"wake_up_snowflake_db\" , \"name\" : \"Wake up Snowflake DB Webhook\" }, { \"connection_config_key\" : \"test_webhook_connection_config\" , \"direction\" : \"two_way\" , \"key\" : \"prep_systems_webhook\" , \"name\" : \"Prep Systems Webhook\" } ] This creates two webhooks that are run sequentially for the Policy before a PrivacyRequest runs. Similarly, to update your list of Post-Execution webhooks on a Policy: PUT /policy/<policy_key>/webhook/post_execution See API docs for more information on how to Update PolicyPreWebhooks and how to Update PolicyPostWebhooks . Updating a Single Webhook To update a single PolicyPreWebhook or PolicyPostWebhook, send a PATCH request to update selected attributes. Note that updates to order can likewise update the order of related webhooks. The following example will update the PolicyPreWebhook with key webhook_hook to be two_way instead of one_way and will update its order from 0 to 1. Because we've defined two PolicyPreWebhooks, this causes the webhook at position 1 to move to position 0. PATCH /policy/<policy_key>/webhook/pre-execution/wake_up_snowflake_db 1 2 3 4 { \"direction\" : \"two_way\" , \"order\" : 1 } Response Because this PATCH request updated the order of other webhooks, a reordered summary is included under the new_order attribute: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"resource\" : { \"direction\" : \"two_way\" , \"key\" : \"wake_up_snowflake_db\" , \"name\" : \"Wake up Snowflake DB Webhook\" , \"connection_config\" : \"<TRUNCATED>\" , \"order\" : 1 }, \"new_order\" : [ { \"key\" : \"prep_systems_webhook\" , \"order\" : 0 }, { \"key\" : \"wake_up_snowflake_db\" , \"order\" : 1 } ] } Similarly, to update your a Post-Execution webhook on a Policy: PATCH /policy/<policy_key>/webhook/post_execution/<post_execution_key> See API docs for more information on how to PATCH a PolicyPreWebhook and how to PATCH a PolicyPostWebhook . Webhook Request Format Before and after running access or erasure requests, Fidesops will send requests to any configured webhooks in sequential order with the following request body: POST 1 2 3 4 5 6 7 8 9 { \"privacy_request_id\" : \"pri_029832ba-3b84-40f7-8946-82aec6f95448\" , \"direction\" : \"one_way | two_way\" , \"callback_type\" : \"pre | post\" , \"identity\" : { \"email\" : \"customer-1@example.com\" , \"phone_number\" : \"555-5555\" } } Most of these attributes were configured by you: the direction , the callback_type (\"pre\" for PolicyPreWebhook s that will run before PrivacyRequest execution or \"post\" for PolicyPostWebhook s that will run after PrivacyRequestExecution). Known identities are also embedded in the request. For two-way PolicyPreWebhooks , we include specific headers in case you need to pause PrivacyRequest execution while you take care of additional processing on your end. 1 2 3 4 { \"reply-to\" : \"/privacy-request/<privacy_request_id>/resume\" , \"reply-to-token\" : \"<jwe_token>\" } To resume, you should send a request back to the reply-to URL with the reply-to-token . The reply-to-token will expire when your redis cache expires: config.redis.DEFAULT_TTL_SECONDS (Fidesops uses the redis cache to temporarily store identity data). At this point, your PrivacyRequest will be given an error status, and you would have to resubmit the PrivacyRequest. Expected Webhook Response Format Your webhook should respond immediately. If more processing time is needed, either make sure it is configured as a one-way webhook, or reply with halt=True if you want to pause execution and wait for your processing to finish. Note that only PolicyPreWebhooks can pause execution. We don't expect a response from one-way webhooks, but two-way webhooks should respond with the following: 1 2 3 4 5 6 7 { \"derived_identity\" : { \"email\" : \"customer-1@gmail.com\" , \"phone_number\" : \"555-5555\" }, \"halt\" : \"true | false\" } Derived identity is optional: a returned email or phone number will replace currently known emails or phone numbers. Resuming PrivacyRequest Execution If your webhook needed more processing time, once completed, send a request to the reply-to URL given to you in the original request header with the reply-to-token auth token. POST privacy_request/<privacy-request-id>/resume 1 2 3 4 5 6 { \"derived_identity\" : { \"email\" : \"customer-1@gmail.com\" , \"phone_number\" : \"555-5555\" } } If there are no derived identities, an empty {} request body will suffice. The reply-to-token is a JWE containing the current webhook id, scopes to access the callback endpoint, and the datetime the token is issued. We unpack this and resume the privacy request execution after the specified webhook. The reply-to-token expires when the redis cache expires ( config.redis.DEFAULT_TTL_SECONDS ). Once the redis cache expires, Fidesops no longer has the original identity data and the privacy request should be resubmitted.","title":"Configure Policy Webhooks"},{"location":"guides/policy_webhooks/#how-to-configure-policy-webhooks","text":"In this section we'll cover: What's a Policy Webhook? How do I configure Policy Webhooks? Create a ConnectionConfig Add ConnectionConfig secrets Define PolicyPreWebhooks or PolicyPostWebhooks Expected webhook request and response formats Resuming Privacy Request Execution Take me directly to the Policy Webhooks API documentation .","title":"How-To: Configure Policy Webhooks"},{"location":"guides/policy_webhooks/#policy-webhook-defined","text":"A Policy Webhook is an HTTPS Callback that you've defined on a Policy to call an external REST API endpoint before or after a PrivacyRequest executes. You can define as many webhooks as you'd like. Webhooks can be one_way , where we will just ping your API and move on, or two_way , where we will wait for a response. Any derived_identities returned from a two_way webhook will be saved and can be used to locate other user information. For example, a webhook might take a known email identity and use that to find a phone_number derived)identity . Another use case for a Policy Webhook might be to log a user out of your mobile app after you've cleared their data from your system. In this case, you'd create a Policy and a ConnectionConfig to describe the URL to hit to clear the cache. You'd then create a one-way PolicyPostWebhook to run after your PrivacyRequest executes.","title":"Policy Webhook Defined"},{"location":"guides/policy_webhooks/#configuration","text":"Big picture, you will define an https ConnectionConfig that contains the details to make a request to your API endpoint. You will then define a PolicyPreWebhook or a PolicyPostWebhook for a specific Policy using that ConnectionConfig .","title":"Configuration"},{"location":"guides/policy_webhooks/#creating-an-https-connectionconfig","text":"The information that describes how to connect to your API endpoint lives on a ConnectionConfig . We also use ConnectionConfigs to connect to databases like PostgreSQL and MongoDB . This same construct can help us store how to connect to an external API endpoint. For more information on ConnectionConfigs, see how to Create a ConnectionConfig. To start, send a PATCH request to /v1/connection to add an https ConnectionConfig: 1 2 3 4 5 6 7 8 [ { \"name\" : \"My Webhook Connection Configuration\" , \"key\" : \"test_webhook_connection_config\" , \"connection_type\" : \"https\" , \"access\" : \"read\" } ]","title":"Creating an HTTPS ConnectionConfig"},{"location":"guides/policy_webhooks/#adding-connectionconfig-secrets","text":"The secret details needed to talk to your API endpoint are defined by making a PUT to the ConnectionConfig Secrets endpoint: These credentials are stored encrypted in the fidesops app database. See API docs on how to Set a ConnectionConfig's Secrets . PUT /v1/connection/test_webhook_connection_config 1 2 3 4 { \"url\" : \"https://www.example.com\" , \"authorization\" : \"test_authorization\" }","title":"Adding ConnectionConfig Secrets"},{"location":"guides/policy_webhooks/#defining-pre-execution-or-post-execution-policy-webhooks","text":"After you've defined a ConnectionConfig , you can create lists of webhooks to run before ( PolicyPreWebhooks ) or after ( PolicyPostWebhooks ) a PrivacyRequest is executed. If you are defining PolicyPreWebhooks, all desired PolicyPreWebhooks should be included in the request body in the desired order. Any PolicyPreWebhooks on the Policy not included in the request, will be removed from the Policy. The same applies for PolicyPostWebhooks. To update your list of PolicyPreWebhooks: PUT /policy/<policy_key>/webhook/pre_execution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [ { \"connection_config_key\" : \"test_webhook_connection_config\" , \"direction\" : \"one_way\" , \"key\" : \"wake_up_snowflake_db\" , \"name\" : \"Wake up Snowflake DB Webhook\" }, { \"connection_config_key\" : \"test_webhook_connection_config\" , \"direction\" : \"two_way\" , \"key\" : \"prep_systems_webhook\" , \"name\" : \"Prep Systems Webhook\" } ] This creates two webhooks that are run sequentially for the Policy before a PrivacyRequest runs. Similarly, to update your list of Post-Execution webhooks on a Policy: PUT /policy/<policy_key>/webhook/post_execution See API docs for more information on how to Update PolicyPreWebhooks and how to Update PolicyPostWebhooks .","title":"Defining Pre-Execution or Post-Execution Policy Webhooks"},{"location":"guides/policy_webhooks/#updating-a-single-webhook","text":"To update a single PolicyPreWebhook or PolicyPostWebhook, send a PATCH request to update selected attributes. Note that updates to order can likewise update the order of related webhooks. The following example will update the PolicyPreWebhook with key webhook_hook to be two_way instead of one_way and will update its order from 0 to 1. Because we've defined two PolicyPreWebhooks, this causes the webhook at position 1 to move to position 0. PATCH /policy/<policy_key>/webhook/pre-execution/wake_up_snowflake_db 1 2 3 4 { \"direction\" : \"two_way\" , \"order\" : 1 }","title":"Updating a Single Webhook"},{"location":"guides/policy_webhooks/#response","text":"Because this PATCH request updated the order of other webhooks, a reordered summary is included under the new_order attribute: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \"resource\" : { \"direction\" : \"two_way\" , \"key\" : \"wake_up_snowflake_db\" , \"name\" : \"Wake up Snowflake DB Webhook\" , \"connection_config\" : \"<TRUNCATED>\" , \"order\" : 1 }, \"new_order\" : [ { \"key\" : \"prep_systems_webhook\" , \"order\" : 0 }, { \"key\" : \"wake_up_snowflake_db\" , \"order\" : 1 } ] } Similarly, to update your a Post-Execution webhook on a Policy: PATCH /policy/<policy_key>/webhook/post_execution/<post_execution_key> See API docs for more information on how to PATCH a PolicyPreWebhook and how to PATCH a PolicyPostWebhook .","title":"Response"},{"location":"guides/policy_webhooks/#webhook-request-format","text":"Before and after running access or erasure requests, Fidesops will send requests to any configured webhooks in sequential order with the following request body: POST 1 2 3 4 5 6 7 8 9 { \"privacy_request_id\" : \"pri_029832ba-3b84-40f7-8946-82aec6f95448\" , \"direction\" : \"one_way | two_way\" , \"callback_type\" : \"pre | post\" , \"identity\" : { \"email\" : \"customer-1@example.com\" , \"phone_number\" : \"555-5555\" } } Most of these attributes were configured by you: the direction , the callback_type (\"pre\" for PolicyPreWebhook s that will run before PrivacyRequest execution or \"post\" for PolicyPostWebhook s that will run after PrivacyRequestExecution). Known identities are also embedded in the request. For two-way PolicyPreWebhooks , we include specific headers in case you need to pause PrivacyRequest execution while you take care of additional processing on your end. 1 2 3 4 { \"reply-to\" : \"/privacy-request/<privacy_request_id>/resume\" , \"reply-to-token\" : \"<jwe_token>\" } To resume, you should send a request back to the reply-to URL with the reply-to-token . The reply-to-token will expire when your redis cache expires: config.redis.DEFAULT_TTL_SECONDS (Fidesops uses the redis cache to temporarily store identity data). At this point, your PrivacyRequest will be given an error status, and you would have to resubmit the PrivacyRequest.","title":"Webhook Request Format"},{"location":"guides/policy_webhooks/#expected-webhook-response-format","text":"Your webhook should respond immediately. If more processing time is needed, either make sure it is configured as a one-way webhook, or reply with halt=True if you want to pause execution and wait for your processing to finish. Note that only PolicyPreWebhooks can pause execution. We don't expect a response from one-way webhooks, but two-way webhooks should respond with the following: 1 2 3 4 5 6 7 { \"derived_identity\" : { \"email\" : \"customer-1@gmail.com\" , \"phone_number\" : \"555-5555\" }, \"halt\" : \"true | false\" } Derived identity is optional: a returned email or phone number will replace currently known emails or phone numbers.","title":"Expected Webhook Response Format"},{"location":"guides/policy_webhooks/#resuming-privacyrequest-execution","text":"If your webhook needed more processing time, once completed, send a request to the reply-to URL given to you in the original request header with the reply-to-token auth token. POST privacy_request/<privacy-request-id>/resume 1 2 3 4 5 6 { \"derived_identity\" : { \"email\" : \"customer-1@gmail.com\" , \"phone_number\" : \"555-5555\" } } If there are no derived identities, an empty {} request body will suffice. The reply-to-token is a JWE containing the current webhook id, scopes to access the callback endpoint, and the datetime the token is issued. We unpack this and resume the privacy request execution after the specified webhook. The reply-to-token expires when the redis cache expires ( config.redis.DEFAULT_TTL_SECONDS ). Once the redis cache expires, Fidesops no longer has the original identity data and the privacy request should be resubmitted.","title":"Resuming PrivacyRequest Execution"},{"location":"guides/privacy_requests/","text":"How-To: Execute Privacy Requests In this section we'll cover: What is a Privacy Request? How does a Privacy Request work in conjunction with a policy? How can I execute a Privacy Request? How do I monitor Privacy Requests as they execute? How can I integrate the Privacy Request flow into my existing support tools? Specifying encryption of access request results Decrypting access request results Take me directly to API docs . What is a Privacy Request? A Privacy Request represents a request to perform an action on a user's identity data. The Request object itself identifies the user by email address, phone number, social security number, or other identifiable information. The data that will be affected and how it's affected is described in a Policy object that's associated with the Request. For more information on Policies, see How-To: Configure Policies . How do I submit a Privacy Request? You submit a Privacy Request by calling the Submit a Privacy Request operation. Here, we submit a request to apply the a-demo-policy Policy to all target data in the Identity Graph that can be generated from the email address identity@example.com and the phone number +1 (123) 456 7891 . POST /api/v1/privacy-request 1 2 3 4 5 6 7 8 9 10 11 [ { \"external_id\" : \"a-user-defined-id\" , \"requested_at\" : \"2021-10-31T16:00:00.000Z\" , \"policy_key\" : \"a-demo-policy\" , \"identity\" : { \"email\" : \"identity@example.com\" , \"phone_number\" : \"+1 (123) 456 7891\" } } ] external_id is an optional identifier of your own invention that lets you track the Privacy Request. See How-To: Report on Privacy Requests for more information. requested_at is an ISO8601 timestamp that specifies the moment that the request was submitted. policy_key identifies the Policy object to which this request will be applied. See How-To: Configure Request Policies for more information. identities is an array of objects that contain data that identify the users whose data will be affected by the Policy. Each object identifies a single user by AND'ing the object's properties. This request will submit a Privacy Request for execution that applies the a-demo-policy Policy to all target data in the Identity Graph that can be generated from the email address identity@example.com or the phone number +1 (123) 456 7891 . Specifying a external_id enables us to track this Privacy Request with that external_id later on. See How-To: Report on Privacy Requests for more information. policy_key should correspond to a previously configured Policy object. See How-To: Configure Request Policies for more information. A full list of attributes available to set on the Privacy Request can be found in the API docs . How do I monitor Privacy Requests as they execute? Privacy Requests can be monitored at any time throughout their execution by submitting any of the following requests: GET api/v1/privacy-request?id=<privacy_request_id> GET api/v1/privacy-request?external_id=<external_id> For more detailed examples and further Privacy Request filtering in Fidesops please see How-To: Report on Privacy Requests . How can I integrate the Privacy Request flow into my existing support tools? Alongside generic API interoperability, Fidesops provides a direct integration with the OneTrust's DSAR automation flow. Generic API interoperability: Third party services can be authorized by creating additional OAuth clients. Tokens obtained from OAuth clients can be managed and revoked at any time. See How-To: Authenticate with OAuth for more information. OneTrust: Fidesops can be configured to act as (or as part of) the fulfillment layer in OneTrust's Data Subject Request automation flow. Please see How-To: Configure OneTrust Integration for more information. Generic API interoperability: Third party services can be authorized by creating additional OAuth clients. Tokens obtained from OAuth clients can be managed and revoked at any time. Please see How-To: Authenticate with OAuth for more information. OneTrust: Fidesops can be configured to act as (or as part of) the fulfilment layer in OneTrust's Data Subject Request automation flow. Please see How-To: Configure OneTrust Integration for more information. Encryption You can optionally encrypt your access request results by supplying an encryption_key string in the request body: We will use the supplied encryption_key to encrypt the contents of your JSON and CSV results using an AES-256 algorithm in GCM mode. When converted to bytes, your encryption_key must be 16 bytes long. The data we return will have the nonce concatenated to the encrypted data. POST /privacy-request 1 2 3 4 5 6 7 8 [ { \"requested_at\" : \"2021-08-30T16:09:37.359Z\" , \"identity\" : { \"email\" : \"customer-1@example.com\" }, \"policy_key\" : \"my_access_policy\" , \"encryption_key\" : \"test--encryption\" } ] Decrypting your access request results If you specified an encryption key, we encrypted the access result data using your key and an internally-generated nonce with an AES 256 algorithm in GCM mode. The return value is a 12-byte nonce plus the encrypted data that is all b64encoded together. 1 2 3 +------------------+-------------------+ | nonce (12 bytes) | message (N bytes) | +------------------+-------------------+ For example, pretend you specified an encryption key of test--encryption , and the resulting data was uploaded to S3 in a JSON file: GPUiK9tq5k/HfBnSN+J+OvLXZ+GCisapdI2KGP7A1WK+dz1XHef+hWb/SjszdqdNVGvziyY6GF5KIrvrXgxjZuaAvgU=' . You will need to implement something similar to the snippet below on your end to decrypt: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import json import base64 from cryptography.hazmat.primitives.ciphers.aead import AESGCM encrypted : str = \"GPUiK9tq5k/HfBnSN+J+OvLXZ+GCisapdI2KGP7A1WK+dz1XHef+hWb/SjszdqdNVGvziyY6GF5KIrvrXgxjZuaAvgU=\" encryption_key : str = \"test--encryption\" . encode ( \"utf-8\" ) # Only you know this encrypted_combined : bytes = base64 . b64decode ( encrypted ) nonce : bytes = encrypted_combined [ 0 : 12 ] encrypted_message : bytes = encrypted_combined [ 12 :] gcm = AESGCM ( encryption_key ) decrypted_bytes : bytes = gcm . decrypt ( nonce , encrypted_message , nonce ) decrypted_str : str = decrypted_bytes . decode ( \"utf-8\" ) json . loads ( decrypted_str ) 1 >>> { \"street\" : \"test street\" , \"state\" : \"NY\" } If CSV data was uploaded, each CSV in the zipfile was encrypted using a different nonce, so you'll need to follow a similar process for each csv file.","title":"Execute Privacy Requests"},{"location":"guides/privacy_requests/#how-to-execute-privacy-requests","text":"In this section we'll cover: What is a Privacy Request? How does a Privacy Request work in conjunction with a policy? How can I execute a Privacy Request? How do I monitor Privacy Requests as they execute? How can I integrate the Privacy Request flow into my existing support tools? Specifying encryption of access request results Decrypting access request results Take me directly to API docs .","title":"How-To: Execute Privacy Requests"},{"location":"guides/privacy_requests/#what-is-a-privacy-request","text":"A Privacy Request represents a request to perform an action on a user's identity data. The Request object itself identifies the user by email address, phone number, social security number, or other identifiable information. The data that will be affected and how it's affected is described in a Policy object that's associated with the Request. For more information on Policies, see How-To: Configure Policies .","title":"What is a Privacy Request?"},{"location":"guides/privacy_requests/#how-do-i-submit-a-privacy-request","text":"You submit a Privacy Request by calling the Submit a Privacy Request operation. Here, we submit a request to apply the a-demo-policy Policy to all target data in the Identity Graph that can be generated from the email address identity@example.com and the phone number +1 (123) 456 7891 . POST /api/v1/privacy-request 1 2 3 4 5 6 7 8 9 10 11 [ { \"external_id\" : \"a-user-defined-id\" , \"requested_at\" : \"2021-10-31T16:00:00.000Z\" , \"policy_key\" : \"a-demo-policy\" , \"identity\" : { \"email\" : \"identity@example.com\" , \"phone_number\" : \"+1 (123) 456 7891\" } } ] external_id is an optional identifier of your own invention that lets you track the Privacy Request. See How-To: Report on Privacy Requests for more information. requested_at is an ISO8601 timestamp that specifies the moment that the request was submitted. policy_key identifies the Policy object to which this request will be applied. See How-To: Configure Request Policies for more information. identities is an array of objects that contain data that identify the users whose data will be affected by the Policy. Each object identifies a single user by AND'ing the object's properties. This request will submit a Privacy Request for execution that applies the a-demo-policy Policy to all target data in the Identity Graph that can be generated from the email address identity@example.com or the phone number +1 (123) 456 7891 . Specifying a external_id enables us to track this Privacy Request with that external_id later on. See How-To: Report on Privacy Requests for more information. policy_key should correspond to a previously configured Policy object. See How-To: Configure Request Policies for more information. A full list of attributes available to set on the Privacy Request can be found in the API docs .","title":"How do I submit a Privacy Request?"},{"location":"guides/privacy_requests/#how-do-i-monitor-privacy-requests-as-they-execute","text":"Privacy Requests can be monitored at any time throughout their execution by submitting any of the following requests: GET api/v1/privacy-request?id=<privacy_request_id> GET api/v1/privacy-request?external_id=<external_id> For more detailed examples and further Privacy Request filtering in Fidesops please see How-To: Report on Privacy Requests .","title":"How do I monitor Privacy Requests as they execute?"},{"location":"guides/privacy_requests/#how-can-i-integrate-the-privacy-request-flow-into-my-existing-support-tools","text":"Alongside generic API interoperability, Fidesops provides a direct integration with the OneTrust's DSAR automation flow. Generic API interoperability: Third party services can be authorized by creating additional OAuth clients. Tokens obtained from OAuth clients can be managed and revoked at any time. See How-To: Authenticate with OAuth for more information. OneTrust: Fidesops can be configured to act as (or as part of) the fulfillment layer in OneTrust's Data Subject Request automation flow. Please see How-To: Configure OneTrust Integration for more information. Generic API interoperability: Third party services can be authorized by creating additional OAuth clients. Tokens obtained from OAuth clients can be managed and revoked at any time. Please see How-To: Authenticate with OAuth for more information. OneTrust: Fidesops can be configured to act as (or as part of) the fulfilment layer in OneTrust's Data Subject Request automation flow. Please see How-To: Configure OneTrust Integration for more information.","title":"How can I integrate the Privacy Request flow into my existing support tools?"},{"location":"guides/privacy_requests/#encryption","text":"You can optionally encrypt your access request results by supplying an encryption_key string in the request body: We will use the supplied encryption_key to encrypt the contents of your JSON and CSV results using an AES-256 algorithm in GCM mode. When converted to bytes, your encryption_key must be 16 bytes long. The data we return will have the nonce concatenated to the encrypted data. POST /privacy-request 1 2 3 4 5 6 7 8 [ { \"requested_at\" : \"2021-08-30T16:09:37.359Z\" , \"identity\" : { \"email\" : \"customer-1@example.com\" }, \"policy_key\" : \"my_access_policy\" , \"encryption_key\" : \"test--encryption\" } ]","title":"Encryption"},{"location":"guides/privacy_requests/#decrypting-your-access-request-results","text":"If you specified an encryption key, we encrypted the access result data using your key and an internally-generated nonce with an AES 256 algorithm in GCM mode. The return value is a 12-byte nonce plus the encrypted data that is all b64encoded together. 1 2 3 +------------------+-------------------+ | nonce (12 bytes) | message (N bytes) | +------------------+-------------------+ For example, pretend you specified an encryption key of test--encryption , and the resulting data was uploaded to S3 in a JSON file: GPUiK9tq5k/HfBnSN+J+OvLXZ+GCisapdI2KGP7A1WK+dz1XHef+hWb/SjszdqdNVGvziyY6GF5KIrvrXgxjZuaAvgU=' . You will need to implement something similar to the snippet below on your end to decrypt: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import json import base64 from cryptography.hazmat.primitives.ciphers.aead import AESGCM encrypted : str = \"GPUiK9tq5k/HfBnSN+J+OvLXZ+GCisapdI2KGP7A1WK+dz1XHef+hWb/SjszdqdNVGvziyY6GF5KIrvrXgxjZuaAvgU=\" encryption_key : str = \"test--encryption\" . encode ( \"utf-8\" ) # Only you know this encrypted_combined : bytes = base64 . b64decode ( encrypted ) nonce : bytes = encrypted_combined [ 0 : 12 ] encrypted_message : bytes = encrypted_combined [ 12 :] gcm = AESGCM ( encryption_key ) decrypted_bytes : bytes = gcm . decrypt ( nonce , encrypted_message , nonce ) decrypted_str : str = decrypted_bytes . decode ( \"utf-8\" ) json . loads ( decrypted_str ) 1 >>> { \"street\" : \"test street\" , \"state\" : \"NY\" } If CSV data was uploaded, each CSV in the zipfile was encrypted using a different nonce, so you'll need to follow a similar process for each csv file.","title":"Decrypting your access request results"},{"location":"guides/query_execution/","text":"Query Execution Graphs and Traversals Fidesops uses your Datasets to generate a graph of the resources. Based on the identity data you provide, Fidesops then generates a specific traversal , which is the order of steps that will be taken to fulfill a specific request. The graph supports both directed and non-directed edges using the optional direction parameter on the relation (non-directional edges may be traversed in either direction). You can preview the queries that will be generated or manually control the order of operations by making relations explicitly directional and with the and Collection parameters. If you specify a Collection that can't be reached, Fidesops generates an error. An example graph In this example there are three databases: a mysql database that stores users and their comments, a postgres DB that stores purchase information, and a mongoDB that stores user accounts. Each of them may have related data that we'd like to retrieve. The Dataset specification looks like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 dataset : - fides_key : mongo_1 collections : - name : users fields : - name : _id fidesops_meta : primary_key : True - name : user_name fidesops_meta : identity : username - name : full_name - name : accounts fields : - name : _id fidesops_meta : primary_key : True - name : name fidesops_meta : references : - dataset : mongo_1 name : users.full_name direction : from - name : comments 1 2 3 4 5 6 7 8 9 10 11 12 13 14 dataset : - fides_key : mysql_1 collections : - name : users fields : - name : id fidesops_meta : primary_key : True references : - dataset : postgres_1 field : users.id direction : from - name : internal_id - name : comment 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 dataset : - fides_key : postgres_1 collections : - name : purchase_items fields : - name : id fidesops_meta : primary_key : True - name : purchase_id fidesops_meta : references : - dataset : postgres_1 field : purchases.id direction : from - name : amount - name : rating - name : purchases fields : - name : id fidesops_meta : primary_key : True - name : user_id fidesops_meta : references : - dataset : postgres_1 field : users.id - name : amount - name : users fields : - name : id fidesops_meta : primary_key : True - name : email fidesops_meta : identity : email - name : address_id We trigger a retrieval with identity data, such as an email address or user ID, that's provided by the user. What we do is... Identify the collections that contain the identity data that the user provided. Find all related records. Use the data to find all connected data. Continue until we've found all related data. For the first step, we use the concept of an identity . In the Fidesops Dataset specification, any field may be marked with an identity notation: 1 2 3 4 5 6 collection : - name : foo fields : - name : bar fidesop_meta : identity : email What this means is that we will initiate the data retrieval process with provided data that looks like {\"email\": \"user@example.com\", \"username\": \"someone\"} by looking for values in the collection users where email == user@example.com . Note that the names of the provided starter data do not need to match the field names we're going to use this data to search. Also note that in this case, since we're providing two pieces of data, we can also choose to start a search using the username provided value. In the above diagram, this means we have enough data to search in both postgres_1.users.email and mongo_1.users.user_name . How does Fidesops execute queries? The next step is to follow any links provided in field relationship information. In the abbreviated dataset declarations below, you can see that since we know that mongo_1.accounts data contains data related to mongo_1.users , we can retrieve data from mongo_1.accounts by generating this set of queries: 1 2 3 4 5 6 7 8 9 10 11 # mongo_1 1 . db . users . find ( { \"user_name\" : \"someone\" } , { \"_id\" : 1 , \"full_name\" : 1 } ) 2 . db . accounts . find ( { \"name\" : { \"$in\" :[ < full_name value from ( 1 ) > ] }} , { \"_id\" : 1 , \"comments\" : 1 } ) # postgres_1 3 . select id , address_id from users where email = 'user@example.com' ; 4 . select id , amount from purchases where user_id in [ < id values from ( 3 ) > ] 5 . select id , amount , rating from purchase_items where purchase_id in [ < id values from ( 4 ) > ] # mysql_1 6 . select internal_id , comment from users where id in [ < id values from ( 3 ) > ] Logically, we are creating a linked graph using the connections you've specified between your collections to retrieve your data. Notes about Dataset traversals You can define multiple links between collections, which will generate OR queries like SELECT a,b,c from TABLE_1 where name in (values from TABLE\\_2) OR email in (values from TABLE\\_3) . It's an error to specify a collection in your Dataset can't be reached through the relations you've specified. Fidesops uses your Datasets and your input data to \"solve\" the graph of your collections and how it is traversed. If your Dataset has multiple identity values, you can create a situation where the query behavior depends on the values you provide. In the example above, starting the graph traversal with {\"email\": \"value1\", \"username\":\" value2\"} is valid, but starting with {\"email\": \"value1\"} fails because mongo_1.users is no longer reachable. As shown in the example, you can create queries between Datasets.","title":"Preview Query Execution"},{"location":"guides/query_execution/#query-execution","text":"","title":"Query Execution"},{"location":"guides/query_execution/#graphs-and-traversals","text":"Fidesops uses your Datasets to generate a graph of the resources. Based on the identity data you provide, Fidesops then generates a specific traversal , which is the order of steps that will be taken to fulfill a specific request. The graph supports both directed and non-directed edges using the optional direction parameter on the relation (non-directional edges may be traversed in either direction). You can preview the queries that will be generated or manually control the order of operations by making relations explicitly directional and with the and Collection parameters. If you specify a Collection that can't be reached, Fidesops generates an error.","title":"Graphs and Traversals"},{"location":"guides/query_execution/#an-example-graph","text":"In this example there are three databases: a mysql database that stores users and their comments, a postgres DB that stores purchase information, and a mongoDB that stores user accounts. Each of them may have related data that we'd like to retrieve. The Dataset specification looks like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 dataset : - fides_key : mongo_1 collections : - name : users fields : - name : _id fidesops_meta : primary_key : True - name : user_name fidesops_meta : identity : username - name : full_name - name : accounts fields : - name : _id fidesops_meta : primary_key : True - name : name fidesops_meta : references : - dataset : mongo_1 name : users.full_name direction : from - name : comments 1 2 3 4 5 6 7 8 9 10 11 12 13 14 dataset : - fides_key : mysql_1 collections : - name : users fields : - name : id fidesops_meta : primary_key : True references : - dataset : postgres_1 field : users.id direction : from - name : internal_id - name : comment 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 dataset : - fides_key : postgres_1 collections : - name : purchase_items fields : - name : id fidesops_meta : primary_key : True - name : purchase_id fidesops_meta : references : - dataset : postgres_1 field : purchases.id direction : from - name : amount - name : rating - name : purchases fields : - name : id fidesops_meta : primary_key : True - name : user_id fidesops_meta : references : - dataset : postgres_1 field : users.id - name : amount - name : users fields : - name : id fidesops_meta : primary_key : True - name : email fidesops_meta : identity : email - name : address_id We trigger a retrieval with identity data, such as an email address or user ID, that's provided by the user. What we do is... Identify the collections that contain the identity data that the user provided. Find all related records. Use the data to find all connected data. Continue until we've found all related data. For the first step, we use the concept of an identity . In the Fidesops Dataset specification, any field may be marked with an identity notation: 1 2 3 4 5 6 collection : - name : foo fields : - name : bar fidesop_meta : identity : email What this means is that we will initiate the data retrieval process with provided data that looks like {\"email\": \"user@example.com\", \"username\": \"someone\"} by looking for values in the collection users where email == user@example.com . Note that the names of the provided starter data do not need to match the field names we're going to use this data to search. Also note that in this case, since we're providing two pieces of data, we can also choose to start a search using the username provided value. In the above diagram, this means we have enough data to search in both postgres_1.users.email and mongo_1.users.user_name .","title":"An example graph"},{"location":"guides/query_execution/#how-does-fidesops-execute-queries","text":"The next step is to follow any links provided in field relationship information. In the abbreviated dataset declarations below, you can see that since we know that mongo_1.accounts data contains data related to mongo_1.users , we can retrieve data from mongo_1.accounts by generating this set of queries: 1 2 3 4 5 6 7 8 9 10 11 # mongo_1 1 . db . users . find ( { \"user_name\" : \"someone\" } , { \"_id\" : 1 , \"full_name\" : 1 } ) 2 . db . accounts . find ( { \"name\" : { \"$in\" :[ < full_name value from ( 1 ) > ] }} , { \"_id\" : 1 , \"comments\" : 1 } ) # postgres_1 3 . select id , address_id from users where email = 'user@example.com' ; 4 . select id , amount from purchases where user_id in [ < id values from ( 3 ) > ] 5 . select id , amount , rating from purchase_items where purchase_id in [ < id values from ( 4 ) > ] # mysql_1 6 . select internal_id , comment from users where id in [ < id values from ( 3 ) > ] Logically, we are creating a linked graph using the connections you've specified between your collections to retrieve your data.","title":"How does Fidesops execute queries?"},{"location":"guides/query_execution/#notes-about-dataset-traversals","text":"You can define multiple links between collections, which will generate OR queries like SELECT a,b,c from TABLE_1 where name in (values from TABLE\\_2) OR email in (values from TABLE\\_3) . It's an error to specify a collection in your Dataset can't be reached through the relations you've specified. Fidesops uses your Datasets and your input data to \"solve\" the graph of your collections and how it is traversed. If your Dataset has multiple identity values, you can create a situation where the query behavior depends on the values you provide. In the example above, starting the graph traversal with {\"email\": \"value1\", \"username\":\" value2\"} is valid, but starting with {\"email\": \"value1\"} fails because mongo_1.users is no longer reachable. As shown in the example, you can create queries between Datasets.","title":"Notes about Dataset traversals"},{"location":"guides/reporting/","text":"How-To: Report on Privacy Requests In this section we'll cover: How to check the high-level status of your privacy requests How to get more detailed execution logs of queries that were run as part of your privacy requests. Take me directly to API docs . Overview The reporting feature allows you to fetch information about privacy requests. You can opt for high-level or more detailed information about the individual queries executed internally. High-level Status This request displays concise, high-level information for all your PrivacyRequests including their status and related timestamps. Check out the API docs here . GET api/v1/privacy-request 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \"items\" : [ { \"id\" : \"pri_5f4feff5-fb60-4286-82bd-7e0748ce90ac\" , \"created_at\" : \"2021-10-04T17:36:32.223287+00:00\" , \"started_processing_at\" : \"2021-10-04T17:36:37.248880+00:00\" , \"finished_processing_at\" : \"2021-10-04T17:36:37.263121+00:00\" , \"status\" : \"pending\" } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 } Single Privacy Request Use the id query param to view the high level status of a single privacy request. GET api/v1/privacy-request?id=<privacy_request_id> If an external_id was provided at request creation, we can also track the privacy request using: GET api/v1/privacy-request?external_id=<external_id> Privacy Request Filtering Options Use the following query params to further filter your privacy requests. Filters can be chained, for example, GET api/v1/privacy-request?created_gt=2021-10-01&created_lt=2021-10-05&status=pending id status (one of in_processing , pending , complete , or error ) created_lt created_gt started_lt started_gt completed_lt completed_gt errored_lt errored_gt View All Privacy Request Logs To view all the execution logs for a Privacy Request, visit /api/v1/privacy-request/{privacy_request_id}/logs . Embedded logs in the previous endpoints are truncated at 50 logs. Check out the API docs here . View Individual Privacy Request Log Details Use the verbose query param to see more details about individual queries run as part of the Privacy Request along with individual statuses. verbose will embed a \u201cresults\u201d key in the response, with execution logs grouped by dataset name. In the example below, we have two datasets: my-mongo-db and my-postgres-db . There is one execution log for my-mongo-db and two execution logs for my-postgres-db. The embedded execution logs are automatically truncated at 50 logs, so to view the entire list of logs, visit the execution logs endpoint separately. GET api/v1/privacy-request?verbose=True 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 { \"items\" : [ { \"id\" : \"pri_5f4feff5-fb60-4286-82bd-7e0748ce90ac\" , \"created_at\" : \"2021-10-04T17:36:32.223287+00:00\" , \"started_processing_at\" : \"2021-10-04T17:36:37.248880+00:00\" , \"finished_processing_at\" : \"2021-10-04T17:36:37.263121+00:00\" , \"status\" : \"pending\" , \"results\" : { \"my-mongo-db\" : [ { \"collection_name\" : \"order\" , \"fields_affected\" : [ { \"path\" : \"order.customer_name\" , \"field_name\" : \"name\" , \"data_categories\" : [ \"user.provided.identifiable.name\" ] } ], \"message\" : null , \"action_type\" : \"access\" , \"status\" : \"pending\" , \"updated_at\" : \"2021-10-05T18:24:55.570430+00:00\" } ], \"my-postgres-db\" : [ { \"collection_name\" : \"order\" , \"fields_affected\" : [ { \"path\" : \"order.customer_name\" , \"field_name\" : \"name\" , \"data_categories\" : [ \"user.provided.identifiable.name\" ] } ], \"message\" : null , \"action_type\" : \"access\" , \"status\" : \"pending\" , \"updated_at\" : \"2021-10-05T18:24:39.953914+00:00\" }, { \"collection_name\" : \"order\" , \"fields_affected\" : [ { \"path\" : \"order.customer_name\" , \"field_name\" : \"name\" , \"data_categories\" : [ \"user.provided.identifiable.name\" ] } ], \"message\" : null , \"action_type\" : \"access\" , \"status\" : \"pending\" , \"updated_at\" : \"2021-10-05T18:24:45.240612+00:00\" } ] } } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 }","title":"Report on Privacy Requests"},{"location":"guides/reporting/#how-to-report-on-privacy-requests","text":"In this section we'll cover: How to check the high-level status of your privacy requests How to get more detailed execution logs of queries that were run as part of your privacy requests. Take me directly to API docs .","title":"How-To: Report on Privacy Requests"},{"location":"guides/reporting/#overview","text":"The reporting feature allows you to fetch information about privacy requests. You can opt for high-level or more detailed information about the individual queries executed internally.","title":"Overview"},{"location":"guides/reporting/#high-level-status","text":"This request displays concise, high-level information for all your PrivacyRequests including their status and related timestamps. Check out the API docs here . GET api/v1/privacy-request 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \"items\" : [ { \"id\" : \"pri_5f4feff5-fb60-4286-82bd-7e0748ce90ac\" , \"created_at\" : \"2021-10-04T17:36:32.223287+00:00\" , \"started_processing_at\" : \"2021-10-04T17:36:37.248880+00:00\" , \"finished_processing_at\" : \"2021-10-04T17:36:37.263121+00:00\" , \"status\" : \"pending\" } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 }","title":"High-level Status"},{"location":"guides/reporting/#single-privacy-request","text":"Use the id query param to view the high level status of a single privacy request. GET api/v1/privacy-request?id=<privacy_request_id> If an external_id was provided at request creation, we can also track the privacy request using: GET api/v1/privacy-request?external_id=<external_id>","title":"Single Privacy Request"},{"location":"guides/reporting/#privacy-request-filtering-options","text":"Use the following query params to further filter your privacy requests. Filters can be chained, for example, GET api/v1/privacy-request?created_gt=2021-10-01&created_lt=2021-10-05&status=pending id status (one of in_processing , pending , complete , or error ) created_lt created_gt started_lt started_gt completed_lt completed_gt errored_lt errored_gt","title":"Privacy Request Filtering Options"},{"location":"guides/reporting/#view-all-privacy-request-logs","text":"To view all the execution logs for a Privacy Request, visit /api/v1/privacy-request/{privacy_request_id}/logs . Embedded logs in the previous endpoints are truncated at 50 logs. Check out the API docs here .","title":"View All Privacy Request Logs"},{"location":"guides/reporting/#view-individual-privacy-request-log-details","text":"Use the verbose query param to see more details about individual queries run as part of the Privacy Request along with individual statuses. verbose will embed a \u201cresults\u201d key in the response, with execution logs grouped by dataset name. In the example below, we have two datasets: my-mongo-db and my-postgres-db . There is one execution log for my-mongo-db and two execution logs for my-postgres-db. The embedded execution logs are automatically truncated at 50 logs, so to view the entire list of logs, visit the execution logs endpoint separately. GET api/v1/privacy-request?verbose=True 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 { \"items\" : [ { \"id\" : \"pri_5f4feff5-fb60-4286-82bd-7e0748ce90ac\" , \"created_at\" : \"2021-10-04T17:36:32.223287+00:00\" , \"started_processing_at\" : \"2021-10-04T17:36:37.248880+00:00\" , \"finished_processing_at\" : \"2021-10-04T17:36:37.263121+00:00\" , \"status\" : \"pending\" , \"results\" : { \"my-mongo-db\" : [ { \"collection_name\" : \"order\" , \"fields_affected\" : [ { \"path\" : \"order.customer_name\" , \"field_name\" : \"name\" , \"data_categories\" : [ \"user.provided.identifiable.name\" ] } ], \"message\" : null , \"action_type\" : \"access\" , \"status\" : \"pending\" , \"updated_at\" : \"2021-10-05T18:24:55.570430+00:00\" } ], \"my-postgres-db\" : [ { \"collection_name\" : \"order\" , \"fields_affected\" : [ { \"path\" : \"order.customer_name\" , \"field_name\" : \"name\" , \"data_categories\" : [ \"user.provided.identifiable.name\" ] } ], \"message\" : null , \"action_type\" : \"access\" , \"status\" : \"pending\" , \"updated_at\" : \"2021-10-05T18:24:39.953914+00:00\" }, { \"collection_name\" : \"order\" , \"fields_affected\" : [ { \"path\" : \"order.customer_name\" , \"field_name\" : \"name\" , \"data_categories\" : [ \"user.provided.identifiable.name\" ] } ], \"message\" : null , \"action_type\" : \"access\" , \"status\" : \"pending\" , \"updated_at\" : \"2021-10-05T18:24:45.240612+00:00\" } ] } } ], \"total\" : 1 , \"page\" : 1 , \"size\" : 50 }","title":"View Individual Privacy Request Log Details"},{"location":"guides/storage/","text":"How-To: Configure Storage Destinations In this section we'll cover: An overview of storage destinations How to configure storage destinations How to authenticate storage destinations How to test your storage destinations How to extend this module to create a new, custom storage destination type Take me directly to API docs Overview Access requests will produce a data package upon completion. This data will need to be uploaded to a storage destination (e.g. an S3 bucket). Fidesops never stores privacy request results locally, so you\u2019ll need to configure at least one storage destination if you wish to process Access requests. Storage destinations are configured on Rules. Multiple destinations can be configured, each of which might be used by different rules. Read more about configuring rules here Each unique destination is configured using a \"StorageConfig\", which you can create and manage via the API. To configure a StorageConfig, you'll first need to choose a storage destination type. Fidesops currently supports the following types: local - This saves upload packages locally, generating a fides_uploads directory at the root of this project. This destination type should be used only for testing purposes, never to process real-world access requests. S3 - S3 upload is straightforward, in which files are uploaded in an S3 bucket of your choosing upon completion of access requests. Use S3 if you simply need a place to store those files. OneTrust - A OneTrust storage destination should be configured if you wish to use Fidesops to process requests from an existing OneTrust integration. Read more about how our OneTrust integration works here Configuration Let's get started. To create a new StorageConfig, use the following endpoint ( API docs here ): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 PATCH { host } /api/v1/storage/config { \"destinations\" : [ { \"name\" : str, \"key\" : FidesOpsKey ( optional ) , \"type\" : str, \"format\" : str \"details\" : { # s3 \"bucket\" : str, \"naming\" : str, # onetrust \"service_name\" : str, \"onetrust_polling_hr\" : int, \"onetrust_polling_day_of_week\" : int } } ] } Params: name : A unique user-friendly name for your storage destination. key : A unique key used to manage your storage destination. This is auto-generated from name if left blank. Accepted values are alphanumeric, _ , and . . type : Type of storage destination. Supported types include s3 , onetrust , and local . You may configure multiple destinations of the same type. format : Format of uploaded data. Supported formats include json and csv . For OneTrust and local destination types, use json . Additional params needed for S3: bucket : Name of bucket in S3. naming : This defines how the uploaded files will be named. Currently, Fidesops only supports upload file naming by request_id . Use this value for all your storage destinations. Additional params needed for OneTrust: service_name : Name of your service / company. This informs OneTrust from where the data obtained from a given access request originated. onetrust_polling_hr : Hour, in UTC timezone, at which to poll OneTrust for new requests. Accepts an int from 0-23, where 0 is midnight. E.g. 7 is 7am UTC. onetrust_polling_day_of_week : Day on which to poll OneTrust for new requests. Accepts an int from 0-6 where 0 is Sunday. E.g. 1 is Monday. Additional params needed for local: naming : This defines how the uploaded files will be named. Currently, Fidesops only supports upload file naming by request_id . Use this value for all your storage destinations. On success, the response from the above endpoint will include a storage_key for each destination. Example response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"items\" : [ { \"id\" : \"sto_fe4e4dc0-b5d3-4ac1-bfcd-86e60e9891b9\" , \"name\" : \"s3 storage 2\" , \"type\" : \"s3\" , \"details\" : { \"bucket\" : \"my-bucket\" , \"naming\" : \"request_id\" , \"object_name\" : \"requests\" } , \"key\" : \"s3_storage_2\" } ] , \"total\" : 1 , \"page\" : 1 , \"size\" : 1 Authentication Next, you'll need to authenticate secrets with the specific storage destination. Authentication is not needed for the local destination type. Use the storage_key obtained from above in the following endpoint ( API docs here ): 1 2 3 4 5 6 7 8 9 10 PUT { host } /api/v1/storage/config/ { storage_key } /secret { # s3 \"aws_access_key_id\" : str, \"aws_secret_access_key\" : str # onetrust \"onetrust_hostname\" : str \"onetrust_client_id\" : str \"onetrust_client_secret\" : str } Params needed for S3: aws_access_key_id : AWS access key id, obtained from AWS console. aws_secret_access_key : AWS secret access key, obtained from AWS console. Params needed for OneTrust: onetrust_hostname : Your unique OneTrust hostname, used to call OneTrust REST APIs, e.g. my-company.onetrust onetrust_client_id : OneTrust client id, obtained from OneTrust portal. onetrust_client_secret : OneTrust client id, obtained from OneTrust portal. Currently, we do not save the secrets if credentials fail authentication with the given storage destination. Testing To test that your storage destination works correctly, you may hit the upload endpoint directly, where request_id in the path is an arbitrary string. Keep in mind that OneTrust destinations will need to be tested end-to-end, using the OneTrust interface to approve a test privacy request. To upload data to a storage destination of choice ( api docs here ): 1 2 3 4 5 6 7 PUT { host } /api/v1/storage/ { request_id } { \"storage_key\" : { storage_key } , \"data\" : { # data here } } Params: storage_key : key associated with the storage destination data : dict of arbitrary data you wish to upload to storage destination. Extensibility Need a different storage destination? Fidesops can be extended to support additional storage destinations by: Add destination-specific enums in src/fidesops/schemas/storage/storage.py Implement an authenticator in src/fidesops/service/storage/storage_authenticator_service.py Implement the uploader in src/fidesops/service/storage/storage_uploader_service.py","title":"Configure Storage Destinations"},{"location":"guides/storage/#how-to-configure-storage-destinations","text":"In this section we'll cover: An overview of storage destinations How to configure storage destinations How to authenticate storage destinations How to test your storage destinations How to extend this module to create a new, custom storage destination type Take me directly to API docs","title":"How-To: Configure Storage Destinations"},{"location":"guides/storage/#overview","text":"Access requests will produce a data package upon completion. This data will need to be uploaded to a storage destination (e.g. an S3 bucket). Fidesops never stores privacy request results locally, so you\u2019ll need to configure at least one storage destination if you wish to process Access requests. Storage destinations are configured on Rules. Multiple destinations can be configured, each of which might be used by different rules. Read more about configuring rules here Each unique destination is configured using a \"StorageConfig\", which you can create and manage via the API. To configure a StorageConfig, you'll first need to choose a storage destination type. Fidesops currently supports the following types: local - This saves upload packages locally, generating a fides_uploads directory at the root of this project. This destination type should be used only for testing purposes, never to process real-world access requests. S3 - S3 upload is straightforward, in which files are uploaded in an S3 bucket of your choosing upon completion of access requests. Use S3 if you simply need a place to store those files. OneTrust - A OneTrust storage destination should be configured if you wish to use Fidesops to process requests from an existing OneTrust integration. Read more about how our OneTrust integration works here","title":"Overview"},{"location":"guides/storage/#configuration","text":"Let's get started. To create a new StorageConfig, use the following endpoint ( API docs here ): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 PATCH { host } /api/v1/storage/config { \"destinations\" : [ { \"name\" : str, \"key\" : FidesOpsKey ( optional ) , \"type\" : str, \"format\" : str \"details\" : { # s3 \"bucket\" : str, \"naming\" : str, # onetrust \"service_name\" : str, \"onetrust_polling_hr\" : int, \"onetrust_polling_day_of_week\" : int } } ] } Params: name : A unique user-friendly name for your storage destination. key : A unique key used to manage your storage destination. This is auto-generated from name if left blank. Accepted values are alphanumeric, _ , and . . type : Type of storage destination. Supported types include s3 , onetrust , and local . You may configure multiple destinations of the same type. format : Format of uploaded data. Supported formats include json and csv . For OneTrust and local destination types, use json . Additional params needed for S3: bucket : Name of bucket in S3. naming : This defines how the uploaded files will be named. Currently, Fidesops only supports upload file naming by request_id . Use this value for all your storage destinations. Additional params needed for OneTrust: service_name : Name of your service / company. This informs OneTrust from where the data obtained from a given access request originated. onetrust_polling_hr : Hour, in UTC timezone, at which to poll OneTrust for new requests. Accepts an int from 0-23, where 0 is midnight. E.g. 7 is 7am UTC. onetrust_polling_day_of_week : Day on which to poll OneTrust for new requests. Accepts an int from 0-6 where 0 is Sunday. E.g. 1 is Monday. Additional params needed for local: naming : This defines how the uploaded files will be named. Currently, Fidesops only supports upload file naming by request_id . Use this value for all your storage destinations. On success, the response from the above endpoint will include a storage_key for each destination. Example response: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"items\" : [ { \"id\" : \"sto_fe4e4dc0-b5d3-4ac1-bfcd-86e60e9891b9\" , \"name\" : \"s3 storage 2\" , \"type\" : \"s3\" , \"details\" : { \"bucket\" : \"my-bucket\" , \"naming\" : \"request_id\" , \"object_name\" : \"requests\" } , \"key\" : \"s3_storage_2\" } ] , \"total\" : 1 , \"page\" : 1 , \"size\" : 1","title":"Configuration"},{"location":"guides/storage/#authentication","text":"Next, you'll need to authenticate secrets with the specific storage destination. Authentication is not needed for the local destination type. Use the storage_key obtained from above in the following endpoint ( API docs here ): 1 2 3 4 5 6 7 8 9 10 PUT { host } /api/v1/storage/config/ { storage_key } /secret { # s3 \"aws_access_key_id\" : str, \"aws_secret_access_key\" : str # onetrust \"onetrust_hostname\" : str \"onetrust_client_id\" : str \"onetrust_client_secret\" : str } Params needed for S3: aws_access_key_id : AWS access key id, obtained from AWS console. aws_secret_access_key : AWS secret access key, obtained from AWS console. Params needed for OneTrust: onetrust_hostname : Your unique OneTrust hostname, used to call OneTrust REST APIs, e.g. my-company.onetrust onetrust_client_id : OneTrust client id, obtained from OneTrust portal. onetrust_client_secret : OneTrust client id, obtained from OneTrust portal. Currently, we do not save the secrets if credentials fail authentication with the given storage destination.","title":"Authentication"},{"location":"guides/storage/#testing","text":"To test that your storage destination works correctly, you may hit the upload endpoint directly, where request_id in the path is an arbitrary string. Keep in mind that OneTrust destinations will need to be tested end-to-end, using the OneTrust interface to approve a test privacy request. To upload data to a storage destination of choice ( api docs here ): 1 2 3 4 5 6 7 PUT { host } /api/v1/storage/ { request_id } { \"storage_key\" : { storage_key } , \"data\" : { # data here } } Params: storage_key : key associated with the storage destination data : dict of arbitrary data you wish to upload to storage destination.","title":"Testing"},{"location":"guides/storage/#extensibility","text":"Need a different storage destination? Fidesops can be extended to support additional storage destinations by: Add destination-specific enums in src/fidesops/schemas/storage/storage.py Implement an authenticator in src/fidesops/service/storage/storage_authenticator_service.py Implement the uploader in src/fidesops/service/storage/storage_uploader_service.py","title":"Extensibility"},{"location":"postman/using_postman/","text":"Using the fidesops postman collection We include a minimal fidesops collection for executing example access and erasure privacy requests against mock external databases, and setting up the required prerequisite configuration. Loading the collection Get postman Postman > File > Import Upload the Fidesops collection found in docs/fidesops/docs/postman/Fidesops.postman_collection.json Click on the imported Fidesops collection in the left pane and then find Variables to edit Fidesops collection variables. Some variables are populated for you - the authentication variables you will have to add yourself below. Add your OAUTH_ROOT_CLIENT_ID and OAUTH_ROOT_CLIENT_SECRET under CURRENT VALUE . I'm adding fidesopsadmin and fidesopsadmin secret, but you should add the appropriate values for your instance. Important: Click Save Bring up local servers and mock databases Run make integration-env in your terminal to bring up the fidesops server, redis , the fidesops postgres database, and some mock external databases like mongodb_example and postgres_example pre-populated with test data, to represent your datastores. Note: We'll be working through the list of requests in the Minimum API calls to create an Access Privacy Request folder. Some of the returned data will need to be saved as additional Fidesops variables for use in other steps. Saving Authentication variables Click on the Get Root Client Token request and then click Send to send a POST request to fidesops to create a root token. Copy the returned access token in the response body and paste it as the Current Value of root_client_token in Fidesops variables and click \"Save\". Similarly, click on the next Create Client request and click Send to send POST request fo fidesops to create a client. Copy the client_id and client_secret and paste into Current Value slots in Fidesops variables and click \"Save\". Finally, click on the Get Client Token request, and then click Send to send a POST request to create a token for the client we created in the previous step. Note: If you click on \"Body\" you can see that the client_id and client_secret have been added as form data for you. Save the returned token under client_token Current Value in the Fidesops variables. The client_token will be automatically passed into the rest of your requests as the Bearer Token. Building out remaining privacy request configuration Run through the remaining requests in the Minimum API calls to create an Access Privacy Request folder. Because variables are automatically being populated for you, you should be able to click on each request, clicking \"Send\" for each one. Inspect the Body of each request to see what we're sending to fidesops: Specify where your data is going SEND Create/Update Storage - Local Storage Config - Sets up a local folder which we'll upload your privacy request results (for local testing only) Configure what data we care about and what we'll do with it SEND Create/Update Policies - Creates a Policy where we'll start to spell out how to handle Privacy Requests SEND Create/Update Access Rule - Define an access Rule on that Policy that specifies results will be uploaded to our local storage SEND Create/Update Rule Targets - Specify a RuleTarget that says we will return data that has been marked as having a user.provided.identifiable data category Create ConnectionConfigs and add connection secrets for our postgres_example and mongodb_example mock databases: SEND Create/Update Connection Configs: Postgres SEND Create/Update Connection Configs: Mongo SEND Update Connection Secrets: Postgres SEND Update Connection Secrets: Mongo Add our annotations of the Postgres and Mongo datastores SEND Create/Update Postgres Dataset SEND Create/Update Dataset Mongo Note: API calls to additional supported datastores (MsSQL, MySQL) are in separate folders within the collection. Run a privacy request Now, we should have all the basic pieces needed to create an Access request. 1. SEND Create Access Privacy Requests - If \"succeeded\", note the \"id\" that is returned. Note that succeeded means the privacy request has been created, and is pending, not that its execution is complete. Check your local fides_uploads folder that we configured earlier to see access request results. This is run asynchronously, so it may take a few moments to complete. This particular request should have retrieved data from both the postgres_example and mongodb_example databases with the user.provided.identifiable data_category Check out other requests in the collection - the Calls to create an Erasure Request folder, walks you through configuring a separate erasure policy and executing an erasure request. Note that these erasure requests will mask data in your connected datastores ( postgres_example and mongo_example here). If you connect your own live databases, data may be deleted. Happy experimenting!","title":"Using the fidesops postman collection"},{"location":"postman/using_postman/#using-the-fidesops-postman-collection","text":"We include a minimal fidesops collection for executing example access and erasure privacy requests against mock external databases, and setting up the required prerequisite configuration.","title":"Using the fidesops postman collection"},{"location":"postman/using_postman/#loading-the-collection","text":"Get postman Postman > File > Import Upload the Fidesops collection found in docs/fidesops/docs/postman/Fidesops.postman_collection.json Click on the imported Fidesops collection in the left pane and then find Variables to edit Fidesops collection variables. Some variables are populated for you - the authentication variables you will have to add yourself below. Add your OAUTH_ROOT_CLIENT_ID and OAUTH_ROOT_CLIENT_SECRET under CURRENT VALUE . I'm adding fidesopsadmin and fidesopsadmin secret, but you should add the appropriate values for your instance. Important: Click Save","title":"Loading the collection"},{"location":"postman/using_postman/#bring-up-local-servers-and-mock-databases","text":"Run make integration-env in your terminal to bring up the fidesops server, redis , the fidesops postgres database, and some mock external databases like mongodb_example and postgres_example pre-populated with test data, to represent your datastores. Note: We'll be working through the list of requests in the Minimum API calls to create an Access Privacy Request folder. Some of the returned data will need to be saved as additional Fidesops variables for use in other steps.","title":"Bring up local servers and mock databases"},{"location":"postman/using_postman/#saving-authentication-variables","text":"Click on the Get Root Client Token request and then click Send to send a POST request to fidesops to create a root token. Copy the returned access token in the response body and paste it as the Current Value of root_client_token in Fidesops variables and click \"Save\". Similarly, click on the next Create Client request and click Send to send POST request fo fidesops to create a client. Copy the client_id and client_secret and paste into Current Value slots in Fidesops variables and click \"Save\". Finally, click on the Get Client Token request, and then click Send to send a POST request to create a token for the client we created in the previous step. Note: If you click on \"Body\" you can see that the client_id and client_secret have been added as form data for you. Save the returned token under client_token Current Value in the Fidesops variables. The client_token will be automatically passed into the rest of your requests as the Bearer Token.","title":"Saving Authentication variables"},{"location":"postman/using_postman/#building-out-remaining-privacy-request-configuration","text":"Run through the remaining requests in the Minimum API calls to create an Access Privacy Request folder. Because variables are automatically being populated for you, you should be able to click on each request, clicking \"Send\" for each one. Inspect the Body of each request to see what we're sending to fidesops: Specify where your data is going SEND Create/Update Storage - Local Storage Config - Sets up a local folder which we'll upload your privacy request results (for local testing only) Configure what data we care about and what we'll do with it SEND Create/Update Policies - Creates a Policy where we'll start to spell out how to handle Privacy Requests SEND Create/Update Access Rule - Define an access Rule on that Policy that specifies results will be uploaded to our local storage SEND Create/Update Rule Targets - Specify a RuleTarget that says we will return data that has been marked as having a user.provided.identifiable data category Create ConnectionConfigs and add connection secrets for our postgres_example and mongodb_example mock databases: SEND Create/Update Connection Configs: Postgres SEND Create/Update Connection Configs: Mongo SEND Update Connection Secrets: Postgres SEND Update Connection Secrets: Mongo Add our annotations of the Postgres and Mongo datastores SEND Create/Update Postgres Dataset SEND Create/Update Dataset Mongo Note: API calls to additional supported datastores (MsSQL, MySQL) are in separate folders within the collection.","title":"Building out remaining privacy request configuration"},{"location":"postman/using_postman/#run-a-privacy-request","text":"Now, we should have all the basic pieces needed to create an Access request. 1. SEND Create Access Privacy Requests - If \"succeeded\", note the \"id\" that is returned. Note that succeeded means the privacy request has been created, and is pending, not that its execution is complete. Check your local fides_uploads folder that we configured earlier to see access request results. This is run asynchronously, so it may take a few moments to complete. This particular request should have retrieved data from both the postgres_example and mongodb_example databases with the user.provided.identifiable data_category Check out other requests in the collection - the Calls to create an Erasure Request folder, walks you through configuring a separate erasure policy and executing an erasure request. Note that these erasure requests will mask data in your connected datastores ( postgres_example and mongo_example here). If you connect your own live databases, data may be deleted. Happy experimenting!","title":"Run a privacy request"},{"location":"tutorial/","text":"Tutorial Going from Zero to Privacy Request in Ten Minutes In this tutorial, we will be walking through the steps needed to execute a Privacy Request against an application. We will install fidesops in a test app and write a Python script that will make a series of API requests to fidesops to set up the required configuration, like the connection to an app's database, the instructions on how to traverse its tables, and where to upload any data it finds. Finally, we'll execute an access request to fetch all the data that our test application has collected about a customer.","title":"Zero to Privacy Request"},{"location":"tutorial/#tutorial","text":"","title":"Tutorial"},{"location":"tutorial/#going-from-zero-to-privacy-request-in-ten-minutes","text":"In this tutorial, we will be walking through the steps needed to execute a Privacy Request against an application. We will install fidesops in a test app and write a Python script that will make a series of API requests to fidesops to set up the required configuration, like the connection to an app's database, the instructions on how to traverse its tables, and where to upload any data it finds. Finally, we'll execute an access request to fetch all the data that our test application has collected about a customer.","title":"Going from Zero to Privacy Request in Ten Minutes"},{"location":"tutorial/annotate_datasets/","text":"Create DatasetConfigs Annotate Datasets with fidesops_meta For more detailed information, see the Datasets Guide . Next, fidesops needs to know how to traverse through our Flask App's database tables. We should upload a YAML file that describes our Flask App's database in a language that Fides understands. See fidesdemo/fides_resources/flaskr_postgres_dataset.yml where we've already annotated the tables and fields in our Postgres database with the relevant Data Categories. We just need a few more annotations: Add a fidesops_meta attribute to flaskr_postgres_dataset.collections.seller_id . Fidesops will be able to take the users id and use that to look up the seller_id . 1 2 3 4 5 6 7 - name : seller_id data_categories : [ user.derived.identifiable.unique_id ] fidesops_meta : references : - dataset : flaskr_postgres_dataset field : users.id direction : from Similarly, add a fidesops_meta attribute to flaskr_postgres_dataset.purchases.buyer_id Fidesops will be able to take the user id and use that to look up purchases by buyer_id . 1 2 3 4 5 6 7 - name : buyer_id data_categories : [ user.derived.identifiable.unique_id ] fidesops_meta : references : - dataset : flaskr_postgres_dataset field : users.id direction : from Lastly, annotate flaskr_postgres_dataset.users.email field. This is our entry point: Fidesops will first look up the user by email , and from there, travel through other tables linked to user . 1 2 3 4 - name : email data_categories : [ user.provided.identifiable.contact.email ] fidesops_meta : identity : email Upload this Dataset to Fidesops For more detailed information, see the Datasets Guide . We need to create a method that takes the Dataset we've just annotated and upload it to fidesops: Define helper method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def create_dataset ( connection_key , yaml_path , access_token ): \"\"\" Create a Dataset in fidesops given a YAML manifest file. Requires the `connection_key` for the PostgreSQL connection, and `yaml_path` that is a local filepath to a .yml Dataset Fides manifest file. Returns the response JSON if successful, or throws an error otherwise. See http://localhost:8000/api#operations-tag-Datasets \"\"\" with open ( yaml_path , \"r\" ) as file : dataset = yaml . safe_load ( file ) . get ( \"dataset\" , [])[ 0 ] dataset_create_data = [ dataset ] response = requests . patch ( f \" { FIDESOPS_URL } /api/v1/connection/ { connection_key } /dataset\" , headers = oauth_headers ( access_token = access_token ), json = dataset_create_data , ) logger . info ( f \"Creating an annotated Dataset. Status { response . status_code } \" ) return response . json () Call helper method to create a dataset Our connection_key is the flaskr_postgres ConnectionConfig we created in the previous step, and we're also passing in our completed YAML file: 1 2 3 4 5 6 7 8 9 if __name__ == \"__main__\" : ... # Upload the Dataset YAML for our PostgreSQL schema datasets = create_dataset ( connection_key = \"flaskr_postgres\" , yaml_path = \"fides_resources/flaskr_postgres_dataset.yml\" , access_token = access_token , ) ...","title":"Annotating our Database"},{"location":"tutorial/annotate_datasets/#create-datasetconfigs","text":"","title":"Create DatasetConfigs"},{"location":"tutorial/annotate_datasets/#annotate-datasets-with-fidesops_meta","text":"For more detailed information, see the Datasets Guide . Next, fidesops needs to know how to traverse through our Flask App's database tables. We should upload a YAML file that describes our Flask App's database in a language that Fides understands. See fidesdemo/fides_resources/flaskr_postgres_dataset.yml where we've already annotated the tables and fields in our Postgres database with the relevant Data Categories. We just need a few more annotations: Add a fidesops_meta attribute to flaskr_postgres_dataset.collections.seller_id . Fidesops will be able to take the users id and use that to look up the seller_id . 1 2 3 4 5 6 7 - name : seller_id data_categories : [ user.derived.identifiable.unique_id ] fidesops_meta : references : - dataset : flaskr_postgres_dataset field : users.id direction : from Similarly, add a fidesops_meta attribute to flaskr_postgres_dataset.purchases.buyer_id Fidesops will be able to take the user id and use that to look up purchases by buyer_id . 1 2 3 4 5 6 7 - name : buyer_id data_categories : [ user.derived.identifiable.unique_id ] fidesops_meta : references : - dataset : flaskr_postgres_dataset field : users.id direction : from Lastly, annotate flaskr_postgres_dataset.users.email field. This is our entry point: Fidesops will first look up the user by email , and from there, travel through other tables linked to user . 1 2 3 4 - name : email data_categories : [ user.provided.identifiable.contact.email ] fidesops_meta : identity : email","title":"Annotate Datasets with fidesops_meta"},{"location":"tutorial/annotate_datasets/#upload-this-dataset-to-fidesops","text":"For more detailed information, see the Datasets Guide . We need to create a method that takes the Dataset we've just annotated and upload it to fidesops:","title":"Upload this Dataset to Fidesops"},{"location":"tutorial/annotate_datasets/#define-helper-method","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def create_dataset ( connection_key , yaml_path , access_token ): \"\"\" Create a Dataset in fidesops given a YAML manifest file. Requires the `connection_key` for the PostgreSQL connection, and `yaml_path` that is a local filepath to a .yml Dataset Fides manifest file. Returns the response JSON if successful, or throws an error otherwise. See http://localhost:8000/api#operations-tag-Datasets \"\"\" with open ( yaml_path , \"r\" ) as file : dataset = yaml . safe_load ( file ) . get ( \"dataset\" , [])[ 0 ] dataset_create_data = [ dataset ] response = requests . patch ( f \" { FIDESOPS_URL } /api/v1/connection/ { connection_key } /dataset\" , headers = oauth_headers ( access_token = access_token ), json = dataset_create_data , ) logger . info ( f \"Creating an annotated Dataset. Status { response . status_code } \" ) return response . json ()","title":"Define helper method"},{"location":"tutorial/annotate_datasets/#call-helper-method-to-create-a-dataset","text":"Our connection_key is the flaskr_postgres ConnectionConfig we created in the previous step, and we're also passing in our completed YAML file: 1 2 3 4 5 6 7 8 9 if __name__ == \"__main__\" : ... # Upload the Dataset YAML for our PostgreSQL schema datasets = create_dataset ( connection_key = \"flaskr_postgres\" , yaml_path = \"fides_resources/flaskr_postgres_dataset.yml\" , access_token = access_token , ) ...","title":"Call helper method to create a dataset"},{"location":"tutorial/define_policy/","text":"Define Policies Creating a Policy with Rules and Targets For more detailed information, see the Policy Guide . We're almost there: we need to create a Policy to describe how to handle a Privacy Request. Very detailed configurations are supported to define how different data is treated. You can create Policies with multiple Rules (how the data is handled), that each have Rule Targets (what data we care about). Below are methods to add a Policy, a Rule, and a Rule Target, plus a cleanup method that deletes Rules for convenience (handy if you'll be running this script multiple times). Define helper methods 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 ... def create_policy ( key , access_token ): \"\"\" Create a request policy in fidesops with the given key.Returns the response JSON if successful, or throws an error otherwise. See http://localhost:8000/api#operations-Policy-create_or_update_policies_api_v1_policy_put \"\"\" policy_create_data = [ { \"name\" : key , \"key\" : key , }, ] response = requests . patch ( f \" { FIDESOPS_URL } /api/v1/policy\" , headers = oauth_headers ( access_token = access_token ), json = policy_create_data , ) logger . info ( f \"Creating a Policy. Status { response . status_code } \" ) return response . json () ``` ``` python ... def create_policy_rule ( policy_key , key , action_type , storage_destination_key , access_token ): \"\"\" Create a Policy Rule to return matched data in an access request to the given Storage destination. Returns the response JSON if successful, or throws an error otherwise. See http://localhost:8000/api#operations-Policy-create_or_update_policies_api_v1_policy_put \"\"\" rule_create_data = [ { \"name\" : key , \"key\" : key , \"action_type\" : action_type , \"storage_destination_key\" : storage_destination_key , }, ] response = requests . patch ( f \" { FIDESOPS_URL } /api/v1/policy/ { policy_key } /rule\" , headers = oauth_headers ( access_token = access_token ), json = rule_create_data , ) logger . info ( f \"Creating a rule. Status { response . status_code } \" ) return response . json () 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ... def create_policy_rule_target ( policy_key , rule_key , data_category , access_token ): \"\"\" Create a Policy Rule Target that matches the given data_category. Returns the response JSON if successful, or throws an error otherwise. See http://localhost:8000/api#operations-Policy-create_or_update_rules_api_v1_policy__policy_key__rule_put \"\"\" target_create_data = [ { \"data_category\" : data_category , }, ] response = requests . patch ( f \" { FIDESOPS_URL } /api/v1/policy/ { policy_key } /rule/ { rule_key } /target\" , headers = oauth_headers ( access_token = access_token ), json = target_create_data , ) logger . info ( f \"Creating a Rule Target. Status { response . status_code } \" ) return response . json () 1 2 3 4 5 6 7 8 9 10 11 ... def delete_policy_rule ( policy_key , key , access_token ): \"\"\" Deletes a Policy rule with the given key. Returns the response JSON. See http://localhost:8000/api#operations-Policy-delete_rule_api_v1_policy__policy_key__rule__rule_key__delete \"\"\" return requests . delete ( f \" { FIDESOPS_URL } /api/v1/policy/ { policy_key } /rule/ { key } \" , headers = oauth_headers ( access_token = access_token ), ) Call helper methods to create the Policy For simplicity's sake, let's just create one Policy, one Rule, and one Target. Our single Policy will have one Rule with type access , meaning we just want to retrieve user data, not delete it. We also configure on the Rule that any results will be uploaded to our local Storage example_storage . Finally, we create a RuleTarget, that is looking for all data with the category user.provided.identifiable (and included subcategories). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 if __name__ == \"__main__\" : ... # Create a Policy that returns all user data policy = create_policy ( key = \"example_request_policy\" , access_token = access_token , ) delete_policy_rule ( \"example_request_policy\" , \"access_user_data\" , access_token ) create_policy_rule ( policy_key = \"example_request_policy\" , key = \"access_user_data\" , action_type = \"access\" , storage_destination_key = \"example_storage\" , access_token = access_token , ) data_category = \"user.provided.identifiable\" create_policy_rule_target ( \"example_request_policy\" , \"access_user_data\" , data_category , access_token ) If you look back at our annotated YAML fides_resources/flaskr_postgres_dataset.yml , we can see the relevant fields associated with this Data Category that we will expect in our final upload package: 1 2 3 - `products` collection: `description`,`name`, and `price` - `user` collection: `email`, `first_name`, `last_name`, and `password` - `purchases` collection`: `city`, `state`, `street_1`, `street_2`, and `zip`","title":"Defining a Policy"},{"location":"tutorial/define_policy/#define-policies","text":"","title":"Define Policies"},{"location":"tutorial/define_policy/#creating-a-policy-with-rules-and-targets","text":"For more detailed information, see the Policy Guide . We're almost there: we need to create a Policy to describe how to handle a Privacy Request. Very detailed configurations are supported to define how different data is treated. You can create Policies with multiple Rules (how the data is handled), that each have Rule Targets (what data we care about). Below are methods to add a Policy, a Rule, and a Rule Target, plus a cleanup method that deletes Rules for convenience (handy if you'll be running this script multiple times).","title":"Creating a Policy with Rules and Targets"},{"location":"tutorial/define_policy/#define-helper-methods","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 ... def create_policy ( key , access_token ): \"\"\" Create a request policy in fidesops with the given key.Returns the response JSON if successful, or throws an error otherwise. See http://localhost:8000/api#operations-Policy-create_or_update_policies_api_v1_policy_put \"\"\" policy_create_data = [ { \"name\" : key , \"key\" : key , }, ] response = requests . patch ( f \" { FIDESOPS_URL } /api/v1/policy\" , headers = oauth_headers ( access_token = access_token ), json = policy_create_data , ) logger . info ( f \"Creating a Policy. Status { response . status_code } \" ) return response . json () ``` ``` python ... def create_policy_rule ( policy_key , key , action_type , storage_destination_key , access_token ): \"\"\" Create a Policy Rule to return matched data in an access request to the given Storage destination. Returns the response JSON if successful, or throws an error otherwise. See http://localhost:8000/api#operations-Policy-create_or_update_policies_api_v1_policy_put \"\"\" rule_create_data = [ { \"name\" : key , \"key\" : key , \"action_type\" : action_type , \"storage_destination_key\" : storage_destination_key , }, ] response = requests . patch ( f \" { FIDESOPS_URL } /api/v1/policy/ { policy_key } /rule\" , headers = oauth_headers ( access_token = access_token ), json = rule_create_data , ) logger . info ( f \"Creating a rule. Status { response . status_code } \" ) return response . json () 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ... def create_policy_rule_target ( policy_key , rule_key , data_category , access_token ): \"\"\" Create a Policy Rule Target that matches the given data_category. Returns the response JSON if successful, or throws an error otherwise. See http://localhost:8000/api#operations-Policy-create_or_update_rules_api_v1_policy__policy_key__rule_put \"\"\" target_create_data = [ { \"data_category\" : data_category , }, ] response = requests . patch ( f \" { FIDESOPS_URL } /api/v1/policy/ { policy_key } /rule/ { rule_key } /target\" , headers = oauth_headers ( access_token = access_token ), json = target_create_data , ) logger . info ( f \"Creating a Rule Target. Status { response . status_code } \" ) return response . json () 1 2 3 4 5 6 7 8 9 10 11 ... def delete_policy_rule ( policy_key , key , access_token ): \"\"\" Deletes a Policy rule with the given key. Returns the response JSON. See http://localhost:8000/api#operations-Policy-delete_rule_api_v1_policy__policy_key__rule__rule_key__delete \"\"\" return requests . delete ( f \" { FIDESOPS_URL } /api/v1/policy/ { policy_key } /rule/ { key } \" , headers = oauth_headers ( access_token = access_token ), )","title":"Define helper methods"},{"location":"tutorial/define_policy/#call-helper-methods-to-create-the-policy","text":"For simplicity's sake, let's just create one Policy, one Rule, and one Target. Our single Policy will have one Rule with type access , meaning we just want to retrieve user data, not delete it. We also configure on the Rule that any results will be uploaded to our local Storage example_storage . Finally, we create a RuleTarget, that is looking for all data with the category user.provided.identifiable (and included subcategories). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 if __name__ == \"__main__\" : ... # Create a Policy that returns all user data policy = create_policy ( key = \"example_request_policy\" , access_token = access_token , ) delete_policy_rule ( \"example_request_policy\" , \"access_user_data\" , access_token ) create_policy_rule ( policy_key = \"example_request_policy\" , key = \"access_user_data\" , action_type = \"access\" , storage_destination_key = \"example_storage\" , access_token = access_token , ) data_category = \"user.provided.identifiable\" create_policy_rule_target ( \"example_request_policy\" , \"access_user_data\" , data_category , access_token ) If you look back at our annotated YAML fides_resources/flaskr_postgres_dataset.yml , we can see the relevant fields associated with this Data Category that we will expect in our final upload package: 1 2 3 - `products` collection: `description`,`name`, and `price` - `user` collection: `email`, `first_name`, `last_name`, and `password` - `purchases` collection`: `city`, `state`, `street_1`, `street_2`, and `zip`","title":"Call helper methods to create the Policy"},{"location":"tutorial/execute_privacy_request/","text":"Execute a Privacy Request See a Privacy Request in Action For more detailed information, see the Privacy Request Guide . To summarize so far, we have: 1 2 3 4 5 1) Created a client for authentication 2) Created a connection from fidesops to our Flask App's Postgres Database 3) Uploaded an annotated Dataset to fidesops so it knows how to traverse through the Flask App's tables 4) Defined where to upload our user data after we've retrieved it from the Flask App 5) Defined Policies describing what data we're looking for and what to do with that data. For our last step, we'll write a method that will let us create a Privacy Request. We need to specify the Policy we want applied to that Privacy Request, as well as the starting identity of the user we'll need to locate the remaining user information: Define helper method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def create_privacy_request ( email , policy_key , access_token ): \"\"\" Create a Privacy Request that is executed against the given request Policy. Returns the response JSON if successful, or throws an error otherwise. See http://localhost:8000/api#operations-Privacy_Requests-create_privacy_request_api_v1_privacy_request_post \"\"\" privacy_request_data = [ { \"requested_at\" : datetime ( 2021 , 1 , 1 ) . isoformat (), \"policy_key\" : policy_key , \"identity\" : { \"email\" : email }, }, ] response = requests . post ( f \" { FIDESOPS_URL } /api/v1/privacy-request\" , headers = oauth_headers ( access_token = access_token ), json = privacy_request_data , ) logger . info ( f \"Executing a Privacy Request. Status { response . status_code } \" ) logger . info ( f \"Check fidesdemo/fidesuploads for upload package.\" ) return response . json () Call helper method to run Privacy Request This will create a request to fetch for all user data with category user.provided.identifiable associated with email user@example.com and save it to our local Storage destination, by specifying the email and the Policy. 1 2 3 4 5 6 7 8 9 10 ... if __name__ == \"__main__\" : ... # Execute a Privacy Request for user@example.com email = \"user@example.com\" privacy_requests = create_privacy_request ( email = email , policy_key = \"example_request_policy\" , access_token = access_token , ) Execute our Privacy Request In your terminal, within the fidesdemo directory, we'll run our script to execute the Privacy Request: 1 python3 flaskr/fidesops.py 1 2 3 4 5 6 7 8 9 10 11 12 13 INFO:__main__:Creating access token. Status 200 INFO:__main__:Creating Oauth Client. Status 200 INFO:__main__:Adding scopes to oauth client. Status 200 INFO:__main__:Creating access token. Status 200 INFO:__main__:Creating PostgreSQL ConnectionConfig. Status 200 INFO:__main__:Updating PostgreSQL Secrets. Status 200 . INFO:__main__:Defining an upload location. Status 200 INFO:__main__:Creating an annotated Dataset. Status 200 INFO:__main__:Creating a Policy. Status 200 INFO:__main__:Creating a Rule. Status 200 INFO:__main__:Creating a Rule Target. Status 200 INFO:__main__:Executing a Privacy Request. Status 200 INFO:__main__:Check fidesdemo/fidesuploads for upload package. Check your fidesdemo/fides_uploads directory for your data package (you may have to wait a few moments for the file to appear): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \"flaskr_postgres_dataset:products\" : [ { \"description\" : \"A description for example product #3\" , \"name\" : \"Example Product 3\" , \"price\" : 50 } ], \"flaskr_postgres_dataset:purchases\" : [ { \"city\" : \"Exampletown\" , \"state\" : \"NY\" , \"street_1\" : \"123 Example St\" , \"street_2\" : \"Apt 123\" , \"zip\" : \"12345\" } ], \"flaskr_postgres_dataset:users\" : [ { \"email\" : \"user@example.com\" , \"first_name\" : \"Example\" , \"last_name\" : \"User\" , \"password\" : \"pbkdf2:sha256:260000$PGcBy5NzZeDdlu0b$a91ee29eefad98920fe47a6ef4d53b5abffe593300f766f02de041af93ae51f8\" } ] } Issues? Is make server running? Reference the full script here for pieces you may be missing. This script has more detailed logging and error handling. Make sure your dataset is annotated properly Add breakpoints by inserting import pdb; pdb.set_trace() into the line where you want the breakpoint to set, then run your script. Many of the endpoints used here are Bulk endpoints that return a 200 and then a mixture of a succeeded/failed resources. Check the docker logs: 1 docker ps 1 2 3 4 5 6 Name Command State Ports ------------------------------------------------------------------------------------------------------------------ fidesdemo_db_1 docker-entrypoint.sh postgres Up 0 .0.0.0:5432->5432/tcp,:::5432->5432/tcp fidesdemo_fidesctl_1 fidesctl webserver Up 0 .0.0.0:8080->8080/tcp,:::8080->8080/tcp fidesdemo_fidesops_1 fidesops webserver Up 8000 /tcp, 0 .0.0.0:8000->8080/tcp,:::8000->8080/tcp fidesdemo_redis_1 docker-entrypoint.sh redis ... Up 0 .0.0.0:6379->6379/tcp,:::6379->6379/tcp 1 docker logs fidesdemo_fidesops_1","title":"Executing a Privacy Request"},{"location":"tutorial/execute_privacy_request/#execute-a-privacy-request","text":"","title":"Execute a Privacy Request"},{"location":"tutorial/execute_privacy_request/#see-a-privacy-request-in-action","text":"For more detailed information, see the Privacy Request Guide . To summarize so far, we have: 1 2 3 4 5 1) Created a client for authentication 2) Created a connection from fidesops to our Flask App's Postgres Database 3) Uploaded an annotated Dataset to fidesops so it knows how to traverse through the Flask App's tables 4) Defined where to upload our user data after we've retrieved it from the Flask App 5) Defined Policies describing what data we're looking for and what to do with that data. For our last step, we'll write a method that will let us create a Privacy Request. We need to specify the Policy we want applied to that Privacy Request, as well as the starting identity of the user we'll need to locate the remaining user information:","title":"See a Privacy Request in Action"},{"location":"tutorial/execute_privacy_request/#define-helper-method","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def create_privacy_request ( email , policy_key , access_token ): \"\"\" Create a Privacy Request that is executed against the given request Policy. Returns the response JSON if successful, or throws an error otherwise. See http://localhost:8000/api#operations-Privacy_Requests-create_privacy_request_api_v1_privacy_request_post \"\"\" privacy_request_data = [ { \"requested_at\" : datetime ( 2021 , 1 , 1 ) . isoformat (), \"policy_key\" : policy_key , \"identity\" : { \"email\" : email }, }, ] response = requests . post ( f \" { FIDESOPS_URL } /api/v1/privacy-request\" , headers = oauth_headers ( access_token = access_token ), json = privacy_request_data , ) logger . info ( f \"Executing a Privacy Request. Status { response . status_code } \" ) logger . info ( f \"Check fidesdemo/fidesuploads for upload package.\" ) return response . json ()","title":"Define helper method"},{"location":"tutorial/execute_privacy_request/#call-helper-method-to-run-privacy-request","text":"This will create a request to fetch for all user data with category user.provided.identifiable associated with email user@example.com and save it to our local Storage destination, by specifying the email and the Policy. 1 2 3 4 5 6 7 8 9 10 ... if __name__ == \"__main__\" : ... # Execute a Privacy Request for user@example.com email = \"user@example.com\" privacy_requests = create_privacy_request ( email = email , policy_key = \"example_request_policy\" , access_token = access_token , )","title":"Call helper method to run Privacy Request"},{"location":"tutorial/execute_privacy_request/#execute-our-privacy-request","text":"In your terminal, within the fidesdemo directory, we'll run our script to execute the Privacy Request: 1 python3 flaskr/fidesops.py 1 2 3 4 5 6 7 8 9 10 11 12 13 INFO:__main__:Creating access token. Status 200 INFO:__main__:Creating Oauth Client. Status 200 INFO:__main__:Adding scopes to oauth client. Status 200 INFO:__main__:Creating access token. Status 200 INFO:__main__:Creating PostgreSQL ConnectionConfig. Status 200 INFO:__main__:Updating PostgreSQL Secrets. Status 200 . INFO:__main__:Defining an upload location. Status 200 INFO:__main__:Creating an annotated Dataset. Status 200 INFO:__main__:Creating a Policy. Status 200 INFO:__main__:Creating a Rule. Status 200 INFO:__main__:Creating a Rule Target. Status 200 INFO:__main__:Executing a Privacy Request. Status 200 INFO:__main__:Check fidesdemo/fidesuploads for upload package. Check your fidesdemo/fides_uploads directory for your data package (you may have to wait a few moments for the file to appear): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \"flaskr_postgres_dataset:products\" : [ { \"description\" : \"A description for example product #3\" , \"name\" : \"Example Product 3\" , \"price\" : 50 } ], \"flaskr_postgres_dataset:purchases\" : [ { \"city\" : \"Exampletown\" , \"state\" : \"NY\" , \"street_1\" : \"123 Example St\" , \"street_2\" : \"Apt 123\" , \"zip\" : \"12345\" } ], \"flaskr_postgres_dataset:users\" : [ { \"email\" : \"user@example.com\" , \"first_name\" : \"Example\" , \"last_name\" : \"User\" , \"password\" : \"pbkdf2:sha256:260000$PGcBy5NzZeDdlu0b$a91ee29eefad98920fe47a6ef4d53b5abffe593300f766f02de041af93ae51f8\" } ] }","title":"Execute our Privacy Request"},{"location":"tutorial/execute_privacy_request/#issues","text":"Is make server running? Reference the full script here for pieces you may be missing. This script has more detailed logging and error handling. Make sure your dataset is annotated properly Add breakpoints by inserting import pdb; pdb.set_trace() into the line where you want the breakpoint to set, then run your script. Many of the endpoints used here are Bulk endpoints that return a 200 and then a mixture of a succeeded/failed resources. Check the docker logs: 1 docker ps 1 2 3 4 5 6 Name Command State Ports ------------------------------------------------------------------------------------------------------------------ fidesdemo_db_1 docker-entrypoint.sh postgres Up 0 .0.0.0:5432->5432/tcp,:::5432->5432/tcp fidesdemo_fidesctl_1 fidesctl webserver Up 0 .0.0.0:8080->8080/tcp,:::8080->8080/tcp fidesdemo_fidesops_1 fidesops webserver Up 8000 /tcp, 0 .0.0.0:8000->8080/tcp,:::8000->8080/tcp fidesdemo_redis_1 docker-entrypoint.sh redis ... Up 0 .0.0.0:6379->6379/tcp,:::6379->6379/tcp 1 docker logs fidesdemo_fidesops_1","title":"Issues?"},{"location":"tutorial/installation/","text":"Installation Clone the fidesdemo repo Let's clone Fides Demo , and rewind to an earlier tag, so we can build out the later commits together. Among other things, this will give us a Flask App to mimic your application and some YAML files that annotate the Flask App's databases. 1 2 3 4 5 git clone https://github.com/ethyca/fidesdemo cd fidesdemo git checkout fidesctl-demo make install source venv/bin/activate You can run make server and visit http://127.0.0.1:5000/ to explore the test app. It is a simple e-commerce marketplace where users can buy and sell products. Install fidesops in our test app We need to install fidesops in the test app, add a PostgreSQL database (for storing Fidesops resources) and a Redis cache (for temporarily storing incoming PII). You'll notice that a postgres container has already been set up for you, and fidesctl is installed (although we won't dive into that tool here). In the Flask App's docker-compose file, add both a container for redis and fidesops services beneath the fidesctl service : fidesdemo/docker-compose.yml : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 services : ... redis : image : \"redis:6.2.5-alpine\" command : redis-server --requirepass redispass expose : - 6379 ports : - \"6379:6379\" fidesops : image : ethyca/fidesops:latest depends_on : - db - redis command : fidesops webserver volumes : - ./fides_uploads:/fidesops/fides_uploads expose : - 8000 ports : - \"8000:8080\" environment : - FIDESOPS__SECURITY__APP_ENCRYPTION_KEY=QLMI5I0xLWUXE4JN4Asnba79JiBHWWM3 - FIDESOPS__SECURITY__OAUTH_ROOT_CLIENT_ID=fidesopsadmin - FIDESOPS__SECURITY__OAUTH_ROOT_CLIENT_SECRET=fidesopsadminsecret - FIDESOPS__DATABASE__SERVER=db - FIDESOPS__DATABASE__USER=postgres - FIDESOPS__DATABASE__PASSWORD=postgres - FIDESOPS__DATABASE__DB=fidesops - FIDESOPS__DATABASE__PORT=5432 - FIDESOPS__REDIS__HOST=redis - FIDESOPS__REDIS__PORT=6379 - FIDESOPS__REDIS__PASSWORD=redispass Verify that fidesops is installed Run make_server again: 1 2 cd fidesdemo make server Visit http://localhost:8000/docs to check that fidesops is up and running and preview the set of API endpoints that are available for us to run requests on fidesops.","title":"Installing Fidesops"},{"location":"tutorial/installation/#installation","text":"","title":"Installation"},{"location":"tutorial/installation/#clone-the-fidesdemo-repo","text":"Let's clone Fides Demo , and rewind to an earlier tag, so we can build out the later commits together. Among other things, this will give us a Flask App to mimic your application and some YAML files that annotate the Flask App's databases. 1 2 3 4 5 git clone https://github.com/ethyca/fidesdemo cd fidesdemo git checkout fidesctl-demo make install source venv/bin/activate You can run make server and visit http://127.0.0.1:5000/ to explore the test app. It is a simple e-commerce marketplace where users can buy and sell products.","title":"Clone the fidesdemo repo"},{"location":"tutorial/installation/#install-fidesops-in-our-test-app","text":"We need to install fidesops in the test app, add a PostgreSQL database (for storing Fidesops resources) and a Redis cache (for temporarily storing incoming PII). You'll notice that a postgres container has already been set up for you, and fidesctl is installed (although we won't dive into that tool here). In the Flask App's docker-compose file, add both a container for redis and fidesops services beneath the fidesctl service : fidesdemo/docker-compose.yml : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 services : ... redis : image : \"redis:6.2.5-alpine\" command : redis-server --requirepass redispass expose : - 6379 ports : - \"6379:6379\" fidesops : image : ethyca/fidesops:latest depends_on : - db - redis command : fidesops webserver volumes : - ./fides_uploads:/fidesops/fides_uploads expose : - 8000 ports : - \"8000:8080\" environment : - FIDESOPS__SECURITY__APP_ENCRYPTION_KEY=QLMI5I0xLWUXE4JN4Asnba79JiBHWWM3 - FIDESOPS__SECURITY__OAUTH_ROOT_CLIENT_ID=fidesopsadmin - FIDESOPS__SECURITY__OAUTH_ROOT_CLIENT_SECRET=fidesopsadminsecret - FIDESOPS__DATABASE__SERVER=db - FIDESOPS__DATABASE__USER=postgres - FIDESOPS__DATABASE__PASSWORD=postgres - FIDESOPS__DATABASE__DB=fidesops - FIDESOPS__DATABASE__PORT=5432 - FIDESOPS__REDIS__HOST=redis - FIDESOPS__REDIS__PORT=6379 - FIDESOPS__REDIS__PASSWORD=redispass","title":"Install fidesops in our test app"},{"location":"tutorial/installation/#verify-that-fidesops-is-installed","text":"Run make_server again: 1 2 cd fidesdemo make server Visit http://localhost:8000/docs to check that fidesops is up and running and preview the set of API endpoints that are available for us to run requests on fidesops.","title":"Verify that fidesops is installed"},{"location":"tutorial/oauth_client/","text":"Authentication Creating our Oauth Client For more detailed information, see the Oauth Guide . Our first step is to create an Oauth Client that we can use to authenticate all of our requests. Add a method to our Python script that will call the fidesops API to create a token given a client_id and a client_secret : Define helper methods fidesdemo/flaskr/fidesops.py 1 2 3 4 5 6 7 8 9 10 11 12 13 def get_access_token ( client_id , client_secret ): \"\"\" Authorize with fidesops via OAuth. Returns a valid access token if successful. See http://localhost:8000/api#operations-OAuth-acquire_access_token_api_v1_oauth_token_post \"\"\" data = { \"grant_type\" : \"client_credentials\" , \"client_id\" : client_id , \"client_secret\" : client_secret , } response = requests . post ( f \" { FIDESOPS_URL } /api/v1/oauth/token\" , data = data ) logger . info ( f \"Creating access token. Status { response . status_code } \" ) return response . json ()[ \"access_token\" ] Add another method that will both create a client and assign scopes to that client. It's also useful to define a helper method to build Oauth headers at this point: fidesdemo/flaskr/fidesops.py 1 2 3 4 ... def oauth_headers ( access_token ): \"\"\"Return valid authorization headers given the provided OAuth access token\"\"\" return { \"Authorization\" : f \"Bearer { access_token } \" } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 ... def create_oauth_client ( access_token ): \"\"\" Create a new OAuth client in fidesops.Returns the response JSON if successful. See http://localhost:8000/api#operations-OAuth-acquire_access_token_api_v1_oauth_token_post \"\"\" # Here we're giving the client all the scopes, but in a production app, just give the client the scopes they actually need. scopes_data = [ \"client:create\" , \"client:update\" , \"client:read\" , \"client:delete\" , \"policy:create_or_update\" , \"policy:read\" , \"policy:delete\" , \"connection:create_or_update\" , \"connection:read\" , \"connection:delete\" , \"privacy-request:create\" , \"privacy-request:read\" , \"privacy-request:delete\" , \"rule:create_or_update\" , \"rule:read\" , \"rule:delete\" , \"storage:create_or_update\" , \"storage:read\" , \"storage:delete\" , \"dataset:create_or_update\" , \"dataset:read\" , \"dataset:delete\" , ] response = requests . post ( f \" { FIDESOPS_URL } /api/v1/oauth/client\" , headers = oauth_headers ( access_token ), json = scopes_data ) logger . info ( f \"Creating Oauth Client. Status { response . status_code } \" ) return response . json () Call helper methods to create Oauth token Update our script to call our new functions to create a token for the root client, and then use that token to create a new client with all the scopes. Finally, we create another token for the new client, and that's what we'll use to authenticate subsequent requests. Do not use the root client for anything other than creating other clients. fidesdemo/flaskr/fidesops.py 1 2 3 4 5 6 7 8 9 10 11 12 13 ... if __name__ == \"__main__\" : # Create a new OAuth client to use for our app root_token = get_access_token ( client_id = ROOT_CLIENT_ID , client_secret = ROOT_CLIENT_SECRET ) client = create_oauth_client ( access_token = root_token ) access_token = get_access_token ( client_id = client [ \"client_id\" ], client_secret = client [ \"client_secret\" ] ) ...","title":"Creating an Oauth Client"},{"location":"tutorial/oauth_client/#authentication","text":"","title":"Authentication"},{"location":"tutorial/oauth_client/#creating-our-oauth-client","text":"For more detailed information, see the Oauth Guide . Our first step is to create an Oauth Client that we can use to authenticate all of our requests. Add a method to our Python script that will call the fidesops API to create a token given a client_id and a client_secret :","title":"Creating our Oauth Client"},{"location":"tutorial/oauth_client/#define-helper-methods","text":"fidesdemo/flaskr/fidesops.py 1 2 3 4 5 6 7 8 9 10 11 12 13 def get_access_token ( client_id , client_secret ): \"\"\" Authorize with fidesops via OAuth. Returns a valid access token if successful. See http://localhost:8000/api#operations-OAuth-acquire_access_token_api_v1_oauth_token_post \"\"\" data = { \"grant_type\" : \"client_credentials\" , \"client_id\" : client_id , \"client_secret\" : client_secret , } response = requests . post ( f \" { FIDESOPS_URL } /api/v1/oauth/token\" , data = data ) logger . info ( f \"Creating access token. Status { response . status_code } \" ) return response . json ()[ \"access_token\" ] Add another method that will both create a client and assign scopes to that client. It's also useful to define a helper method to build Oauth headers at this point: fidesdemo/flaskr/fidesops.py 1 2 3 4 ... def oauth_headers ( access_token ): \"\"\"Return valid authorization headers given the provided OAuth access token\"\"\" return { \"Authorization\" : f \"Bearer { access_token } \" } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 ... def create_oauth_client ( access_token ): \"\"\" Create a new OAuth client in fidesops.Returns the response JSON if successful. See http://localhost:8000/api#operations-OAuth-acquire_access_token_api_v1_oauth_token_post \"\"\" # Here we're giving the client all the scopes, but in a production app, just give the client the scopes they actually need. scopes_data = [ \"client:create\" , \"client:update\" , \"client:read\" , \"client:delete\" , \"policy:create_or_update\" , \"policy:read\" , \"policy:delete\" , \"connection:create_or_update\" , \"connection:read\" , \"connection:delete\" , \"privacy-request:create\" , \"privacy-request:read\" , \"privacy-request:delete\" , \"rule:create_or_update\" , \"rule:read\" , \"rule:delete\" , \"storage:create_or_update\" , \"storage:read\" , \"storage:delete\" , \"dataset:create_or_update\" , \"dataset:read\" , \"dataset:delete\" , ] response = requests . post ( f \" { FIDESOPS_URL } /api/v1/oauth/client\" , headers = oauth_headers ( access_token ), json = scopes_data ) logger . info ( f \"Creating Oauth Client. Status { response . status_code } \" ) return response . json ()","title":"Define helper methods"},{"location":"tutorial/oauth_client/#call-helper-methods-to-create-oauth-token","text":"Update our script to call our new functions to create a token for the root client, and then use that token to create a new client with all the scopes. Finally, we create another token for the new client, and that's what we'll use to authenticate subsequent requests. Do not use the root client for anything other than creating other clients. fidesdemo/flaskr/fidesops.py 1 2 3 4 5 6 7 8 9 10 11 12 13 ... if __name__ == \"__main__\" : # Create a new OAuth client to use for our app root_token = get_access_token ( client_id = ROOT_CLIENT_ID , client_secret = ROOT_CLIENT_SECRET ) client = create_oauth_client ( access_token = root_token ) access_token = get_access_token ( client_id = client [ \"client_id\" ], client_secret = client [ \"client_secret\" ] ) ...","title":"Call helper methods to create Oauth token"},{"location":"tutorial/outline/","text":"Outline Let's sketch out a Python file in fidesdemo/flaskr/fidesops.py where we'll add functions that use Python's requests library to call the Fidesops API to build our required configuration. As we go through each step in the tutorial, you'll add a couple of helper methods that are wrappers to API calls, and then add calls to these functions at the bottom to be executed when we run this script. Create the file fidesdemo/flaskr/fidesops.py and add the following imports, environment variables, and outline the methods we'll be creating together: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import logging import requests import yaml from datetime import datetime logger = logging . getLogger ( __name__ ) # For tutorial simplicity. In prod, this should go in an ENV file or similar. FIDESOPS_URL = \"http://localhost:8000\" ROOT_CLIENT_ID = \"fidesopsadmin\" ROOT_CLIENT_SECRET = \"fidesopsadminsecret\" POSTGRES_SERVER = \"db\" POSTGRES_USER = \"postgres\" POSTGRES_PASSWORD = \"postgres\" POSTGRES_PORT = \"5432\" # We'll define some functions here: if __name__ == \"__main__\" : \"\"\"We'll add calls to our functions here\"\"\" # TODO Create a new OAuth client to use for our app # TODO Connect to our PostgreSQL database # TODO Upload the dataset YAML for our PostgreSQL schema # TODO Configure a Storage Config to upload the results # TODO Create a Policy that returns all user data # TODO Execute a Privacy Request for user@example.com","title":"Outlining our Python Script"},{"location":"tutorial/outline/#outline","text":"Let's sketch out a Python file in fidesdemo/flaskr/fidesops.py where we'll add functions that use Python's requests library to call the Fidesops API to build our required configuration. As we go through each step in the tutorial, you'll add a couple of helper methods that are wrappers to API calls, and then add calls to these functions at the bottom to be executed when we run this script. Create the file fidesdemo/flaskr/fidesops.py and add the following imports, environment variables, and outline the methods we'll be creating together: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import logging import requests import yaml from datetime import datetime logger = logging . getLogger ( __name__ ) # For tutorial simplicity. In prod, this should go in an ENV file or similar. FIDESOPS_URL = \"http://localhost:8000\" ROOT_CLIENT_ID = \"fidesopsadmin\" ROOT_CLIENT_SECRET = \"fidesopsadminsecret\" POSTGRES_SERVER = \"db\" POSTGRES_USER = \"postgres\" POSTGRES_PASSWORD = \"postgres\" POSTGRES_PORT = \"5432\" # We'll define some functions here: if __name__ == \"__main__\" : \"\"\"We'll add calls to our functions here\"\"\" # TODO Create a new OAuth client to use for our app # TODO Connect to our PostgreSQL database # TODO Upload the dataset YAML for our PostgreSQL schema # TODO Configure a Storage Config to upload the results # TODO Create a Policy that returns all user data # TODO Execute a Privacy Request for user@example.com","title":"Outline"},{"location":"tutorial/postgres_connection/","text":"Connect to the Flask App Database Creating a Postgres ConnectionConfig For more detailed information, see the Database Connectors Guide . Next, we need to create a ConnectionConfig so fidesops can connect to our Flask App's database. Let's add a method that hits the PUT connection endpoint, and creates a ConnectionConfig for a postgres database: Define helper methods 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def create_postgres_connection ( key , access_token ): \"\"\" Create a connection in fidesops for our PostgreSQL database. Returns the response JSON if successful. See http://localhost:8000/api#operations-Connections-put_connections_api_v1_connection_put \"\"\" connection_create_data = [ { \"name\" : key , \"key\" : key , \"connection_type\" : \"postgres\" , \"access\" : \"write\" , }, ] response = requests . patch ( f \" { FIDESOPS_URL } /api/v1/connection\" , headers = oauth_headers ( access_token = access_token ), json = connection_create_data , ) logger . info ( f \"Creating PostgreSQL ConnectionConfig. Status { response . status_code } \" ) return response . json () Secrets, like a username and password that are needed to access the Flask App's databases, are added separately: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def configure_postgres_connection ( key , host , port , dbname , username , password , access_token ): \"\"\" Configure the connection with the given `key` in fidesops with our PostgreSQL database credentials. Returns the response JSON if successful. See http://localhost:8000/api#operations-Connections-put_connection_config_secrets_api_v1_connection__connection_key__secret_put \"\"\" connection_secrets_data = { \"host\" : host , \"port\" : port , \"dbname\" : dbname , \"username\" : username , \"password\" : password , } response = requests . put ( f \" { FIDESOPS_URL } /api/v1/connection/ { key } /secret\" , headers = oauth_headers ( access_token = access_token ), json = connection_secrets_data , ) logger . info ( f \"Updating PostgreSQL Secrets. Status { response . status_code } .\" ) return response . json () Call helper methods to connect to Postgres Add calls for our new methods, to create a Postgres ConnectionConfig called flaskr_postgres , and then update that connection's secrets with individual URI components. This will encrypt and save the URI components and also attempt to make a test connection to our Flask App's Postgres Database. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 if __name__ == \"__main__\" : ... # Connect to our PostgreSQL database create_postgres_connection ( key = \"flaskr_postgres\" , access_token = access_token ) configure_postgres_connection ( key = \"flaskr_postgres\" , host = POSTGRES_SERVER , port = POSTGRES_PORT , dbname = \"flaskr\" , username = POSTGRES_USER , password = POSTGRES_PASSWORD , access_token = access_token , ) ...","title":"Connecting to Postgres"},{"location":"tutorial/postgres_connection/#connect-to-the-flask-app-database","text":"","title":"Connect to the Flask App Database"},{"location":"tutorial/postgres_connection/#creating-a-postgres-connectionconfig","text":"For more detailed information, see the Database Connectors Guide . Next, we need to create a ConnectionConfig so fidesops can connect to our Flask App's database. Let's add a method that hits the PUT connection endpoint, and creates a ConnectionConfig for a postgres database:","title":"Creating a Postgres ConnectionConfig"},{"location":"tutorial/postgres_connection/#define-helper-methods","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def create_postgres_connection ( key , access_token ): \"\"\" Create a connection in fidesops for our PostgreSQL database. Returns the response JSON if successful. See http://localhost:8000/api#operations-Connections-put_connections_api_v1_connection_put \"\"\" connection_create_data = [ { \"name\" : key , \"key\" : key , \"connection_type\" : \"postgres\" , \"access\" : \"write\" , }, ] response = requests . patch ( f \" { FIDESOPS_URL } /api/v1/connection\" , headers = oauth_headers ( access_token = access_token ), json = connection_create_data , ) logger . info ( f \"Creating PostgreSQL ConnectionConfig. Status { response . status_code } \" ) return response . json () Secrets, like a username and password that are needed to access the Flask App's databases, are added separately: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def configure_postgres_connection ( key , host , port , dbname , username , password , access_token ): \"\"\" Configure the connection with the given `key` in fidesops with our PostgreSQL database credentials. Returns the response JSON if successful. See http://localhost:8000/api#operations-Connections-put_connection_config_secrets_api_v1_connection__connection_key__secret_put \"\"\" connection_secrets_data = { \"host\" : host , \"port\" : port , \"dbname\" : dbname , \"username\" : username , \"password\" : password , } response = requests . put ( f \" { FIDESOPS_URL } /api/v1/connection/ { key } /secret\" , headers = oauth_headers ( access_token = access_token ), json = connection_secrets_data , ) logger . info ( f \"Updating PostgreSQL Secrets. Status { response . status_code } .\" ) return response . json ()","title":"Define helper methods"},{"location":"tutorial/postgres_connection/#call-helper-methods-to-connect-to-postgres","text":"Add calls for our new methods, to create a Postgres ConnectionConfig called flaskr_postgres , and then update that connection's secrets with individual URI components. This will encrypt and save the URI components and also attempt to make a test connection to our Flask App's Postgres Database. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 if __name__ == \"__main__\" : ... # Connect to our PostgreSQL database create_postgres_connection ( key = \"flaskr_postgres\" , access_token = access_token ) configure_postgres_connection ( key = \"flaskr_postgres\" , host = POSTGRES_SERVER , port = POSTGRES_PORT , dbname = \"flaskr\" , username = POSTGRES_USER , password = POSTGRES_PASSWORD , access_token = access_token , ) ...","title":"Call helper methods to connect to Postgres"},{"location":"tutorial/storage_config/","text":"Set up Storage Destination Creating a StorageConfig For more detailed information, see the Storage Config Guide . We need to configure a location to upload the user's PII after fidesops has retrieved it from the Flask App's database. For tutorial purposes, we'll just write to a local file under /fides_uploads , but typically we'd want to upload this to a Storage location like S3. S3 would require a follow-up step to set up AWS access keys and secrets. Define helper method 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def create_local_storage ( key , format , access_token ): \"\"\" Create a StorageConfig in fidesops to write to a local file. Returns the response JSON if successful. See http://localhost:8000/api#operations-Storage-put_config_api_v1_storage_config_put \"\"\" storage_create_data = [ { \"name\" : key , \"key\" : key , \"type\" : \"local\" , \"format\" : format , \"details\" : { \"naming\" : \"request_id\" , }, }, ] response = requests . patch ( f \" { FIDESOPS_URL } /api/v1/storage/config\" , headers = oauth_headers ( access_token = access_token ), json = storage_create_data , ) logger . info ( f \"Defining an upload location. Status { response . status_code } \" ) return response . json () Call helper method to set up Storage This will define a local Storage location called example_storage that expects JSON data. 1 2 3 4 5 6 7 8 9 if __name__ == \"__main__\" : ... # Configure a Storage Config to upload the results create_local_storage ( key = \"example_storage\" , format = \"json\" , access_token = access_token , ) ...","title":"Configuring our Storage Destination"},{"location":"tutorial/storage_config/#set-up-storage-destination","text":"","title":"Set up Storage Destination"},{"location":"tutorial/storage_config/#creating-a-storageconfig","text":"For more detailed information, see the Storage Config Guide . We need to configure a location to upload the user's PII after fidesops has retrieved it from the Flask App's database. For tutorial purposes, we'll just write to a local file under /fides_uploads , but typically we'd want to upload this to a Storage location like S3. S3 would require a follow-up step to set up AWS access keys and secrets.","title":"Creating a StorageConfig"},{"location":"tutorial/storage_config/#define-helper-method","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def create_local_storage ( key , format , access_token ): \"\"\" Create a StorageConfig in fidesops to write to a local file. Returns the response JSON if successful. See http://localhost:8000/api#operations-Storage-put_config_api_v1_storage_config_put \"\"\" storage_create_data = [ { \"name\" : key , \"key\" : key , \"type\" : \"local\" , \"format\" : format , \"details\" : { \"naming\" : \"request_id\" , }, }, ] response = requests . patch ( f \" { FIDESOPS_URL } /api/v1/storage/config\" , headers = oauth_headers ( access_token = access_token ), json = storage_create_data , ) logger . info ( f \"Defining an upload location. Status { response . status_code } \" ) return response . json ()","title":"Define helper method"},{"location":"tutorial/storage_config/#call-helper-method-to-set-up-storage","text":"This will define a local Storage location called example_storage that expects JSON data. 1 2 3 4 5 6 7 8 9 if __name__ == \"__main__\" : ... # Configure a Storage Config to upload the results create_local_storage ( key = \"example_storage\" , format = \"json\" , access_token = access_token , ) ...","title":"Call helper method to set up Storage"}]}